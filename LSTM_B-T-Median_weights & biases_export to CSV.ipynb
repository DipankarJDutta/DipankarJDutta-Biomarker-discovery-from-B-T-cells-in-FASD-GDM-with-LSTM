{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_B-T-Median_weights and Biases.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOI4o2SI62tE3u6NBNR5T8/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DipankarJDutta/DipankarJDutta-Biomarker-discovery-from-B-T-cells-in-FASD-GDM-with-LSTM/blob/Weights-%26-Biases-Visualization/LSTM_B-T-Median_weights%20%26%20biases_export%20to%20CSV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOgnPJNr9Wcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Don't display \"warnings\"\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfPN8Hkp_22L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "492283e9-e312-4b8b-fc59-489b1e5bf5fa"
      },
      "source": [
        "# Loading essentials\n",
        "from numpy import loadtxt\n",
        "from numpy import reshape\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN3LIBHE9XH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fixing random seed to 007 for reproducibility\n",
        "from numpy.random import seed\n",
        "seed(7)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7axTkGAD1rHC",
        "colab_type": "code",
        "outputId": "0fb19afd-6824-40a0-e2a2-c023be3a7722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# Setup ngrok to run Tensorboard\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-29 20:35:12--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.203.157.184, 52.204.140.35, 52.72.59.23, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.203.157.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  39.8MB/s    in 0.3s    \n",
            "\n",
            "2020-01-29 20:35:13 (39.8 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdvmuZzJ1z97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start Tensorboard\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApRwUKgx2Gnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run ngrok to tunnel Tensorboard port 6006\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D57mdAo2dhx",
        "colab_type": "code",
        "outputId": "9b113c43-4b44-4587-b2b9-18ac8fc1b9df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# URL for colab Tensorboard web page\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://ac76f641.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMq2vKCJNlmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data\n",
        "dataset = loadtxt('B-T-median.csv', delimiter = ',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf6EYfq1OSND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape 2D dataset into a 3D dataset with columns as features with one time-step\n",
        "x = dataset.reshape(56, 1, 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbfEdKabnlcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Specify binary output of good (1) and bad (0) learners, y, in x. Learner type differentiated by population median.\n",
        "y = x [:, :, -1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBx8zDJlVjje",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "a4474c57-5b66-4107-9912-95c105f65d16"
      },
      "source": [
        "# Define LSTM One-to-One Model with 3 LSTM cells (determined via hyperparameter optimization). Sigmoid activation on the output layer for binary classification.\n",
        "model = Sequential()\n",
        "model.add(LSTM(3, input_shape=(1,30)))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1vO6vpKmAgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "b97a851d-8754-4748-fcdf-73f0d2bdbb35"
      },
      "source": [
        "# Compile the model \n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bii3aeyi2x0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# keras logs to tensorboard\n",
        "from keras.callbacks import TensorBoard\n",
        "tbCallBack = TensorBoard(log_dir='./log', histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=8,\n",
        "                         write_images=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x30BNEbImxA5",
        "colab_type": "code",
        "outputId": "65f27faf-e56c-4e44-a182-cee8b244e548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Fit the model with a 80-20 split of dataset & shuffling sample order within an epoch. Batch size updated to 8 to be an even factor of sample size of 56.\n",
        "history = model.fit(x, y, validation_split = 0.2, batch_size = 8, epochs = 1000, shuffle = True, callbacks=[tbCallBack])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 44 samples, validate on 12 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1068: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1112: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/1000\n",
            "44/44 [==============================] - 1s 21ms/step - loss: 0.7078 - acc: 0.4545 - val_loss: 0.7239 - val_acc: 0.4167\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/1000\n",
            "44/44 [==============================] - 0s 506us/step - loss: 0.7051 - acc: 0.4545 - val_loss: 0.7204 - val_acc: 0.4167\n",
            "Epoch 3/1000\n",
            "44/44 [==============================] - 0s 488us/step - loss: 0.7028 - acc: 0.4545 - val_loss: 0.7170 - val_acc: 0.4167\n",
            "Epoch 4/1000\n",
            "44/44 [==============================] - 0s 417us/step - loss: 0.7008 - acc: 0.4545 - val_loss: 0.7142 - val_acc: 0.4167\n",
            "Epoch 5/1000\n",
            "44/44 [==============================] - 0s 437us/step - loss: 0.6990 - acc: 0.4545 - val_loss: 0.7113 - val_acc: 0.4167\n",
            "Epoch 6/1000\n",
            "44/44 [==============================] - 0s 392us/step - loss: 0.6977 - acc: 0.4545 - val_loss: 0.7084 - val_acc: 0.4167\n",
            "Epoch 7/1000\n",
            "44/44 [==============================] - 0s 538us/step - loss: 0.6963 - acc: 0.4545 - val_loss: 0.7056 - val_acc: 0.4167\n",
            "Epoch 8/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.6949 - acc: 0.4545 - val_loss: 0.7034 - val_acc: 0.4167\n",
            "Epoch 9/1000\n",
            "44/44 [==============================] - 0s 485us/step - loss: 0.6940 - acc: 0.4545 - val_loss: 0.7014 - val_acc: 0.4167\n",
            "Epoch 10/1000\n",
            "44/44 [==============================] - 0s 420us/step - loss: 0.6927 - acc: 0.4545 - val_loss: 0.7002 - val_acc: 0.4167\n",
            "Epoch 11/1000\n",
            "44/44 [==============================] - 0s 464us/step - loss: 0.6918 - acc: 0.4545 - val_loss: 0.6987 - val_acc: 0.4167\n",
            "Epoch 12/1000\n",
            "44/44 [==============================] - 0s 471us/step - loss: 0.6908 - acc: 0.4545 - val_loss: 0.6971 - val_acc: 0.4167\n",
            "Epoch 13/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.6900 - acc: 0.4545 - val_loss: 0.6953 - val_acc: 0.4167\n",
            "Epoch 14/1000\n",
            "44/44 [==============================] - 0s 429us/step - loss: 0.6891 - acc: 0.4545 - val_loss: 0.6937 - val_acc: 0.4167\n",
            "Epoch 15/1000\n",
            "44/44 [==============================] - 0s 535us/step - loss: 0.6881 - acc: 0.4545 - val_loss: 0.6922 - val_acc: 0.4167\n",
            "Epoch 16/1000\n",
            "44/44 [==============================] - 0s 510us/step - loss: 0.6874 - acc: 0.4545 - val_loss: 0.6908 - val_acc: 0.4167\n",
            "Epoch 17/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.6867 - acc: 0.4545 - val_loss: 0.6896 - val_acc: 0.4167\n",
            "Epoch 18/1000\n",
            "44/44 [==============================] - 0s 427us/step - loss: 0.6860 - acc: 0.4545 - val_loss: 0.6886 - val_acc: 0.4167\n",
            "Epoch 19/1000\n",
            "44/44 [==============================] - 0s 470us/step - loss: 0.6853 - acc: 0.4773 - val_loss: 0.6876 - val_acc: 0.4167\n",
            "Epoch 20/1000\n",
            "44/44 [==============================] - 0s 470us/step - loss: 0.6844 - acc: 0.4773 - val_loss: 0.6870 - val_acc: 0.4167\n",
            "Epoch 21/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.6837 - acc: 0.4773 - val_loss: 0.6857 - val_acc: 0.4167\n",
            "Epoch 22/1000\n",
            "44/44 [==============================] - 0s 513us/step - loss: 0.6827 - acc: 0.4773 - val_loss: 0.6846 - val_acc: 0.4167\n",
            "Epoch 23/1000\n",
            "44/44 [==============================] - 0s 397us/step - loss: 0.6818 - acc: 0.4773 - val_loss: 0.6834 - val_acc: 0.4167\n",
            "Epoch 24/1000\n",
            "44/44 [==============================] - 0s 443us/step - loss: 0.6808 - acc: 0.4773 - val_loss: 0.6821 - val_acc: 0.4167\n",
            "Epoch 25/1000\n",
            "44/44 [==============================] - 0s 564us/step - loss: 0.6800 - acc: 0.5000 - val_loss: 0.6803 - val_acc: 0.4167\n",
            "Epoch 26/1000\n",
            "44/44 [==============================] - 0s 422us/step - loss: 0.6787 - acc: 0.5455 - val_loss: 0.6794 - val_acc: 0.5000\n",
            "Epoch 27/1000\n",
            "44/44 [==============================] - 0s 407us/step - loss: 0.6774 - acc: 0.5455 - val_loss: 0.6784 - val_acc: 0.5000\n",
            "Epoch 28/1000\n",
            "44/44 [==============================] - 0s 622us/step - loss: 0.6761 - acc: 0.6364 - val_loss: 0.6770 - val_acc: 0.5000\n",
            "Epoch 29/1000\n",
            "44/44 [==============================] - 0s 510us/step - loss: 0.6745 - acc: 0.6591 - val_loss: 0.6758 - val_acc: 0.5000\n",
            "Epoch 30/1000\n",
            "44/44 [==============================] - 0s 465us/step - loss: 0.6729 - acc: 0.7045 - val_loss: 0.6740 - val_acc: 0.6667\n",
            "Epoch 31/1000\n",
            "44/44 [==============================] - 0s 569us/step - loss: 0.6710 - acc: 0.7273 - val_loss: 0.6739 - val_acc: 0.5833\n",
            "Epoch 32/1000\n",
            "44/44 [==============================] - 0s 533us/step - loss: 0.6685 - acc: 0.7273 - val_loss: 0.6730 - val_acc: 0.5833\n",
            "Epoch 33/1000\n",
            "44/44 [==============================] - 0s 688us/step - loss: 0.6666 - acc: 0.7727 - val_loss: 0.6721 - val_acc: 0.6667\n",
            "Epoch 34/1000\n",
            "44/44 [==============================] - 0s 409us/step - loss: 0.6637 - acc: 0.7955 - val_loss: 0.6723 - val_acc: 0.5833\n",
            "Epoch 35/1000\n",
            "44/44 [==============================] - 0s 396us/step - loss: 0.6620 - acc: 0.7727 - val_loss: 0.6730 - val_acc: 0.5833\n",
            "Epoch 36/1000\n",
            "44/44 [==============================] - 0s 469us/step - loss: 0.6591 - acc: 0.7500 - val_loss: 0.6730 - val_acc: 0.5833\n",
            "Epoch 37/1000\n",
            "44/44 [==============================] - 0s 396us/step - loss: 0.6565 - acc: 0.8182 - val_loss: 0.6709 - val_acc: 0.5833\n",
            "Epoch 38/1000\n",
            "44/44 [==============================] - 0s 410us/step - loss: 0.6537 - acc: 0.8409 - val_loss: 0.6686 - val_acc: 0.6667\n",
            "Epoch 39/1000\n",
            "44/44 [==============================] - 0s 521us/step - loss: 0.6510 - acc: 0.8636 - val_loss: 0.6678 - val_acc: 0.6667\n",
            "Epoch 40/1000\n",
            "44/44 [==============================] - 0s 395us/step - loss: 0.6485 - acc: 0.8864 - val_loss: 0.6648 - val_acc: 0.6667\n",
            "Epoch 41/1000\n",
            "44/44 [==============================] - 0s 493us/step - loss: 0.6456 - acc: 0.9091 - val_loss: 0.6640 - val_acc: 0.6667\n",
            "Epoch 42/1000\n",
            "44/44 [==============================] - 0s 509us/step - loss: 0.6429 - acc: 0.9091 - val_loss: 0.6648 - val_acc: 0.6667\n",
            "Epoch 43/1000\n",
            "44/44 [==============================] - 0s 404us/step - loss: 0.6403 - acc: 0.8864 - val_loss: 0.6658 - val_acc: 0.5833\n",
            "Epoch 44/1000\n",
            "44/44 [==============================] - 0s 424us/step - loss: 0.6370 - acc: 0.8864 - val_loss: 0.6638 - val_acc: 0.5833\n",
            "Epoch 45/1000\n",
            "44/44 [==============================] - 0s 515us/step - loss: 0.6339 - acc: 0.9091 - val_loss: 0.6597 - val_acc: 0.6667\n",
            "Epoch 46/1000\n",
            "44/44 [==============================] - 0s 418us/step - loss: 0.6312 - acc: 0.9318 - val_loss: 0.6566 - val_acc: 0.6667\n",
            "Epoch 47/1000\n",
            "44/44 [==============================] - 0s 496us/step - loss: 0.6283 - acc: 0.9318 - val_loss: 0.6544 - val_acc: 0.6667\n",
            "Epoch 48/1000\n",
            "44/44 [==============================] - 0s 636us/step - loss: 0.6253 - acc: 0.9318 - val_loss: 0.6507 - val_acc: 0.7500\n",
            "Epoch 49/1000\n",
            "44/44 [==============================] - 0s 583us/step - loss: 0.6221 - acc: 0.9318 - val_loss: 0.6493 - val_acc: 0.7500\n",
            "Epoch 50/1000\n",
            "44/44 [==============================] - 0s 460us/step - loss: 0.6191 - acc: 0.9545 - val_loss: 0.6466 - val_acc: 0.7500\n",
            "Epoch 51/1000\n",
            "44/44 [==============================] - 0s 513us/step - loss: 0.6163 - acc: 0.9545 - val_loss: 0.6472 - val_acc: 0.7500\n",
            "Epoch 52/1000\n",
            "44/44 [==============================] - 0s 463us/step - loss: 0.6127 - acc: 0.9318 - val_loss: 0.6466 - val_acc: 0.7500\n",
            "Epoch 53/1000\n",
            "44/44 [==============================] - 0s 489us/step - loss: 0.6098 - acc: 0.9318 - val_loss: 0.6473 - val_acc: 0.6667\n",
            "Epoch 54/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.6067 - acc: 0.9318 - val_loss: 0.6477 - val_acc: 0.6667\n",
            "Epoch 55/1000\n",
            "44/44 [==============================] - 0s 434us/step - loss: 0.6047 - acc: 0.9318 - val_loss: 0.6426 - val_acc: 0.6667\n",
            "Epoch 56/1000\n",
            "44/44 [==============================] - 0s 531us/step - loss: 0.6004 - acc: 0.9318 - val_loss: 0.6433 - val_acc: 0.6667\n",
            "Epoch 57/1000\n",
            "44/44 [==============================] - 0s 474us/step - loss: 0.5973 - acc: 0.9318 - val_loss: 0.6412 - val_acc: 0.6667\n",
            "Epoch 58/1000\n",
            "44/44 [==============================] - 0s 406us/step - loss: 0.5937 - acc: 0.9545 - val_loss: 0.6390 - val_acc: 0.6667\n",
            "Epoch 59/1000\n",
            "44/44 [==============================] - 0s 478us/step - loss: 0.5904 - acc: 0.9545 - val_loss: 0.6346 - val_acc: 0.7500\n",
            "Epoch 60/1000\n",
            "44/44 [==============================] - 0s 479us/step - loss: 0.5870 - acc: 0.9545 - val_loss: 0.6306 - val_acc: 0.7500\n",
            "Epoch 61/1000\n",
            "44/44 [==============================] - 0s 419us/step - loss: 0.5837 - acc: 0.9545 - val_loss: 0.6271 - val_acc: 0.7500\n",
            "Epoch 62/1000\n",
            "44/44 [==============================] - 0s 548us/step - loss: 0.5804 - acc: 0.9545 - val_loss: 0.6253 - val_acc: 0.7500\n",
            "Epoch 63/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.5773 - acc: 0.9545 - val_loss: 0.6226 - val_acc: 0.7500\n",
            "Epoch 64/1000\n",
            "44/44 [==============================] - 0s 472us/step - loss: 0.5737 - acc: 0.9545 - val_loss: 0.6206 - val_acc: 0.7500\n",
            "Epoch 65/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.5716 - acc: 0.9545 - val_loss: 0.6208 - val_acc: 0.7500\n",
            "Epoch 66/1000\n",
            "44/44 [==============================] - 0s 486us/step - loss: 0.5670 - acc: 0.9545 - val_loss: 0.6156 - val_acc: 0.7500\n",
            "Epoch 67/1000\n",
            "44/44 [==============================] - 0s 500us/step - loss: 0.5638 - acc: 0.9773 - val_loss: 0.6116 - val_acc: 0.8333\n",
            "Epoch 68/1000\n",
            "44/44 [==============================] - 0s 573us/step - loss: 0.5621 - acc: 1.0000 - val_loss: 0.6033 - val_acc: 0.8333\n",
            "Epoch 69/1000\n",
            "44/44 [==============================] - 0s 424us/step - loss: 0.5584 - acc: 1.0000 - val_loss: 0.6009 - val_acc: 0.8333\n",
            "Epoch 70/1000\n",
            "44/44 [==============================] - 0s 434us/step - loss: 0.5552 - acc: 1.0000 - val_loss: 0.6038 - val_acc: 0.8333\n",
            "Epoch 71/1000\n",
            "44/44 [==============================] - 0s 495us/step - loss: 0.5511 - acc: 1.0000 - val_loss: 0.6050 - val_acc: 0.8333\n",
            "Epoch 72/1000\n",
            "44/44 [==============================] - 0s 429us/step - loss: 0.5478 - acc: 1.0000 - val_loss: 0.6029 - val_acc: 0.8333\n",
            "Epoch 73/1000\n",
            "44/44 [==============================] - 0s 515us/step - loss: 0.5453 - acc: 1.0000 - val_loss: 0.6055 - val_acc: 0.7500\n",
            "Epoch 74/1000\n",
            "44/44 [==============================] - 0s 566us/step - loss: 0.5416 - acc: 0.9773 - val_loss: 0.6037 - val_acc: 0.7500\n",
            "Epoch 75/1000\n",
            "44/44 [==============================] - 0s 468us/step - loss: 0.5381 - acc: 0.9773 - val_loss: 0.6001 - val_acc: 0.8333\n",
            "Epoch 76/1000\n",
            "44/44 [==============================] - 0s 545us/step - loss: 0.5348 - acc: 1.0000 - val_loss: 0.5950 - val_acc: 0.8333\n",
            "Epoch 77/1000\n",
            "44/44 [==============================] - 0s 431us/step - loss: 0.5314 - acc: 1.0000 - val_loss: 0.5923 - val_acc: 0.8333\n",
            "Epoch 78/1000\n",
            "44/44 [==============================] - 0s 423us/step - loss: 0.5287 - acc: 1.0000 - val_loss: 0.5926 - val_acc: 0.8333\n",
            "Epoch 79/1000\n",
            "44/44 [==============================] - 0s 569us/step - loss: 0.5253 - acc: 1.0000 - val_loss: 0.5887 - val_acc: 0.8333\n",
            "Epoch 80/1000\n",
            "44/44 [==============================] - 0s 425us/step - loss: 0.5223 - acc: 1.0000 - val_loss: 0.5894 - val_acc: 0.8333\n",
            "Epoch 81/1000\n",
            "44/44 [==============================] - 0s 456us/step - loss: 0.5188 - acc: 1.0000 - val_loss: 0.5851 - val_acc: 0.8333\n",
            "Epoch 82/1000\n",
            "44/44 [==============================] - 0s 537us/step - loss: 0.5158 - acc: 1.0000 - val_loss: 0.5809 - val_acc: 0.8333\n",
            "Epoch 83/1000\n",
            "44/44 [==============================] - 0s 482us/step - loss: 0.5125 - acc: 1.0000 - val_loss: 0.5796 - val_acc: 0.8333\n",
            "Epoch 84/1000\n",
            "44/44 [==============================] - 0s 449us/step - loss: 0.5093 - acc: 1.0000 - val_loss: 0.5781 - val_acc: 0.8333\n",
            "Epoch 85/1000\n",
            "44/44 [==============================] - 0s 490us/step - loss: 0.5061 - acc: 1.0000 - val_loss: 0.5752 - val_acc: 0.8333\n",
            "Epoch 86/1000\n",
            "44/44 [==============================] - 0s 419us/step - loss: 0.5029 - acc: 1.0000 - val_loss: 0.5760 - val_acc: 0.8333\n",
            "Epoch 87/1000\n",
            "44/44 [==============================] - 0s 596us/step - loss: 0.4998 - acc: 1.0000 - val_loss: 0.5765 - val_acc: 0.8333\n",
            "Epoch 88/1000\n",
            "44/44 [==============================] - 0s 558us/step - loss: 0.4970 - acc: 1.0000 - val_loss: 0.5767 - val_acc: 0.8333\n",
            "Epoch 89/1000\n",
            "44/44 [==============================] - 0s 429us/step - loss: 0.4937 - acc: 1.0000 - val_loss: 0.5711 - val_acc: 0.8333\n",
            "Epoch 90/1000\n",
            "44/44 [==============================] - 0s 589us/step - loss: 0.4901 - acc: 1.0000 - val_loss: 0.5690 - val_acc: 0.8333\n",
            "Epoch 91/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.4869 - acc: 1.0000 - val_loss: 0.5667 - val_acc: 0.8333\n",
            "Epoch 92/1000\n",
            "44/44 [==============================] - 0s 398us/step - loss: 0.4844 - acc: 1.0000 - val_loss: 0.5607 - val_acc: 0.8333\n",
            "Epoch 93/1000\n",
            "44/44 [==============================] - 0s 471us/step - loss: 0.4804 - acc: 1.0000 - val_loss: 0.5591 - val_acc: 0.8333\n",
            "Epoch 94/1000\n",
            "44/44 [==============================] - 0s 400us/step - loss: 0.4772 - acc: 1.0000 - val_loss: 0.5574 - val_acc: 0.8333\n",
            "Epoch 95/1000\n",
            "44/44 [==============================] - 0s 399us/step - loss: 0.4744 - acc: 1.0000 - val_loss: 0.5568 - val_acc: 0.8333\n",
            "Epoch 96/1000\n",
            "44/44 [==============================] - 0s 453us/step - loss: 0.4709 - acc: 1.0000 - val_loss: 0.5519 - val_acc: 0.8333\n",
            "Epoch 97/1000\n",
            "44/44 [==============================] - 0s 410us/step - loss: 0.4679 - acc: 1.0000 - val_loss: 0.5507 - val_acc: 0.8333\n",
            "Epoch 98/1000\n",
            "44/44 [==============================] - 0s 459us/step - loss: 0.4649 - acc: 1.0000 - val_loss: 0.5443 - val_acc: 0.8333\n",
            "Epoch 99/1000\n",
            "44/44 [==============================] - 0s 547us/step - loss: 0.4615 - acc: 1.0000 - val_loss: 0.5432 - val_acc: 0.8333\n",
            "Epoch 100/1000\n",
            "44/44 [==============================] - 0s 396us/step - loss: 0.4582 - acc: 1.0000 - val_loss: 0.5399 - val_acc: 0.8333\n",
            "Epoch 101/1000\n",
            "44/44 [==============================] - 0s 391us/step - loss: 0.4551 - acc: 1.0000 - val_loss: 0.5358 - val_acc: 0.8333\n",
            "Epoch 102/1000\n",
            "44/44 [==============================] - 0s 392us/step - loss: 0.4530 - acc: 1.0000 - val_loss: 0.5304 - val_acc: 0.8333\n",
            "Epoch 103/1000\n",
            "44/44 [==============================] - 0s 411us/step - loss: 0.4492 - acc: 1.0000 - val_loss: 0.5314 - val_acc: 0.8333\n",
            "Epoch 104/1000\n",
            "44/44 [==============================] - 0s 378us/step - loss: 0.4463 - acc: 1.0000 - val_loss: 0.5279 - val_acc: 0.8333\n",
            "Epoch 105/1000\n",
            "44/44 [==============================] - 0s 428us/step - loss: 0.4434 - acc: 1.0000 - val_loss: 0.5240 - val_acc: 0.8333\n",
            "Epoch 106/1000\n",
            "44/44 [==============================] - 0s 658us/step - loss: 0.4401 - acc: 1.0000 - val_loss: 0.5227 - val_acc: 0.8333\n",
            "Epoch 107/1000\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.4373 - acc: 1.0000 - val_loss: 0.5223 - val_acc: 0.8333\n",
            "Epoch 108/1000\n",
            "44/44 [==============================] - 0s 593us/step - loss: 0.4345 - acc: 1.0000 - val_loss: 0.5173 - val_acc: 0.8333\n",
            "Epoch 109/1000\n",
            "44/44 [==============================] - 0s 653us/step - loss: 0.4316 - acc: 1.0000 - val_loss: 0.5153 - val_acc: 0.8333\n",
            "Epoch 110/1000\n",
            "44/44 [==============================] - 0s 694us/step - loss: 0.4287 - acc: 1.0000 - val_loss: 0.5125 - val_acc: 0.8333\n",
            "Epoch 111/1000\n",
            "44/44 [==============================] - 0s 926us/step - loss: 0.4260 - acc: 1.0000 - val_loss: 0.5098 - val_acc: 0.8333\n",
            "Epoch 112/1000\n",
            "44/44 [==============================] - 0s 668us/step - loss: 0.4230 - acc: 1.0000 - val_loss: 0.5080 - val_acc: 0.8333\n",
            "Epoch 113/1000\n",
            "44/44 [==============================] - 0s 747us/step - loss: 0.4203 - acc: 1.0000 - val_loss: 0.5065 - val_acc: 0.8333\n",
            "Epoch 114/1000\n",
            "44/44 [==============================] - 0s 576us/step - loss: 0.4176 - acc: 1.0000 - val_loss: 0.5008 - val_acc: 0.8333\n",
            "Epoch 115/1000\n",
            "44/44 [==============================] - 0s 700us/step - loss: 0.4148 - acc: 1.0000 - val_loss: 0.4971 - val_acc: 0.8333\n",
            "Epoch 116/1000\n",
            "44/44 [==============================] - 0s 930us/step - loss: 0.4117 - acc: 1.0000 - val_loss: 0.4968 - val_acc: 0.8333\n",
            "Epoch 117/1000\n",
            "44/44 [==============================] - 0s 802us/step - loss: 0.4090 - acc: 1.0000 - val_loss: 0.4955 - val_acc: 0.8333\n",
            "Epoch 118/1000\n",
            "44/44 [==============================] - 0s 720us/step - loss: 0.4063 - acc: 1.0000 - val_loss: 0.4936 - val_acc: 0.8333\n",
            "Epoch 119/1000\n",
            "44/44 [==============================] - 0s 627us/step - loss: 0.4036 - acc: 1.0000 - val_loss: 0.4926 - val_acc: 0.8333\n",
            "Epoch 120/1000\n",
            "44/44 [==============================] - 0s 777us/step - loss: 0.4007 - acc: 1.0000 - val_loss: 0.4893 - val_acc: 0.8333\n",
            "Epoch 121/1000\n",
            "44/44 [==============================] - 0s 802us/step - loss: 0.3980 - acc: 1.0000 - val_loss: 0.4875 - val_acc: 0.8333\n",
            "Epoch 122/1000\n",
            "44/44 [==============================] - 0s 700us/step - loss: 0.3954 - acc: 1.0000 - val_loss: 0.4856 - val_acc: 0.8333\n",
            "Epoch 123/1000\n",
            "44/44 [==============================] - 0s 615us/step - loss: 0.3928 - acc: 1.0000 - val_loss: 0.4822 - val_acc: 0.8333\n",
            "Epoch 124/1000\n",
            "44/44 [==============================] - 0s 788us/step - loss: 0.3902 - acc: 1.0000 - val_loss: 0.4765 - val_acc: 0.8333\n",
            "Epoch 125/1000\n",
            "44/44 [==============================] - 0s 715us/step - loss: 0.3882 - acc: 1.0000 - val_loss: 0.4716 - val_acc: 0.8333\n",
            "Epoch 126/1000\n",
            "44/44 [==============================] - 0s 436us/step - loss: 0.3850 - acc: 1.0000 - val_loss: 0.4733 - val_acc: 0.8333\n",
            "Epoch 127/1000\n",
            "44/44 [==============================] - 0s 394us/step - loss: 0.3828 - acc: 1.0000 - val_loss: 0.4761 - val_acc: 0.8333\n",
            "Epoch 128/1000\n",
            "44/44 [==============================] - 0s 381us/step - loss: 0.3800 - acc: 1.0000 - val_loss: 0.4744 - val_acc: 0.8333\n",
            "Epoch 129/1000\n",
            "44/44 [==============================] - 0s 397us/step - loss: 0.3775 - acc: 1.0000 - val_loss: 0.4706 - val_acc: 0.8333\n",
            "Epoch 130/1000\n",
            "44/44 [==============================] - 0s 549us/step - loss: 0.3753 - acc: 1.0000 - val_loss: 0.4651 - val_acc: 0.8333\n",
            "Epoch 131/1000\n",
            "44/44 [==============================] - 0s 410us/step - loss: 0.3725 - acc: 1.0000 - val_loss: 0.4655 - val_acc: 0.8333\n",
            "Epoch 132/1000\n",
            "44/44 [==============================] - 0s 396us/step - loss: 0.3699 - acc: 1.0000 - val_loss: 0.4611 - val_acc: 0.8333\n",
            "Epoch 133/1000\n",
            "44/44 [==============================] - 0s 617us/step - loss: 0.3677 - acc: 1.0000 - val_loss: 0.4573 - val_acc: 0.8333\n",
            "Epoch 134/1000\n",
            "44/44 [==============================] - 0s 400us/step - loss: 0.3652 - acc: 1.0000 - val_loss: 0.4575 - val_acc: 0.8333\n",
            "Epoch 135/1000\n",
            "44/44 [==============================] - 0s 521us/step - loss: 0.3626 - acc: 1.0000 - val_loss: 0.4522 - val_acc: 0.9167\n",
            "Epoch 136/1000\n",
            "44/44 [==============================] - 0s 419us/step - loss: 0.3603 - acc: 1.0000 - val_loss: 0.4487 - val_acc: 0.9167\n",
            "Epoch 137/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.3584 - acc: 1.0000 - val_loss: 0.4451 - val_acc: 0.9167\n",
            "Epoch 138/1000\n",
            "44/44 [==============================] - 0s 422us/step - loss: 0.3556 - acc: 1.0000 - val_loss: 0.4474 - val_acc: 0.9167\n",
            "Epoch 139/1000\n",
            "44/44 [==============================] - 0s 471us/step - loss: 0.3532 - acc: 1.0000 - val_loss: 0.4466 - val_acc: 0.8333\n",
            "Epoch 140/1000\n",
            "44/44 [==============================] - 0s 391us/step - loss: 0.3508 - acc: 1.0000 - val_loss: 0.4454 - val_acc: 0.8333\n",
            "Epoch 141/1000\n",
            "44/44 [==============================] - 0s 432us/step - loss: 0.3485 - acc: 1.0000 - val_loss: 0.4473 - val_acc: 0.8333\n",
            "Epoch 142/1000\n",
            "44/44 [==============================] - 0s 390us/step - loss: 0.3464 - acc: 1.0000 - val_loss: 0.4448 - val_acc: 0.8333\n",
            "Epoch 143/1000\n",
            "44/44 [==============================] - 0s 602us/step - loss: 0.3451 - acc: 1.0000 - val_loss: 0.4374 - val_acc: 0.9167\n",
            "Epoch 144/1000\n",
            "44/44 [==============================] - 0s 437us/step - loss: 0.3418 - acc: 1.0000 - val_loss: 0.4390 - val_acc: 0.9167\n",
            "Epoch 145/1000\n",
            "44/44 [==============================] - 0s 406us/step - loss: 0.3394 - acc: 1.0000 - val_loss: 0.4356 - val_acc: 0.9167\n",
            "Epoch 146/1000\n",
            "44/44 [==============================] - 0s 389us/step - loss: 0.3375 - acc: 1.0000 - val_loss: 0.4349 - val_acc: 0.9167\n",
            "Epoch 147/1000\n",
            "44/44 [==============================] - 0s 395us/step - loss: 0.3349 - acc: 1.0000 - val_loss: 0.4267 - val_acc: 0.9167\n",
            "Epoch 148/1000\n",
            "44/44 [==============================] - 0s 466us/step - loss: 0.3327 - acc: 1.0000 - val_loss: 0.4229 - val_acc: 0.9167\n",
            "Epoch 149/1000\n",
            "44/44 [==============================] - 0s 482us/step - loss: 0.3308 - acc: 1.0000 - val_loss: 0.4178 - val_acc: 0.9167\n",
            "Epoch 150/1000\n",
            "44/44 [==============================] - 0s 540us/step - loss: 0.3285 - acc: 1.0000 - val_loss: 0.4172 - val_acc: 0.9167\n",
            "Epoch 151/1000\n",
            "44/44 [==============================] - 0s 523us/step - loss: 0.3263 - acc: 1.0000 - val_loss: 0.4167 - val_acc: 0.9167\n",
            "Epoch 152/1000\n",
            "44/44 [==============================] - 0s 461us/step - loss: 0.3247 - acc: 1.0000 - val_loss: 0.4187 - val_acc: 0.9167\n",
            "Epoch 153/1000\n",
            "44/44 [==============================] - 0s 603us/step - loss: 0.3219 - acc: 1.0000 - val_loss: 0.4147 - val_acc: 0.9167\n",
            "Epoch 154/1000\n",
            "44/44 [==============================] - 0s 397us/step - loss: 0.3202 - acc: 1.0000 - val_loss: 0.4106 - val_acc: 0.9167\n",
            "Epoch 155/1000\n",
            "44/44 [==============================] - 0s 447us/step - loss: 0.3178 - acc: 1.0000 - val_loss: 0.4098 - val_acc: 0.9167\n",
            "Epoch 156/1000\n",
            "44/44 [==============================] - 0s 404us/step - loss: 0.3161 - acc: 1.0000 - val_loss: 0.4114 - val_acc: 0.9167\n",
            "Epoch 157/1000\n",
            "44/44 [==============================] - 0s 406us/step - loss: 0.3138 - acc: 1.0000 - val_loss: 0.4089 - val_acc: 0.9167\n",
            "Epoch 158/1000\n",
            "44/44 [==============================] - 0s 506us/step - loss: 0.3118 - acc: 1.0000 - val_loss: 0.4069 - val_acc: 0.9167\n",
            "Epoch 159/1000\n",
            "44/44 [==============================] - 0s 579us/step - loss: 0.3097 - acc: 1.0000 - val_loss: 0.4021 - val_acc: 0.9167\n",
            "Epoch 160/1000\n",
            "44/44 [==============================] - 0s 501us/step - loss: 0.3081 - acc: 1.0000 - val_loss: 0.3967 - val_acc: 0.9167\n",
            "Epoch 161/1000\n",
            "44/44 [==============================] - 0s 440us/step - loss: 0.3059 - acc: 1.0000 - val_loss: 0.3960 - val_acc: 0.9167\n",
            "Epoch 162/1000\n",
            "44/44 [==============================] - 0s 564us/step - loss: 0.3037 - acc: 1.0000 - val_loss: 0.3970 - val_acc: 0.9167\n",
            "Epoch 163/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.3017 - acc: 1.0000 - val_loss: 0.4001 - val_acc: 0.9167\n",
            "Epoch 164/1000\n",
            "44/44 [==============================] - 0s 490us/step - loss: 0.2999 - acc: 1.0000 - val_loss: 0.3999 - val_acc: 0.9167\n",
            "Epoch 165/1000\n",
            "44/44 [==============================] - 0s 425us/step - loss: 0.2985 - acc: 1.0000 - val_loss: 0.4014 - val_acc: 0.9167\n",
            "Epoch 166/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.2965 - acc: 1.0000 - val_loss: 0.3951 - val_acc: 0.9167\n",
            "Epoch 167/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.2945 - acc: 1.0000 - val_loss: 0.3906 - val_acc: 0.9167\n",
            "Epoch 168/1000\n",
            "44/44 [==============================] - 0s 447us/step - loss: 0.2925 - acc: 1.0000 - val_loss: 0.3906 - val_acc: 0.9167\n",
            "Epoch 169/1000\n",
            "44/44 [==============================] - 0s 432us/step - loss: 0.2905 - acc: 1.0000 - val_loss: 0.3905 - val_acc: 0.9167\n",
            "Epoch 170/1000\n",
            "44/44 [==============================] - 0s 467us/step - loss: 0.2889 - acc: 1.0000 - val_loss: 0.3909 - val_acc: 0.9167\n",
            "Epoch 171/1000\n",
            "44/44 [==============================] - 0s 429us/step - loss: 0.2870 - acc: 1.0000 - val_loss: 0.3856 - val_acc: 0.9167\n",
            "Epoch 172/1000\n",
            "44/44 [==============================] - 0s 433us/step - loss: 0.2850 - acc: 1.0000 - val_loss: 0.3813 - val_acc: 0.9167\n",
            "Epoch 173/1000\n",
            "44/44 [==============================] - 0s 433us/step - loss: 0.2832 - acc: 1.0000 - val_loss: 0.3788 - val_acc: 0.9167\n",
            "Epoch 174/1000\n",
            "44/44 [==============================] - 0s 420us/step - loss: 0.2815 - acc: 1.0000 - val_loss: 0.3749 - val_acc: 0.9167\n",
            "Epoch 175/1000\n",
            "44/44 [==============================] - 0s 429us/step - loss: 0.2796 - acc: 1.0000 - val_loss: 0.3748 - val_acc: 0.9167\n",
            "Epoch 176/1000\n",
            "44/44 [==============================] - 0s 564us/step - loss: 0.2780 - acc: 1.0000 - val_loss: 0.3726 - val_acc: 0.9167\n",
            "Epoch 177/1000\n",
            "44/44 [==============================] - 0s 392us/step - loss: 0.2762 - acc: 1.0000 - val_loss: 0.3708 - val_acc: 0.9167\n",
            "Epoch 178/1000\n",
            "44/44 [==============================] - 0s 424us/step - loss: 0.2744 - acc: 1.0000 - val_loss: 0.3707 - val_acc: 0.9167\n",
            "Epoch 179/1000\n",
            "44/44 [==============================] - 0s 550us/step - loss: 0.2726 - acc: 1.0000 - val_loss: 0.3680 - val_acc: 0.9167\n",
            "Epoch 180/1000\n",
            "44/44 [==============================] - 0s 399us/step - loss: 0.2711 - acc: 1.0000 - val_loss: 0.3619 - val_acc: 0.9167\n",
            "Epoch 181/1000\n",
            "44/44 [==============================] - 0s 412us/step - loss: 0.2692 - acc: 1.0000 - val_loss: 0.3595 - val_acc: 0.9167\n",
            "Epoch 182/1000\n",
            "44/44 [==============================] - 0s 518us/step - loss: 0.2676 - acc: 1.0000 - val_loss: 0.3583 - val_acc: 0.9167\n",
            "Epoch 183/1000\n",
            "44/44 [==============================] - 0s 407us/step - loss: 0.2659 - acc: 1.0000 - val_loss: 0.3564 - val_acc: 0.9167\n",
            "Epoch 184/1000\n",
            "44/44 [==============================] - 0s 425us/step - loss: 0.2646 - acc: 1.0000 - val_loss: 0.3532 - val_acc: 0.9167\n",
            "Epoch 185/1000\n",
            "44/44 [==============================] - 0s 481us/step - loss: 0.2625 - acc: 1.0000 - val_loss: 0.3541 - val_acc: 0.9167\n",
            "Epoch 186/1000\n",
            "44/44 [==============================] - 0s 394us/step - loss: 0.2611 - acc: 1.0000 - val_loss: 0.3583 - val_acc: 0.9167\n",
            "Epoch 187/1000\n",
            "44/44 [==============================] - 0s 404us/step - loss: 0.2594 - acc: 1.0000 - val_loss: 0.3569 - val_acc: 0.9167\n",
            "Epoch 188/1000\n",
            "44/44 [==============================] - 0s 486us/step - loss: 0.2577 - acc: 1.0000 - val_loss: 0.3579 - val_acc: 0.9167\n",
            "Epoch 189/1000\n",
            "44/44 [==============================] - 0s 413us/step - loss: 0.2563 - acc: 1.0000 - val_loss: 0.3567 - val_acc: 0.9167\n",
            "Epoch 190/1000\n",
            "44/44 [==============================] - 0s 437us/step - loss: 0.2545 - acc: 1.0000 - val_loss: 0.3533 - val_acc: 0.9167\n",
            "Epoch 191/1000\n",
            "44/44 [==============================] - 0s 432us/step - loss: 0.2528 - acc: 1.0000 - val_loss: 0.3492 - val_acc: 0.9167\n",
            "Epoch 192/1000\n",
            "44/44 [==============================] - 0s 425us/step - loss: 0.2513 - acc: 1.0000 - val_loss: 0.3453 - val_acc: 0.9167\n",
            "Epoch 193/1000\n",
            "44/44 [==============================] - 0s 432us/step - loss: 0.2500 - acc: 1.0000 - val_loss: 0.3402 - val_acc: 0.9167\n",
            "Epoch 194/1000\n",
            "44/44 [==============================] - 0s 426us/step - loss: 0.2483 - acc: 1.0000 - val_loss: 0.3401 - val_acc: 0.9167\n",
            "Epoch 195/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.2467 - acc: 1.0000 - val_loss: 0.3405 - val_acc: 0.9167\n",
            "Epoch 196/1000\n",
            "44/44 [==============================] - 0s 460us/step - loss: 0.2453 - acc: 1.0000 - val_loss: 0.3391 - val_acc: 0.9167\n",
            "Epoch 197/1000\n",
            "44/44 [==============================] - 0s 879us/step - loss: 0.2435 - acc: 1.0000 - val_loss: 0.3411 - val_acc: 0.9167\n",
            "Epoch 198/1000\n",
            "44/44 [==============================] - 0s 425us/step - loss: 0.2424 - acc: 1.0000 - val_loss: 0.3428 - val_acc: 0.9167\n",
            "Epoch 199/1000\n",
            "44/44 [==============================] - 0s 598us/step - loss: 0.2408 - acc: 1.0000 - val_loss: 0.3396 - val_acc: 0.9167\n",
            "Epoch 200/1000\n",
            "44/44 [==============================] - 0s 421us/step - loss: 0.2394 - acc: 1.0000 - val_loss: 0.3348 - val_acc: 0.9167\n",
            "Epoch 201/1000\n",
            "44/44 [==============================] - 0s 476us/step - loss: 0.2378 - acc: 1.0000 - val_loss: 0.3335 - val_acc: 0.9167\n",
            "Epoch 202/1000\n",
            "44/44 [==============================] - 0s 540us/step - loss: 0.2362 - acc: 1.0000 - val_loss: 0.3300 - val_acc: 0.9167\n",
            "Epoch 203/1000\n",
            "44/44 [==============================] - 0s 423us/step - loss: 0.2348 - acc: 1.0000 - val_loss: 0.3292 - val_acc: 0.9167\n",
            "Epoch 204/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.2333 - acc: 1.0000 - val_loss: 0.3268 - val_acc: 0.9167\n",
            "Epoch 205/1000\n",
            "44/44 [==============================] - 0s 493us/step - loss: 0.2320 - acc: 1.0000 - val_loss: 0.3238 - val_acc: 0.9167\n",
            "Epoch 206/1000\n",
            "44/44 [==============================] - 0s 434us/step - loss: 0.2305 - acc: 1.0000 - val_loss: 0.3244 - val_acc: 0.9167\n",
            "Epoch 207/1000\n",
            "44/44 [==============================] - 0s 500us/step - loss: 0.2290 - acc: 1.0000 - val_loss: 0.3231 - val_acc: 0.9167\n",
            "Epoch 208/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.2276 - acc: 1.0000 - val_loss: 0.3215 - val_acc: 0.9167\n",
            "Epoch 209/1000\n",
            "44/44 [==============================] - 0s 544us/step - loss: 0.2262 - acc: 1.0000 - val_loss: 0.3182 - val_acc: 0.9167\n",
            "Epoch 210/1000\n",
            "44/44 [==============================] - 0s 556us/step - loss: 0.2248 - acc: 1.0000 - val_loss: 0.3156 - val_acc: 1.0000\n",
            "Epoch 211/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.2236 - acc: 1.0000 - val_loss: 0.3148 - val_acc: 0.9167\n",
            "Epoch 212/1000\n",
            "44/44 [==============================] - 0s 456us/step - loss: 0.2223 - acc: 1.0000 - val_loss: 0.3114 - val_acc: 1.0000\n",
            "Epoch 213/1000\n",
            "44/44 [==============================] - 0s 434us/step - loss: 0.2208 - acc: 1.0000 - val_loss: 0.3117 - val_acc: 1.0000\n",
            "Epoch 214/1000\n",
            "44/44 [==============================] - 0s 427us/step - loss: 0.2194 - acc: 1.0000 - val_loss: 0.3121 - val_acc: 0.9167\n",
            "Epoch 215/1000\n",
            "44/44 [==============================] - 0s 408us/step - loss: 0.2185 - acc: 1.0000 - val_loss: 0.3139 - val_acc: 0.9167\n",
            "Epoch 216/1000\n",
            "44/44 [==============================] - 0s 492us/step - loss: 0.2168 - acc: 1.0000 - val_loss: 0.3109 - val_acc: 0.9167\n",
            "Epoch 217/1000\n",
            "44/44 [==============================] - 0s 405us/step - loss: 0.2155 - acc: 1.0000 - val_loss: 0.3077 - val_acc: 1.0000\n",
            "Epoch 218/1000\n",
            "44/44 [==============================] - 0s 452us/step - loss: 0.2142 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 1.0000\n",
            "Epoch 219/1000\n",
            "44/44 [==============================] - 0s 427us/step - loss: 0.2130 - acc: 1.0000 - val_loss: 0.3010 - val_acc: 1.0000\n",
            "Epoch 220/1000\n",
            "44/44 [==============================] - 0s 456us/step - loss: 0.2117 - acc: 1.0000 - val_loss: 0.2969 - val_acc: 1.0000\n",
            "Epoch 221/1000\n",
            "44/44 [==============================] - 0s 608us/step - loss: 0.2106 - acc: 1.0000 - val_loss: 0.2953 - val_acc: 1.0000\n",
            "Epoch 222/1000\n",
            "44/44 [==============================] - 0s 456us/step - loss: 0.2095 - acc: 1.0000 - val_loss: 0.2939 - val_acc: 1.0000\n",
            "Epoch 223/1000\n",
            "44/44 [==============================] - 0s 510us/step - loss: 0.2081 - acc: 1.0000 - val_loss: 0.2967 - val_acc: 1.0000\n",
            "Epoch 224/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.2066 - acc: 1.0000 - val_loss: 0.2982 - val_acc: 1.0000\n",
            "Epoch 225/1000\n",
            "44/44 [==============================] - 0s 433us/step - loss: 0.2056 - acc: 1.0000 - val_loss: 0.2991 - val_acc: 1.0000\n",
            "Epoch 226/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.2044 - acc: 1.0000 - val_loss: 0.2952 - val_acc: 1.0000\n",
            "Epoch 227/1000\n",
            "44/44 [==============================] - 0s 453us/step - loss: 0.2029 - acc: 1.0000 - val_loss: 0.2943 - val_acc: 1.0000\n",
            "Epoch 228/1000\n",
            "44/44 [==============================] - 0s 500us/step - loss: 0.2018 - acc: 1.0000 - val_loss: 0.2929 - val_acc: 1.0000\n",
            "Epoch 229/1000\n",
            "44/44 [==============================] - 0s 588us/step - loss: 0.2006 - acc: 1.0000 - val_loss: 0.2935 - val_acc: 1.0000\n",
            "Epoch 230/1000\n",
            "44/44 [==============================] - 0s 566us/step - loss: 0.1994 - acc: 1.0000 - val_loss: 0.2918 - val_acc: 1.0000\n",
            "Epoch 231/1000\n",
            "44/44 [==============================] - 0s 538us/step - loss: 0.1983 - acc: 1.0000 - val_loss: 0.2887 - val_acc: 1.0000\n",
            "Epoch 232/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.1971 - acc: 1.0000 - val_loss: 0.2859 - val_acc: 1.0000\n",
            "Epoch 233/1000\n",
            "44/44 [==============================] - 0s 444us/step - loss: 0.1959 - acc: 1.0000 - val_loss: 0.2846 - val_acc: 1.0000\n",
            "Epoch 234/1000\n",
            "44/44 [==============================] - 0s 632us/step - loss: 0.1947 - acc: 1.0000 - val_loss: 0.2838 - val_acc: 1.0000\n",
            "Epoch 235/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.1936 - acc: 1.0000 - val_loss: 0.2826 - val_acc: 1.0000\n",
            "Epoch 236/1000\n",
            "44/44 [==============================] - 0s 406us/step - loss: 0.1927 - acc: 1.0000 - val_loss: 0.2828 - val_acc: 1.0000\n",
            "Epoch 237/1000\n",
            "44/44 [==============================] - 0s 472us/step - loss: 0.1915 - acc: 1.0000 - val_loss: 0.2795 - val_acc: 1.0000\n",
            "Epoch 238/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.1902 - acc: 1.0000 - val_loss: 0.2788 - val_acc: 1.0000\n",
            "Epoch 239/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.1891 - acc: 1.0000 - val_loss: 0.2772 - val_acc: 1.0000\n",
            "Epoch 240/1000\n",
            "44/44 [==============================] - 0s 665us/step - loss: 0.1880 - acc: 1.0000 - val_loss: 0.2752 - val_acc: 1.0000\n",
            "Epoch 241/1000\n",
            "44/44 [==============================] - 0s 462us/step - loss: 0.1870 - acc: 1.0000 - val_loss: 0.2738 - val_acc: 1.0000\n",
            "Epoch 242/1000\n",
            "44/44 [==============================] - 0s 434us/step - loss: 0.1859 - acc: 1.0000 - val_loss: 0.2737 - val_acc: 1.0000\n",
            "Epoch 243/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.1848 - acc: 1.0000 - val_loss: 0.2736 - val_acc: 1.0000\n",
            "Epoch 244/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.1838 - acc: 1.0000 - val_loss: 0.2717 - val_acc: 1.0000\n",
            "Epoch 245/1000\n",
            "44/44 [==============================] - 0s 387us/step - loss: 0.1827 - acc: 1.0000 - val_loss: 0.2705 - val_acc: 1.0000\n",
            "Epoch 246/1000\n",
            "44/44 [==============================] - 0s 536us/step - loss: 0.1816 - acc: 1.0000 - val_loss: 0.2689 - val_acc: 1.0000\n",
            "Epoch 247/1000\n",
            "44/44 [==============================] - 0s 429us/step - loss: 0.1806 - acc: 1.0000 - val_loss: 0.2661 - val_acc: 1.0000\n",
            "Epoch 248/1000\n",
            "44/44 [==============================] - 0s 419us/step - loss: 0.1795 - acc: 1.0000 - val_loss: 0.2653 - val_acc: 1.0000\n",
            "Epoch 249/1000\n",
            "44/44 [==============================] - 0s 505us/step - loss: 0.1786 - acc: 1.0000 - val_loss: 0.2656 - val_acc: 1.0000\n",
            "Epoch 250/1000\n",
            "44/44 [==============================] - 0s 486us/step - loss: 0.1774 - acc: 1.0000 - val_loss: 0.2620 - val_acc: 1.0000\n",
            "Epoch 251/1000\n",
            "44/44 [==============================] - 0s 468us/step - loss: 0.1764 - acc: 1.0000 - val_loss: 0.2596 - val_acc: 1.0000\n",
            "Epoch 252/1000\n",
            "44/44 [==============================] - 0s 431us/step - loss: 0.1755 - acc: 1.0000 - val_loss: 0.2594 - val_acc: 1.0000\n",
            "Epoch 253/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.1743 - acc: 1.0000 - val_loss: 0.2560 - val_acc: 1.0000\n",
            "Epoch 254/1000\n",
            "44/44 [==============================] - 0s 465us/step - loss: 0.1738 - acc: 1.0000 - val_loss: 0.2521 - val_acc: 1.0000\n",
            "Epoch 255/1000\n",
            "44/44 [==============================] - 0s 421us/step - loss: 0.1725 - acc: 1.0000 - val_loss: 0.2523 - val_acc: 1.0000\n",
            "Epoch 256/1000\n",
            "44/44 [==============================] - 0s 410us/step - loss: 0.1715 - acc: 1.0000 - val_loss: 0.2527 - val_acc: 1.0000\n",
            "Epoch 257/1000\n",
            "44/44 [==============================] - 0s 433us/step - loss: 0.1705 - acc: 1.0000 - val_loss: 0.2528 - val_acc: 1.0000\n",
            "Epoch 258/1000\n",
            "44/44 [==============================] - 0s 423us/step - loss: 0.1695 - acc: 1.0000 - val_loss: 0.2506 - val_acc: 1.0000\n",
            "Epoch 259/1000\n",
            "44/44 [==============================] - 0s 475us/step - loss: 0.1685 - acc: 1.0000 - val_loss: 0.2514 - val_acc: 1.0000\n",
            "Epoch 260/1000\n",
            "44/44 [==============================] - 0s 479us/step - loss: 0.1676 - acc: 1.0000 - val_loss: 0.2507 - val_acc: 1.0000\n",
            "Epoch 261/1000\n",
            "44/44 [==============================] - 0s 427us/step - loss: 0.1666 - acc: 1.0000 - val_loss: 0.2470 - val_acc: 1.0000\n",
            "Epoch 262/1000\n",
            "44/44 [==============================] - 0s 575us/step - loss: 0.1656 - acc: 1.0000 - val_loss: 0.2463 - val_acc: 1.0000\n",
            "Epoch 263/1000\n",
            "44/44 [==============================] - 0s 444us/step - loss: 0.1647 - acc: 1.0000 - val_loss: 0.2465 - val_acc: 1.0000\n",
            "Epoch 264/1000\n",
            "44/44 [==============================] - 0s 440us/step - loss: 0.1637 - acc: 1.0000 - val_loss: 0.2463 - val_acc: 1.0000\n",
            "Epoch 265/1000\n",
            "44/44 [==============================] - 0s 479us/step - loss: 0.1628 - acc: 1.0000 - val_loss: 0.2464 - val_acc: 1.0000\n",
            "Epoch 266/1000\n",
            "44/44 [==============================] - 0s 483us/step - loss: 0.1619 - acc: 1.0000 - val_loss: 0.2443 - val_acc: 1.0000\n",
            "Epoch 267/1000\n",
            "44/44 [==============================] - 0s 449us/step - loss: 0.1610 - acc: 1.0000 - val_loss: 0.2424 - val_acc: 1.0000\n",
            "Epoch 268/1000\n",
            "44/44 [==============================] - 0s 628us/step - loss: 0.1601 - acc: 1.0000 - val_loss: 0.2406 - val_acc: 1.0000\n",
            "Epoch 269/1000\n",
            "44/44 [==============================] - 0s 412us/step - loss: 0.1591 - acc: 1.0000 - val_loss: 0.2409 - val_acc: 1.0000\n",
            "Epoch 270/1000\n",
            "44/44 [==============================] - 0s 790us/step - loss: 0.1585 - acc: 1.0000 - val_loss: 0.2427 - val_acc: 1.0000\n",
            "Epoch 271/1000\n",
            "44/44 [==============================] - 0s 764us/step - loss: 0.1576 - acc: 1.0000 - val_loss: 0.2422 - val_acc: 1.0000\n",
            "Epoch 272/1000\n",
            "44/44 [==============================] - 0s 824us/step - loss: 0.1565 - acc: 1.0000 - val_loss: 0.2372 - val_acc: 1.0000\n",
            "Epoch 273/1000\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.1560 - acc: 1.0000 - val_loss: 0.2322 - val_acc: 1.0000\n",
            "Epoch 274/1000\n",
            "44/44 [==============================] - 0s 721us/step - loss: 0.1548 - acc: 1.0000 - val_loss: 0.2316 - val_acc: 1.0000\n",
            "Epoch 275/1000\n",
            "44/44 [==============================] - 0s 823us/step - loss: 0.1539 - acc: 1.0000 - val_loss: 0.2309 - val_acc: 1.0000\n",
            "Epoch 276/1000\n",
            "44/44 [==============================] - 0s 583us/step - loss: 0.1531 - acc: 1.0000 - val_loss: 0.2302 - val_acc: 1.0000\n",
            "Epoch 277/1000\n",
            "44/44 [==============================] - 0s 660us/step - loss: 0.1522 - acc: 1.0000 - val_loss: 0.2314 - val_acc: 1.0000\n",
            "Epoch 278/1000\n",
            "44/44 [==============================] - 0s 614us/step - loss: 0.1513 - acc: 1.0000 - val_loss: 0.2326 - val_acc: 1.0000\n",
            "Epoch 279/1000\n",
            "44/44 [==============================] - 0s 603us/step - loss: 0.1506 - acc: 1.0000 - val_loss: 0.2332 - val_acc: 1.0000\n",
            "Epoch 280/1000\n",
            "44/44 [==============================] - 0s 734us/step - loss: 0.1498 - acc: 1.0000 - val_loss: 0.2310 - val_acc: 1.0000\n",
            "Epoch 281/1000\n",
            "44/44 [==============================] - 0s 486us/step - loss: 0.1490 - acc: 1.0000 - val_loss: 0.2284 - val_acc: 1.0000\n",
            "Epoch 282/1000\n",
            "44/44 [==============================] - 0s 765us/step - loss: 0.1481 - acc: 1.0000 - val_loss: 0.2269 - val_acc: 1.0000\n",
            "Epoch 283/1000\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.1474 - acc: 1.0000 - val_loss: 0.2271 - val_acc: 1.0000\n",
            "Epoch 284/1000\n",
            "44/44 [==============================] - 0s 914us/step - loss: 0.1465 - acc: 1.0000 - val_loss: 0.2251 - val_acc: 1.0000\n",
            "Epoch 285/1000\n",
            "44/44 [==============================] - 0s 935us/step - loss: 0.1457 - acc: 1.0000 - val_loss: 0.2229 - val_acc: 1.0000\n",
            "Epoch 286/1000\n",
            "44/44 [==============================] - 0s 751us/step - loss: 0.1449 - acc: 1.0000 - val_loss: 0.2212 - val_acc: 1.0000\n",
            "Epoch 287/1000\n",
            "44/44 [==============================] - 0s 686us/step - loss: 0.1441 - acc: 1.0000 - val_loss: 0.2202 - val_acc: 1.0000\n",
            "Epoch 288/1000\n",
            "44/44 [==============================] - 0s 616us/step - loss: 0.1434 - acc: 1.0000 - val_loss: 0.2181 - val_acc: 1.0000\n",
            "Epoch 289/1000\n",
            "44/44 [==============================] - 0s 680us/step - loss: 0.1426 - acc: 1.0000 - val_loss: 0.2179 - val_acc: 1.0000\n",
            "Epoch 290/1000\n",
            "44/44 [==============================] - 0s 529us/step - loss: 0.1418 - acc: 1.0000 - val_loss: 0.2181 - val_acc: 1.0000\n",
            "Epoch 291/1000\n",
            "44/44 [==============================] - 0s 760us/step - loss: 0.1410 - acc: 1.0000 - val_loss: 0.2175 - val_acc: 1.0000\n",
            "Epoch 292/1000\n",
            "44/44 [==============================] - 0s 670us/step - loss: 0.1404 - acc: 1.0000 - val_loss: 0.2153 - val_acc: 1.0000\n",
            "Epoch 293/1000\n",
            "44/44 [==============================] - 0s 715us/step - loss: 0.1396 - acc: 1.0000 - val_loss: 0.2159 - val_acc: 1.0000\n",
            "Epoch 294/1000\n",
            "44/44 [==============================] - 0s 574us/step - loss: 0.1388 - acc: 1.0000 - val_loss: 0.2144 - val_acc: 1.0000\n",
            "Epoch 295/1000\n",
            "44/44 [==============================] - 0s 642us/step - loss: 0.1380 - acc: 1.0000 - val_loss: 0.2129 - val_acc: 1.0000\n",
            "Epoch 296/1000\n",
            "44/44 [==============================] - 0s 635us/step - loss: 0.1373 - acc: 1.0000 - val_loss: 0.2120 - val_acc: 1.0000\n",
            "Epoch 297/1000\n",
            "44/44 [==============================] - 0s 931us/step - loss: 0.1367 - acc: 1.0000 - val_loss: 0.2097 - val_acc: 1.0000\n",
            "Epoch 298/1000\n",
            "44/44 [==============================] - 0s 566us/step - loss: 0.1359 - acc: 1.0000 - val_loss: 0.2102 - val_acc: 1.0000\n",
            "Epoch 299/1000\n",
            "44/44 [==============================] - 0s 963us/step - loss: 0.1351 - acc: 1.0000 - val_loss: 0.2099 - val_acc: 1.0000\n",
            "Epoch 300/1000\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.1344 - acc: 1.0000 - val_loss: 0.2093 - val_acc: 1.0000\n",
            "Epoch 301/1000\n",
            "44/44 [==============================] - 0s 637us/step - loss: 0.1337 - acc: 1.0000 - val_loss: 0.2077 - val_acc: 1.0000\n",
            "Epoch 302/1000\n",
            "44/44 [==============================] - 0s 802us/step - loss: 0.1330 - acc: 1.0000 - val_loss: 0.2062 - val_acc: 1.0000\n",
            "Epoch 303/1000\n",
            "44/44 [==============================] - 0s 920us/step - loss: 0.1324 - acc: 1.0000 - val_loss: 0.2047 - val_acc: 1.0000\n",
            "Epoch 304/1000\n",
            "44/44 [==============================] - 0s 869us/step - loss: 0.1316 - acc: 1.0000 - val_loss: 0.2059 - val_acc: 1.0000\n",
            "Epoch 305/1000\n",
            "44/44 [==============================] - 0s 427us/step - loss: 0.1309 - acc: 1.0000 - val_loss: 0.2047 - val_acc: 1.0000\n",
            "Epoch 306/1000\n",
            "44/44 [==============================] - 0s 419us/step - loss: 0.1302 - acc: 1.0000 - val_loss: 0.2034 - val_acc: 1.0000\n",
            "Epoch 307/1000\n",
            "44/44 [==============================] - 0s 489us/step - loss: 0.1297 - acc: 1.0000 - val_loss: 0.2043 - val_acc: 1.0000\n",
            "Epoch 308/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.1289 - acc: 1.0000 - val_loss: 0.2018 - val_acc: 1.0000\n",
            "Epoch 309/1000\n",
            "44/44 [==============================] - 0s 463us/step - loss: 0.1282 - acc: 1.0000 - val_loss: 0.2007 - val_acc: 1.0000\n",
            "Epoch 310/1000\n",
            "44/44 [==============================] - 0s 419us/step - loss: 0.1275 - acc: 1.0000 - val_loss: 0.1977 - val_acc: 1.0000\n",
            "Epoch 311/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.1270 - acc: 1.0000 - val_loss: 0.1962 - val_acc: 1.0000\n",
            "Epoch 312/1000\n",
            "44/44 [==============================] - 0s 418us/step - loss: 0.1262 - acc: 1.0000 - val_loss: 0.1964 - val_acc: 1.0000\n",
            "Epoch 313/1000\n",
            "44/44 [==============================] - 0s 437us/step - loss: 0.1256 - acc: 1.0000 - val_loss: 0.1960 - val_acc: 1.0000\n",
            "Epoch 314/1000\n",
            "44/44 [==============================] - 0s 432us/step - loss: 0.1249 - acc: 1.0000 - val_loss: 0.1959 - val_acc: 1.0000\n",
            "Epoch 315/1000\n",
            "44/44 [==============================] - 0s 501us/step - loss: 0.1242 - acc: 1.0000 - val_loss: 0.1954 - val_acc: 1.0000\n",
            "Epoch 316/1000\n",
            "44/44 [==============================] - 0s 506us/step - loss: 0.1238 - acc: 1.0000 - val_loss: 0.1966 - val_acc: 1.0000\n",
            "Epoch 317/1000\n",
            "44/44 [==============================] - 0s 443us/step - loss: 0.1230 - acc: 1.0000 - val_loss: 0.1945 - val_acc: 1.0000\n",
            "Epoch 318/1000\n",
            "44/44 [==============================] - 0s 501us/step - loss: 0.1224 - acc: 1.0000 - val_loss: 0.1914 - val_acc: 1.0000\n",
            "Epoch 319/1000\n",
            "44/44 [==============================] - 0s 465us/step - loss: 0.1218 - acc: 1.0000 - val_loss: 0.1893 - val_acc: 1.0000\n",
            "Epoch 320/1000\n",
            "44/44 [==============================] - 0s 442us/step - loss: 0.1210 - acc: 1.0000 - val_loss: 0.1900 - val_acc: 1.0000\n",
            "Epoch 321/1000\n",
            "44/44 [==============================] - 0s 599us/step - loss: 0.1205 - acc: 1.0000 - val_loss: 0.1891 - val_acc: 1.0000\n",
            "Epoch 322/1000\n",
            "44/44 [==============================] - 0s 500us/step - loss: 0.1199 - acc: 1.0000 - val_loss: 0.1899 - val_acc: 1.0000\n",
            "Epoch 323/1000\n",
            "44/44 [==============================] - 0s 431us/step - loss: 0.1192 - acc: 1.0000 - val_loss: 0.1895 - val_acc: 1.0000\n",
            "Epoch 324/1000\n",
            "44/44 [==============================] - 0s 516us/step - loss: 0.1186 - acc: 1.0000 - val_loss: 0.1881 - val_acc: 1.0000\n",
            "Epoch 325/1000\n",
            "44/44 [==============================] - 0s 499us/step - loss: 0.1180 - acc: 1.0000 - val_loss: 0.1876 - val_acc: 1.0000\n",
            "Epoch 326/1000\n",
            "44/44 [==============================] - 0s 685us/step - loss: 0.1174 - acc: 1.0000 - val_loss: 0.1861 - val_acc: 1.0000\n",
            "Epoch 327/1000\n",
            "44/44 [==============================] - 0s 505us/step - loss: 0.1169 - acc: 1.0000 - val_loss: 0.1836 - val_acc: 1.0000\n",
            "Epoch 328/1000\n",
            "44/44 [==============================] - 0s 475us/step - loss: 0.1162 - acc: 1.0000 - val_loss: 0.1832 - val_acc: 1.0000\n",
            "Epoch 329/1000\n",
            "44/44 [==============================] - 0s 516us/step - loss: 0.1156 - acc: 1.0000 - val_loss: 0.1830 - val_acc: 1.0000\n",
            "Epoch 330/1000\n",
            "44/44 [==============================] - 0s 471us/step - loss: 0.1150 - acc: 1.0000 - val_loss: 0.1823 - val_acc: 1.0000\n",
            "Epoch 331/1000\n",
            "44/44 [==============================] - 0s 466us/step - loss: 0.1146 - acc: 1.0000 - val_loss: 0.1800 - val_acc: 1.0000\n",
            "Epoch 332/1000\n",
            "44/44 [==============================] - 0s 544us/step - loss: 0.1139 - acc: 1.0000 - val_loss: 0.1798 - val_acc: 1.0000\n",
            "Epoch 333/1000\n",
            "44/44 [==============================] - 0s 432us/step - loss: 0.1134 - acc: 1.0000 - val_loss: 0.1778 - val_acc: 1.0000\n",
            "Epoch 334/1000\n",
            "44/44 [==============================] - 0s 466us/step - loss: 0.1128 - acc: 1.0000 - val_loss: 0.1787 - val_acc: 1.0000\n",
            "Epoch 335/1000\n",
            "44/44 [==============================] - 0s 420us/step - loss: 0.1122 - acc: 1.0000 - val_loss: 0.1776 - val_acc: 1.0000\n",
            "Epoch 336/1000\n",
            "44/44 [==============================] - 0s 554us/step - loss: 0.1117 - acc: 1.0000 - val_loss: 0.1781 - val_acc: 1.0000\n",
            "Epoch 337/1000\n",
            "44/44 [==============================] - 0s 474us/step - loss: 0.1110 - acc: 1.0000 - val_loss: 0.1761 - val_acc: 1.0000\n",
            "Epoch 338/1000\n",
            "44/44 [==============================] - 0s 567us/step - loss: 0.1105 - acc: 1.0000 - val_loss: 0.1744 - val_acc: 1.0000\n",
            "Epoch 339/1000\n",
            "44/44 [==============================] - 0s 489us/step - loss: 0.1099 - acc: 1.0000 - val_loss: 0.1741 - val_acc: 1.0000\n",
            "Epoch 340/1000\n",
            "44/44 [==============================] - 0s 659us/step - loss: 0.1095 - acc: 1.0000 - val_loss: 0.1756 - val_acc: 1.0000\n",
            "Epoch 341/1000\n",
            "44/44 [==============================] - 0s 503us/step - loss: 0.1088 - acc: 1.0000 - val_loss: 0.1745 - val_acc: 1.0000\n",
            "Epoch 342/1000\n",
            "44/44 [==============================] - 0s 578us/step - loss: 0.1083 - acc: 1.0000 - val_loss: 0.1738 - val_acc: 1.0000\n",
            "Epoch 343/1000\n",
            "44/44 [==============================] - 0s 591us/step - loss: 0.1078 - acc: 1.0000 - val_loss: 0.1737 - val_acc: 1.0000\n",
            "Epoch 344/1000\n",
            "44/44 [==============================] - 0s 524us/step - loss: 0.1072 - acc: 1.0000 - val_loss: 0.1714 - val_acc: 1.0000\n",
            "Epoch 345/1000\n",
            "44/44 [==============================] - 0s 623us/step - loss: 0.1067 - acc: 1.0000 - val_loss: 0.1691 - val_acc: 1.0000\n",
            "Epoch 346/1000\n",
            "44/44 [==============================] - 0s 520us/step - loss: 0.1062 - acc: 1.0000 - val_loss: 0.1688 - val_acc: 1.0000\n",
            "Epoch 347/1000\n",
            "44/44 [==============================] - 0s 601us/step - loss: 0.1056 - acc: 1.0000 - val_loss: 0.1672 - val_acc: 1.0000\n",
            "Epoch 348/1000\n",
            "44/44 [==============================] - 0s 420us/step - loss: 0.1051 - acc: 1.0000 - val_loss: 0.1667 - val_acc: 1.0000\n",
            "Epoch 349/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.1046 - acc: 1.0000 - val_loss: 0.1657 - val_acc: 1.0000\n",
            "Epoch 350/1000\n",
            "44/44 [==============================] - 0s 608us/step - loss: 0.1042 - acc: 1.0000 - val_loss: 0.1635 - val_acc: 1.0000\n",
            "Epoch 351/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.1037 - acc: 1.0000 - val_loss: 0.1627 - val_acc: 1.0000\n",
            "Epoch 352/1000\n",
            "44/44 [==============================] - 0s 476us/step - loss: 0.1031 - acc: 1.0000 - val_loss: 0.1633 - val_acc: 1.0000\n",
            "Epoch 353/1000\n",
            "44/44 [==============================] - 0s 545us/step - loss: 0.1025 - acc: 1.0000 - val_loss: 0.1643 - val_acc: 1.0000\n",
            "Epoch 354/1000\n",
            "44/44 [==============================] - 0s 542us/step - loss: 0.1020 - acc: 1.0000 - val_loss: 0.1640 - val_acc: 1.0000\n",
            "Epoch 355/1000\n",
            "44/44 [==============================] - 0s 511us/step - loss: 0.1015 - acc: 1.0000 - val_loss: 0.1634 - val_acc: 1.0000\n",
            "Epoch 356/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.1011 - acc: 1.0000 - val_loss: 0.1623 - val_acc: 1.0000\n",
            "Epoch 357/1000\n",
            "44/44 [==============================] - 0s 499us/step - loss: 0.1006 - acc: 1.0000 - val_loss: 0.1623 - val_acc: 1.0000\n",
            "Epoch 358/1000\n",
            "44/44 [==============================] - 0s 594us/step - loss: 0.1001 - acc: 1.0000 - val_loss: 0.1601 - val_acc: 1.0000\n",
            "Epoch 359/1000\n",
            "44/44 [==============================] - 0s 480us/step - loss: 0.0996 - acc: 1.0000 - val_loss: 0.1605 - val_acc: 1.0000\n",
            "Epoch 360/1000\n",
            "44/44 [==============================] - 0s 606us/step - loss: 0.0991 - acc: 1.0000 - val_loss: 0.1589 - val_acc: 1.0000\n",
            "Epoch 361/1000\n",
            "44/44 [==============================] - 0s 518us/step - loss: 0.0987 - acc: 1.0000 - val_loss: 0.1565 - val_acc: 1.0000\n",
            "Epoch 362/1000\n",
            "44/44 [==============================] - 0s 455us/step - loss: 0.0981 - acc: 1.0000 - val_loss: 0.1556 - val_acc: 1.0000\n",
            "Epoch 363/1000\n",
            "44/44 [==============================] - 0s 452us/step - loss: 0.0977 - acc: 1.0000 - val_loss: 0.1549 - val_acc: 1.0000\n",
            "Epoch 364/1000\n",
            "44/44 [==============================] - 0s 504us/step - loss: 0.0973 - acc: 1.0000 - val_loss: 0.1551 - val_acc: 1.0000\n",
            "Epoch 365/1000\n",
            "44/44 [==============================] - 0s 509us/step - loss: 0.0969 - acc: 1.0000 - val_loss: 0.1562 - val_acc: 1.0000\n",
            "Epoch 366/1000\n",
            "44/44 [==============================] - 0s 548us/step - loss: 0.0962 - acc: 1.0000 - val_loss: 0.1549 - val_acc: 1.0000\n",
            "Epoch 367/1000\n",
            "44/44 [==============================] - 0s 469us/step - loss: 0.0958 - acc: 1.0000 - val_loss: 0.1532 - val_acc: 1.0000\n",
            "Epoch 368/1000\n",
            "44/44 [==============================] - 0s 603us/step - loss: 0.0954 - acc: 1.0000 - val_loss: 0.1541 - val_acc: 1.0000\n",
            "Epoch 369/1000\n",
            "44/44 [==============================] - 0s 537us/step - loss: 0.0949 - acc: 1.0000 - val_loss: 0.1531 - val_acc: 1.0000\n",
            "Epoch 370/1000\n",
            "44/44 [==============================] - 0s 507us/step - loss: 0.0944 - acc: 1.0000 - val_loss: 0.1523 - val_acc: 1.0000\n",
            "Epoch 371/1000\n",
            "44/44 [==============================] - 0s 513us/step - loss: 0.0940 - acc: 1.0000 - val_loss: 0.1510 - val_acc: 1.0000\n",
            "Epoch 372/1000\n",
            "44/44 [==============================] - 0s 488us/step - loss: 0.0935 - acc: 1.0000 - val_loss: 0.1515 - val_acc: 1.0000\n",
            "Epoch 373/1000\n",
            "44/44 [==============================] - 0s 499us/step - loss: 0.0931 - acc: 1.0000 - val_loss: 0.1506 - val_acc: 1.0000\n",
            "Epoch 374/1000\n",
            "44/44 [==============================] - 0s 625us/step - loss: 0.0926 - acc: 1.0000 - val_loss: 0.1496 - val_acc: 1.0000\n",
            "Epoch 375/1000\n",
            "44/44 [==============================] - 0s 537us/step - loss: 0.0922 - acc: 1.0000 - val_loss: 0.1492 - val_acc: 1.0000\n",
            "Epoch 376/1000\n",
            "44/44 [==============================] - 0s 660us/step - loss: 0.0917 - acc: 1.0000 - val_loss: 0.1490 - val_acc: 1.0000\n",
            "Epoch 377/1000\n",
            "44/44 [==============================] - 0s 489us/step - loss: 0.0914 - acc: 1.0000 - val_loss: 0.1498 - val_acc: 1.0000\n",
            "Epoch 378/1000\n",
            "44/44 [==============================] - 0s 620us/step - loss: 0.0909 - acc: 1.0000 - val_loss: 0.1481 - val_acc: 1.0000\n",
            "Epoch 379/1000\n",
            "44/44 [==============================] - 0s 628us/step - loss: 0.0904 - acc: 1.0000 - val_loss: 0.1470 - val_acc: 1.0000\n",
            "Epoch 380/1000\n",
            "44/44 [==============================] - 0s 458us/step - loss: 0.0900 - acc: 1.0000 - val_loss: 0.1465 - val_acc: 1.0000\n",
            "Epoch 381/1000\n",
            "44/44 [==============================] - 0s 545us/step - loss: 0.0897 - acc: 1.0000 - val_loss: 0.1467 - val_acc: 1.0000\n",
            "Epoch 382/1000\n",
            "44/44 [==============================] - 0s 456us/step - loss: 0.0892 - acc: 1.0000 - val_loss: 0.1454 - val_acc: 1.0000\n",
            "Epoch 383/1000\n",
            "44/44 [==============================] - 0s 425us/step - loss: 0.0888 - acc: 1.0000 - val_loss: 0.1448 - val_acc: 1.0000\n",
            "Epoch 384/1000\n",
            "44/44 [==============================] - 0s 424us/step - loss: 0.0884 - acc: 1.0000 - val_loss: 0.1447 - val_acc: 1.0000\n",
            "Epoch 385/1000\n",
            "44/44 [==============================] - 0s 449us/step - loss: 0.0880 - acc: 1.0000 - val_loss: 0.1443 - val_acc: 1.0000\n",
            "Epoch 386/1000\n",
            "44/44 [==============================] - 0s 495us/step - loss: 0.0875 - acc: 1.0000 - val_loss: 0.1438 - val_acc: 1.0000\n",
            "Epoch 387/1000\n",
            "44/44 [==============================] - 0s 532us/step - loss: 0.0872 - acc: 1.0000 - val_loss: 0.1429 - val_acc: 1.0000\n",
            "Epoch 388/1000\n",
            "44/44 [==============================] - 0s 480us/step - loss: 0.0868 - acc: 1.0000 - val_loss: 0.1434 - val_acc: 1.0000\n",
            "Epoch 389/1000\n",
            "44/44 [==============================] - 0s 467us/step - loss: 0.0864 - acc: 1.0000 - val_loss: 0.1422 - val_acc: 1.0000\n",
            "Epoch 390/1000\n",
            "44/44 [==============================] - 0s 620us/step - loss: 0.0860 - acc: 1.0000 - val_loss: 0.1414 - val_acc: 1.0000\n",
            "Epoch 391/1000\n",
            "44/44 [==============================] - 0s 422us/step - loss: 0.0856 - acc: 1.0000 - val_loss: 0.1413 - val_acc: 1.0000\n",
            "Epoch 392/1000\n",
            "44/44 [==============================] - 0s 436us/step - loss: 0.0852 - acc: 1.0000 - val_loss: 0.1408 - val_acc: 1.0000\n",
            "Epoch 393/1000\n",
            "44/44 [==============================] - 0s 593us/step - loss: 0.0848 - acc: 1.0000 - val_loss: 0.1400 - val_acc: 1.0000\n",
            "Epoch 394/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.0844 - acc: 1.0000 - val_loss: 0.1385 - val_acc: 1.0000\n",
            "Epoch 395/1000\n",
            "44/44 [==============================] - 0s 652us/step - loss: 0.0840 - acc: 1.0000 - val_loss: 0.1382 - val_acc: 1.0000\n",
            "Epoch 396/1000\n",
            "44/44 [==============================] - 0s 548us/step - loss: 0.0836 - acc: 1.0000 - val_loss: 0.1381 - val_acc: 1.0000\n",
            "Epoch 397/1000\n",
            "44/44 [==============================] - 0s 539us/step - loss: 0.0832 - acc: 1.0000 - val_loss: 0.1362 - val_acc: 1.0000\n",
            "Epoch 398/1000\n",
            "44/44 [==============================] - 0s 579us/step - loss: 0.0828 - acc: 1.0000 - val_loss: 0.1353 - val_acc: 1.0000\n",
            "Epoch 399/1000\n",
            "44/44 [==============================] - 0s 497us/step - loss: 0.0825 - acc: 1.0000 - val_loss: 0.1353 - val_acc: 1.0000\n",
            "Epoch 400/1000\n",
            "44/44 [==============================] - 0s 597us/step - loss: 0.0821 - acc: 1.0000 - val_loss: 0.1344 - val_acc: 1.0000\n",
            "Epoch 401/1000\n",
            "44/44 [==============================] - 0s 542us/step - loss: 0.0817 - acc: 1.0000 - val_loss: 0.1334 - val_acc: 1.0000\n",
            "Epoch 402/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0813 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 1.0000\n",
            "Epoch 403/1000\n",
            "44/44 [==============================] - 0s 618us/step - loss: 0.0810 - acc: 1.0000 - val_loss: 0.1319 - val_acc: 1.0000\n",
            "Epoch 404/1000\n",
            "44/44 [==============================] - 0s 550us/step - loss: 0.0807 - acc: 1.0000 - val_loss: 0.1325 - val_acc: 1.0000\n",
            "Epoch 405/1000\n",
            "44/44 [==============================] - 0s 650us/step - loss: 0.0802 - acc: 1.0000 - val_loss: 0.1314 - val_acc: 1.0000\n",
            "Epoch 406/1000\n",
            "44/44 [==============================] - 0s 517us/step - loss: 0.0798 - acc: 1.0000 - val_loss: 0.1311 - val_acc: 1.0000\n",
            "Epoch 407/1000\n",
            "44/44 [==============================] - 0s 590us/step - loss: 0.0795 - acc: 1.0000 - val_loss: 0.1314 - val_acc: 1.0000\n",
            "Epoch 408/1000\n",
            "44/44 [==============================] - 0s 528us/step - loss: 0.0791 - acc: 1.0000 - val_loss: 0.1307 - val_acc: 1.0000\n",
            "Epoch 409/1000\n",
            "44/44 [==============================] - 0s 458us/step - loss: 0.0788 - acc: 1.0000 - val_loss: 0.1288 - val_acc: 1.0000\n",
            "Epoch 410/1000\n",
            "44/44 [==============================] - 0s 576us/step - loss: 0.0784 - acc: 1.0000 - val_loss: 0.1280 - val_acc: 1.0000\n",
            "Epoch 411/1000\n",
            "44/44 [==============================] - 0s 424us/step - loss: 0.0781 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 1.0000\n",
            "Epoch 412/1000\n",
            "44/44 [==============================] - 0s 437us/step - loss: 0.0777 - acc: 1.0000 - val_loss: 0.1274 - val_acc: 1.0000\n",
            "Epoch 413/1000\n",
            "44/44 [==============================] - 0s 622us/step - loss: 0.0773 - acc: 1.0000 - val_loss: 0.1280 - val_acc: 1.0000\n",
            "Epoch 414/1000\n",
            "44/44 [==============================] - 0s 427us/step - loss: 0.0771 - acc: 1.0000 - val_loss: 0.1272 - val_acc: 1.0000\n",
            "Epoch 415/1000\n",
            "44/44 [==============================] - 0s 460us/step - loss: 0.0766 - acc: 1.0000 - val_loss: 0.1276 - val_acc: 1.0000\n",
            "Epoch 416/1000\n",
            "44/44 [==============================] - 0s 562us/step - loss: 0.0763 - acc: 1.0000 - val_loss: 0.1272 - val_acc: 1.0000\n",
            "Epoch 417/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.0760 - acc: 1.0000 - val_loss: 0.1272 - val_acc: 1.0000\n",
            "Epoch 418/1000\n",
            "44/44 [==============================] - 0s 553us/step - loss: 0.0757 - acc: 1.0000 - val_loss: 0.1268 - val_acc: 1.0000\n",
            "Epoch 419/1000\n",
            "44/44 [==============================] - 0s 428us/step - loss: 0.0754 - acc: 1.0000 - val_loss: 0.1261 - val_acc: 1.0000\n",
            "Epoch 420/1000\n",
            "44/44 [==============================] - 0s 491us/step - loss: 0.0750 - acc: 1.0000 - val_loss: 0.1261 - val_acc: 1.0000\n",
            "Epoch 421/1000\n",
            "44/44 [==============================] - 0s 542us/step - loss: 0.0747 - acc: 1.0000 - val_loss: 0.1250 - val_acc: 1.0000\n",
            "Epoch 422/1000\n",
            "44/44 [==============================] - 0s 468us/step - loss: 0.0744 - acc: 1.0000 - val_loss: 0.1241 - val_acc: 1.0000\n",
            "Epoch 423/1000\n",
            "44/44 [==============================] - 0s 467us/step - loss: 0.0740 - acc: 1.0000 - val_loss: 0.1236 - val_acc: 1.0000\n",
            "Epoch 424/1000\n",
            "44/44 [==============================] - 0s 479us/step - loss: 0.0737 - acc: 1.0000 - val_loss: 0.1223 - val_acc: 1.0000\n",
            "Epoch 425/1000\n",
            "44/44 [==============================] - 0s 546us/step - loss: 0.0734 - acc: 1.0000 - val_loss: 0.1222 - val_acc: 1.0000\n",
            "Epoch 426/1000\n",
            "44/44 [==============================] - 0s 561us/step - loss: 0.0730 - acc: 1.0000 - val_loss: 0.1217 - val_acc: 1.0000\n",
            "Epoch 427/1000\n",
            "44/44 [==============================] - 0s 502us/step - loss: 0.0727 - acc: 1.0000 - val_loss: 0.1216 - val_acc: 1.0000\n",
            "Epoch 428/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.0724 - acc: 1.0000 - val_loss: 0.1206 - val_acc: 1.0000\n",
            "Epoch 429/1000\n",
            "44/44 [==============================] - 0s 595us/step - loss: 0.0722 - acc: 1.0000 - val_loss: 0.1183 - val_acc: 1.0000\n",
            "Epoch 430/1000\n",
            "44/44 [==============================] - 0s 424us/step - loss: 0.0718 - acc: 1.0000 - val_loss: 0.1177 - val_acc: 1.0000\n",
            "Epoch 431/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.0715 - acc: 1.0000 - val_loss: 0.1181 - val_acc: 1.0000\n",
            "Epoch 432/1000\n",
            "44/44 [==============================] - 0s 550us/step - loss: 0.0711 - acc: 1.0000 - val_loss: 0.1189 - val_acc: 1.0000\n",
            "Epoch 433/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.0708 - acc: 1.0000 - val_loss: 0.1185 - val_acc: 1.0000\n",
            "Epoch 434/1000\n",
            "44/44 [==============================] - 0s 428us/step - loss: 0.0705 - acc: 1.0000 - val_loss: 0.1179 - val_acc: 1.0000\n",
            "Epoch 435/1000\n",
            "44/44 [==============================] - 0s 597us/step - loss: 0.0702 - acc: 1.0000 - val_loss: 0.1173 - val_acc: 1.0000\n",
            "Epoch 436/1000\n",
            "44/44 [==============================] - 0s 544us/step - loss: 0.0699 - acc: 1.0000 - val_loss: 0.1167 - val_acc: 1.0000\n",
            "Epoch 437/1000\n",
            "44/44 [==============================] - 0s 568us/step - loss: 0.0696 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 1.0000\n",
            "Epoch 438/1000\n",
            "44/44 [==============================] - 0s 629us/step - loss: 0.0693 - acc: 1.0000 - val_loss: 0.1167 - val_acc: 1.0000\n",
            "Epoch 439/1000\n",
            "44/44 [==============================] - 0s 735us/step - loss: 0.0690 - acc: 1.0000 - val_loss: 0.1159 - val_acc: 1.0000\n",
            "Epoch 440/1000\n",
            "44/44 [==============================] - 0s 478us/step - loss: 0.0687 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 1.0000\n",
            "Epoch 441/1000\n",
            "44/44 [==============================] - 0s 722us/step - loss: 0.0684 - acc: 1.0000 - val_loss: 0.1151 - val_acc: 1.0000\n",
            "Epoch 442/1000\n",
            "44/44 [==============================] - 0s 847us/step - loss: 0.0681 - acc: 1.0000 - val_loss: 0.1148 - val_acc: 1.0000\n",
            "Epoch 443/1000\n",
            "44/44 [==============================] - 0s 730us/step - loss: 0.0678 - acc: 1.0000 - val_loss: 0.1147 - val_acc: 1.0000\n",
            "Epoch 444/1000\n",
            "44/44 [==============================] - 0s 675us/step - loss: 0.0675 - acc: 1.0000 - val_loss: 0.1141 - val_acc: 1.0000\n",
            "Epoch 445/1000\n",
            "44/44 [==============================] - 0s 863us/step - loss: 0.0673 - acc: 1.0000 - val_loss: 0.1127 - val_acc: 1.0000\n",
            "Epoch 446/1000\n",
            "44/44 [==============================] - 0s 740us/step - loss: 0.0669 - acc: 1.0000 - val_loss: 0.1121 - val_acc: 1.0000\n",
            "Epoch 447/1000\n",
            "44/44 [==============================] - 0s 748us/step - loss: 0.0667 - acc: 1.0000 - val_loss: 0.1117 - val_acc: 1.0000\n",
            "Epoch 448/1000\n",
            "44/44 [==============================] - 0s 671us/step - loss: 0.0664 - acc: 1.0000 - val_loss: 0.1119 - val_acc: 1.0000\n",
            "Epoch 449/1000\n",
            "44/44 [==============================] - 0s 749us/step - loss: 0.0661 - acc: 1.0000 - val_loss: 0.1114 - val_acc: 1.0000\n",
            "Epoch 450/1000\n",
            "44/44 [==============================] - 0s 735us/step - loss: 0.0658 - acc: 1.0000 - val_loss: 0.1108 - val_acc: 1.0000\n",
            "Epoch 451/1000\n",
            "44/44 [==============================] - 0s 810us/step - loss: 0.0655 - acc: 1.0000 - val_loss: 0.1105 - val_acc: 1.0000\n",
            "Epoch 452/1000\n",
            "44/44 [==============================] - 0s 835us/step - loss: 0.0653 - acc: 1.0000 - val_loss: 0.1103 - val_acc: 1.0000\n",
            "Epoch 453/1000\n",
            "44/44 [==============================] - 0s 711us/step - loss: 0.0650 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 1.0000\n",
            "Epoch 454/1000\n",
            "44/44 [==============================] - 0s 770us/step - loss: 0.0647 - acc: 1.0000 - val_loss: 0.1085 - val_acc: 1.0000\n",
            "Epoch 455/1000\n",
            "44/44 [==============================] - 0s 932us/step - loss: 0.0645 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 1.0000\n",
            "Epoch 456/1000\n",
            "44/44 [==============================] - 0s 954us/step - loss: 0.0642 - acc: 1.0000 - val_loss: 0.1092 - val_acc: 1.0000\n",
            "Epoch 457/1000\n",
            "44/44 [==============================] - 0s 780us/step - loss: 0.0639 - acc: 1.0000 - val_loss: 0.1082 - val_acc: 1.0000\n",
            "Epoch 458/1000\n",
            "44/44 [==============================] - 0s 619us/step - loss: 0.0636 - acc: 1.0000 - val_loss: 0.1076 - val_acc: 1.0000\n",
            "Epoch 459/1000\n",
            "44/44 [==============================] - 0s 958us/step - loss: 0.0633 - acc: 1.0000 - val_loss: 0.1072 - val_acc: 1.0000\n",
            "Epoch 460/1000\n",
            "44/44 [==============================] - 0s 788us/step - loss: 0.0631 - acc: 1.0000 - val_loss: 0.1068 - val_acc: 1.0000\n",
            "Epoch 461/1000\n",
            "44/44 [==============================] - 0s 687us/step - loss: 0.0628 - acc: 1.0000 - val_loss: 0.1070 - val_acc: 1.0000\n",
            "Epoch 462/1000\n",
            "44/44 [==============================] - 0s 704us/step - loss: 0.0626 - acc: 1.0000 - val_loss: 0.1060 - val_acc: 1.0000\n",
            "Epoch 463/1000\n",
            "44/44 [==============================] - 0s 825us/step - loss: 0.0623 - acc: 1.0000 - val_loss: 0.1062 - val_acc: 1.0000\n",
            "Epoch 464/1000\n",
            "44/44 [==============================] - 0s 541us/step - loss: 0.0620 - acc: 1.0000 - val_loss: 0.1059 - val_acc: 1.0000\n",
            "Epoch 465/1000\n",
            "44/44 [==============================] - 0s 674us/step - loss: 0.0618 - acc: 1.0000 - val_loss: 0.1045 - val_acc: 1.0000\n",
            "Epoch 466/1000\n",
            "44/44 [==============================] - 0s 763us/step - loss: 0.0615 - acc: 1.0000 - val_loss: 0.1039 - val_acc: 1.0000\n",
            "Epoch 467/1000\n",
            "44/44 [==============================] - 0s 609us/step - loss: 0.0612 - acc: 1.0000 - val_loss: 0.1035 - val_acc: 1.0000\n",
            "Epoch 468/1000\n",
            "44/44 [==============================] - 0s 522us/step - loss: 0.0610 - acc: 1.0000 - val_loss: 0.1038 - val_acc: 1.0000\n",
            "Epoch 469/1000\n",
            "44/44 [==============================] - 0s 552us/step - loss: 0.0607 - acc: 1.0000 - val_loss: 0.1035 - val_acc: 1.0000\n",
            "Epoch 470/1000\n",
            "44/44 [==============================] - 0s 437us/step - loss: 0.0605 - acc: 1.0000 - val_loss: 0.1028 - val_acc: 1.0000\n",
            "Epoch 471/1000\n",
            "44/44 [==============================] - 0s 493us/step - loss: 0.0602 - acc: 1.0000 - val_loss: 0.1022 - val_acc: 1.0000\n",
            "Epoch 472/1000\n",
            "44/44 [==============================] - 0s 684us/step - loss: 0.0600 - acc: 1.0000 - val_loss: 0.1015 - val_acc: 1.0000\n",
            "Epoch 473/1000\n",
            "44/44 [==============================] - 0s 544us/step - loss: 0.0597 - acc: 1.0000 - val_loss: 0.1011 - val_acc: 1.0000\n",
            "Epoch 474/1000\n",
            "44/44 [==============================] - 0s 646us/step - loss: 0.0594 - acc: 1.0000 - val_loss: 0.1009 - val_acc: 1.0000\n",
            "Epoch 475/1000\n",
            "44/44 [==============================] - 0s 596us/step - loss: 0.0592 - acc: 1.0000 - val_loss: 0.1012 - val_acc: 1.0000\n",
            "Epoch 476/1000\n",
            "44/44 [==============================] - 0s 461us/step - loss: 0.0590 - acc: 1.0000 - val_loss: 0.1011 - val_acc: 1.0000\n",
            "Epoch 477/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.0587 - acc: 1.0000 - val_loss: 0.1004 - val_acc: 1.0000\n",
            "Epoch 478/1000\n",
            "44/44 [==============================] - 0s 419us/step - loss: 0.0585 - acc: 1.0000 - val_loss: 0.0997 - val_acc: 1.0000\n",
            "Epoch 479/1000\n",
            "44/44 [==============================] - 0s 488us/step - loss: 0.0582 - acc: 1.0000 - val_loss: 0.0997 - val_acc: 1.0000\n",
            "Epoch 480/1000\n",
            "44/44 [==============================] - 0s 416us/step - loss: 0.0580 - acc: 1.0000 - val_loss: 0.0994 - val_acc: 1.0000\n",
            "Epoch 481/1000\n",
            "44/44 [==============================] - 0s 460us/step - loss: 0.0577 - acc: 1.0000 - val_loss: 0.0990 - val_acc: 1.0000\n",
            "Epoch 482/1000\n",
            "44/44 [==============================] - 0s 550us/step - loss: 0.0575 - acc: 1.0000 - val_loss: 0.0984 - val_acc: 1.0000\n",
            "Epoch 483/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.0573 - acc: 1.0000 - val_loss: 0.0976 - val_acc: 1.0000\n",
            "Epoch 484/1000\n",
            "44/44 [==============================] - 0s 455us/step - loss: 0.0570 - acc: 1.0000 - val_loss: 0.0973 - val_acc: 1.0000\n",
            "Epoch 485/1000\n",
            "44/44 [==============================] - 0s 556us/step - loss: 0.0568 - acc: 1.0000 - val_loss: 0.0973 - val_acc: 1.0000\n",
            "Epoch 486/1000\n",
            "44/44 [==============================] - 0s 527us/step - loss: 0.0566 - acc: 1.0000 - val_loss: 0.0967 - val_acc: 1.0000\n",
            "Epoch 487/1000\n",
            "44/44 [==============================] - 0s 524us/step - loss: 0.0563 - acc: 1.0000 - val_loss: 0.0965 - val_acc: 1.0000\n",
            "Epoch 488/1000\n",
            "44/44 [==============================] - 0s 606us/step - loss: 0.0561 - acc: 1.0000 - val_loss: 0.0966 - val_acc: 1.0000\n",
            "Epoch 489/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.0559 - acc: 1.0000 - val_loss: 0.0957 - val_acc: 1.0000\n",
            "Epoch 490/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0556 - acc: 1.0000 - val_loss: 0.0953 - val_acc: 1.0000\n",
            "Epoch 491/1000\n",
            "44/44 [==============================] - 0s 549us/step - loss: 0.0554 - acc: 1.0000 - val_loss: 0.0948 - val_acc: 1.0000\n",
            "Epoch 492/1000\n",
            "44/44 [==============================] - 0s 497us/step - loss: 0.0552 - acc: 1.0000 - val_loss: 0.0936 - val_acc: 1.0000\n",
            "Epoch 493/1000\n",
            "44/44 [==============================] - 0s 526us/step - loss: 0.0549 - acc: 1.0000 - val_loss: 0.0935 - val_acc: 1.0000\n",
            "Epoch 494/1000\n",
            "44/44 [==============================] - 0s 685us/step - loss: 0.0547 - acc: 1.0000 - val_loss: 0.0939 - val_acc: 1.0000\n",
            "Epoch 495/1000\n",
            "44/44 [==============================] - 0s 536us/step - loss: 0.0545 - acc: 1.0000 - val_loss: 0.0929 - val_acc: 1.0000\n",
            "Epoch 496/1000\n",
            "44/44 [==============================] - 0s 537us/step - loss: 0.0543 - acc: 1.0000 - val_loss: 0.0924 - val_acc: 1.0000\n",
            "Epoch 497/1000\n",
            "44/44 [==============================] - 0s 581us/step - loss: 0.0540 - acc: 1.0000 - val_loss: 0.0928 - val_acc: 1.0000\n",
            "Epoch 498/1000\n",
            "44/44 [==============================] - 0s 587us/step - loss: 0.0538 - acc: 1.0000 - val_loss: 0.0925 - val_acc: 1.0000\n",
            "Epoch 499/1000\n",
            "44/44 [==============================] - 0s 507us/step - loss: 0.0536 - acc: 1.0000 - val_loss: 0.0929 - val_acc: 1.0000\n",
            "Epoch 500/1000\n",
            "44/44 [==============================] - 0s 547us/step - loss: 0.0534 - acc: 1.0000 - val_loss: 0.0918 - val_acc: 1.0000\n",
            "Epoch 501/1000\n",
            "44/44 [==============================] - 0s 535us/step - loss: 0.0532 - acc: 1.0000 - val_loss: 0.0909 - val_acc: 1.0000\n",
            "Epoch 502/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.0529 - acc: 1.0000 - val_loss: 0.0903 - val_acc: 1.0000\n",
            "Epoch 503/1000\n",
            "44/44 [==============================] - 0s 556us/step - loss: 0.0528 - acc: 1.0000 - val_loss: 0.0903 - val_acc: 1.0000\n",
            "Epoch 504/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.0525 - acc: 1.0000 - val_loss: 0.0898 - val_acc: 1.0000\n",
            "Epoch 505/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0523 - acc: 1.0000 - val_loss: 0.0890 - val_acc: 1.0000\n",
            "Epoch 506/1000\n",
            "44/44 [==============================] - 0s 480us/step - loss: 0.0521 - acc: 1.0000 - val_loss: 0.0883 - val_acc: 1.0000\n",
            "Epoch 507/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.0519 - acc: 1.0000 - val_loss: 0.0883 - val_acc: 1.0000\n",
            "Epoch 508/1000\n",
            "44/44 [==============================] - 0s 519us/step - loss: 0.0517 - acc: 1.0000 - val_loss: 0.0885 - val_acc: 1.0000\n",
            "Epoch 509/1000\n",
            "44/44 [==============================] - 0s 584us/step - loss: 0.0515 - acc: 1.0000 - val_loss: 0.0877 - val_acc: 1.0000\n",
            "Epoch 510/1000\n",
            "44/44 [==============================] - 0s 576us/step - loss: 0.0512 - acc: 1.0000 - val_loss: 0.0874 - val_acc: 1.0000\n",
            "Epoch 511/1000\n",
            "44/44 [==============================] - 0s 674us/step - loss: 0.0511 - acc: 1.0000 - val_loss: 0.0865 - val_acc: 1.0000\n",
            "Epoch 512/1000\n",
            "44/44 [==============================] - 0s 574us/step - loss: 0.0508 - acc: 1.0000 - val_loss: 0.0861 - val_acc: 1.0000\n",
            "Epoch 513/1000\n",
            "44/44 [==============================] - 0s 676us/step - loss: 0.0506 - acc: 1.0000 - val_loss: 0.0861 - val_acc: 1.0000\n",
            "Epoch 514/1000\n",
            "44/44 [==============================] - 0s 475us/step - loss: 0.0504 - acc: 1.0000 - val_loss: 0.0862 - val_acc: 1.0000\n",
            "Epoch 515/1000\n",
            "44/44 [==============================] - 0s 546us/step - loss: 0.0502 - acc: 1.0000 - val_loss: 0.0863 - val_acc: 1.0000\n",
            "Epoch 516/1000\n",
            "44/44 [==============================] - 0s 573us/step - loss: 0.0500 - acc: 1.0000 - val_loss: 0.0856 - val_acc: 1.0000\n",
            "Epoch 517/1000\n",
            "44/44 [==============================] - 0s 514us/step - loss: 0.0498 - acc: 1.0000 - val_loss: 0.0854 - val_acc: 1.0000\n",
            "Epoch 518/1000\n",
            "44/44 [==============================] - 0s 462us/step - loss: 0.0496 - acc: 1.0000 - val_loss: 0.0849 - val_acc: 1.0000\n",
            "Epoch 519/1000\n",
            "44/44 [==============================] - 0s 508us/step - loss: 0.0494 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 1.0000\n",
            "Epoch 520/1000\n",
            "44/44 [==============================] - 0s 498us/step - loss: 0.0492 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 1.0000\n",
            "Epoch 521/1000\n",
            "44/44 [==============================] - 0s 775us/step - loss: 0.0490 - acc: 1.0000 - val_loss: 0.0835 - val_acc: 1.0000\n",
            "Epoch 522/1000\n",
            "44/44 [==============================] - 0s 476us/step - loss: 0.0488 - acc: 1.0000 - val_loss: 0.0836 - val_acc: 1.0000\n",
            "Epoch 523/1000\n",
            "44/44 [==============================] - 0s 461us/step - loss: 0.0486 - acc: 1.0000 - val_loss: 0.0836 - val_acc: 1.0000\n",
            "Epoch 524/1000\n",
            "44/44 [==============================] - 0s 602us/step - loss: 0.0484 - acc: 1.0000 - val_loss: 0.0834 - val_acc: 1.0000\n",
            "Epoch 525/1000\n",
            "44/44 [==============================] - 0s 479us/step - loss: 0.0482 - acc: 1.0000 - val_loss: 0.0834 - val_acc: 1.0000\n",
            "Epoch 526/1000\n",
            "44/44 [==============================] - 0s 486us/step - loss: 0.0481 - acc: 1.0000 - val_loss: 0.0830 - val_acc: 1.0000\n",
            "Epoch 527/1000\n",
            "44/44 [==============================] - 0s 622us/step - loss: 0.0479 - acc: 1.0000 - val_loss: 0.0828 - val_acc: 1.0000\n",
            "Epoch 528/1000\n",
            "44/44 [==============================] - 0s 491us/step - loss: 0.0477 - acc: 1.0000 - val_loss: 0.0820 - val_acc: 1.0000\n",
            "Epoch 529/1000\n",
            "44/44 [==============================] - 0s 615us/step - loss: 0.0475 - acc: 1.0000 - val_loss: 0.0822 - val_acc: 1.0000\n",
            "Epoch 530/1000\n",
            "44/44 [==============================] - 0s 551us/step - loss: 0.0473 - acc: 1.0000 - val_loss: 0.0813 - val_acc: 1.0000\n",
            "Epoch 531/1000\n",
            "44/44 [==============================] - 0s 564us/step - loss: 0.0471 - acc: 1.0000 - val_loss: 0.0813 - val_acc: 1.0000\n",
            "Epoch 532/1000\n",
            "44/44 [==============================] - 0s 462us/step - loss: 0.0469 - acc: 1.0000 - val_loss: 0.0808 - val_acc: 1.0000\n",
            "Epoch 533/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0468 - acc: 1.0000 - val_loss: 0.0809 - val_acc: 1.0000\n",
            "Epoch 534/1000\n",
            "44/44 [==============================] - 0s 681us/step - loss: 0.0465 - acc: 1.0000 - val_loss: 0.0801 - val_acc: 1.0000\n",
            "Epoch 535/1000\n",
            "44/44 [==============================] - 0s 705us/step - loss: 0.0464 - acc: 1.0000 - val_loss: 0.0794 - val_acc: 1.0000\n",
            "Epoch 536/1000\n",
            "44/44 [==============================] - 0s 693us/step - loss: 0.0462 - acc: 1.0000 - val_loss: 0.0790 - val_acc: 1.0000\n",
            "Epoch 537/1000\n",
            "44/44 [==============================] - 0s 506us/step - loss: 0.0460 - acc: 1.0000 - val_loss: 0.0788 - val_acc: 1.0000\n",
            "Epoch 538/1000\n",
            "44/44 [==============================] - 0s 530us/step - loss: 0.0458 - acc: 1.0000 - val_loss: 0.0787 - val_acc: 1.0000\n",
            "Epoch 539/1000\n",
            "44/44 [==============================] - 0s 592us/step - loss: 0.0456 - acc: 1.0000 - val_loss: 0.0784 - val_acc: 1.0000\n",
            "Epoch 540/1000\n",
            "44/44 [==============================] - 0s 528us/step - loss: 0.0455 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 1.0000\n",
            "Epoch 541/1000\n",
            "44/44 [==============================] - 0s 470us/step - loss: 0.0453 - acc: 1.0000 - val_loss: 0.0778 - val_acc: 1.0000\n",
            "Epoch 542/1000\n",
            "44/44 [==============================] - 0s 468us/step - loss: 0.0451 - acc: 1.0000 - val_loss: 0.0776 - val_acc: 1.0000\n",
            "Epoch 543/1000\n",
            "44/44 [==============================] - 0s 455us/step - loss: 0.0450 - acc: 1.0000 - val_loss: 0.0778 - val_acc: 1.0000\n",
            "Epoch 544/1000\n",
            "44/44 [==============================] - 0s 683us/step - loss: 0.0448 - acc: 1.0000 - val_loss: 0.0773 - val_acc: 1.0000\n",
            "Epoch 545/1000\n",
            "44/44 [==============================] - 0s 481us/step - loss: 0.0446 - acc: 1.0000 - val_loss: 0.0770 - val_acc: 1.0000\n",
            "Epoch 546/1000\n",
            "44/44 [==============================] - 0s 678us/step - loss: 0.0444 - acc: 1.0000 - val_loss: 0.0767 - val_acc: 1.0000\n",
            "Epoch 547/1000\n",
            "44/44 [==============================] - 0s 496us/step - loss: 0.0443 - acc: 1.0000 - val_loss: 0.0763 - val_acc: 1.0000\n",
            "Epoch 548/1000\n",
            "44/44 [==============================] - 0s 475us/step - loss: 0.0441 - acc: 1.0000 - val_loss: 0.0762 - val_acc: 1.0000\n",
            "Epoch 549/1000\n",
            "44/44 [==============================] - 0s 463us/step - loss: 0.0439 - acc: 1.0000 - val_loss: 0.0766 - val_acc: 1.0000\n",
            "Epoch 550/1000\n",
            "44/44 [==============================] - 0s 437us/step - loss: 0.0437 - acc: 1.0000 - val_loss: 0.0764 - val_acc: 1.0000\n",
            "Epoch 551/1000\n",
            "44/44 [==============================] - 0s 436us/step - loss: 0.0436 - acc: 1.0000 - val_loss: 0.0760 - val_acc: 1.0000\n",
            "Epoch 552/1000\n",
            "44/44 [==============================] - 0s 505us/step - loss: 0.0434 - acc: 1.0000 - val_loss: 0.0754 - val_acc: 1.0000\n",
            "Epoch 553/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.0433 - acc: 1.0000 - val_loss: 0.0743 - val_acc: 1.0000\n",
            "Epoch 554/1000\n",
            "44/44 [==============================] - 0s 447us/step - loss: 0.0431 - acc: 1.0000 - val_loss: 0.0745 - val_acc: 1.0000\n",
            "Epoch 555/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.0429 - acc: 1.0000 - val_loss: 0.0742 - val_acc: 1.0000\n",
            "Epoch 556/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0428 - acc: 1.0000 - val_loss: 0.0743 - val_acc: 1.0000\n",
            "Epoch 557/1000\n",
            "44/44 [==============================] - 0s 503us/step - loss: 0.0426 - acc: 1.0000 - val_loss: 0.0738 - val_acc: 1.0000\n",
            "Epoch 558/1000\n",
            "44/44 [==============================] - 0s 423us/step - loss: 0.0424 - acc: 1.0000 - val_loss: 0.0729 - val_acc: 1.0000\n",
            "Epoch 559/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0423 - acc: 1.0000 - val_loss: 0.0726 - val_acc: 1.0000\n",
            "Epoch 560/1000\n",
            "44/44 [==============================] - 0s 575us/step - loss: 0.0421 - acc: 1.0000 - val_loss: 0.0729 - val_acc: 1.0000\n",
            "Epoch 561/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.0420 - acc: 1.0000 - val_loss: 0.0735 - val_acc: 1.0000\n",
            "Epoch 562/1000\n",
            "44/44 [==============================] - 0s 484us/step - loss: 0.0418 - acc: 1.0000 - val_loss: 0.0733 - val_acc: 1.0000\n",
            "Epoch 563/1000\n",
            "44/44 [==============================] - 0s 555us/step - loss: 0.0416 - acc: 1.0000 - val_loss: 0.0724 - val_acc: 1.0000\n",
            "Epoch 564/1000\n",
            "44/44 [==============================] - 0s 502us/step - loss: 0.0414 - acc: 1.0000 - val_loss: 0.0720 - val_acc: 1.0000\n",
            "Epoch 565/1000\n",
            "44/44 [==============================] - 0s 572us/step - loss: 0.0413 - acc: 1.0000 - val_loss: 0.0719 - val_acc: 1.0000\n",
            "Epoch 566/1000\n",
            "44/44 [==============================] - 0s 488us/step - loss: 0.0411 - acc: 1.0000 - val_loss: 0.0716 - val_acc: 1.0000\n",
            "Epoch 567/1000\n",
            "44/44 [==============================] - 0s 513us/step - loss: 0.0410 - acc: 1.0000 - val_loss: 0.0717 - val_acc: 1.0000\n",
            "Epoch 568/1000\n",
            "44/44 [==============================] - 0s 612us/step - loss: 0.0408 - acc: 1.0000 - val_loss: 0.0710 - val_acc: 1.0000\n",
            "Epoch 569/1000\n",
            "44/44 [==============================] - 0s 480us/step - loss: 0.0407 - acc: 1.0000 - val_loss: 0.0705 - val_acc: 1.0000\n",
            "Epoch 570/1000\n",
            "44/44 [==============================] - 0s 475us/step - loss: 0.0405 - acc: 1.0000 - val_loss: 0.0704 - val_acc: 1.0000\n",
            "Epoch 571/1000\n",
            "44/44 [==============================] - 0s 587us/step - loss: 0.0403 - acc: 1.0000 - val_loss: 0.0702 - val_acc: 1.0000\n",
            "Epoch 572/1000\n",
            "44/44 [==============================] - 0s 444us/step - loss: 0.0402 - acc: 1.0000 - val_loss: 0.0702 - val_acc: 1.0000\n",
            "Epoch 573/1000\n",
            "44/44 [==============================] - 0s 480us/step - loss: 0.0400 - acc: 1.0000 - val_loss: 0.0697 - val_acc: 1.0000\n",
            "Epoch 574/1000\n",
            "44/44 [==============================] - 0s 484us/step - loss: 0.0399 - acc: 1.0000 - val_loss: 0.0694 - val_acc: 1.0000\n",
            "Epoch 575/1000\n",
            "44/44 [==============================] - 0s 419us/step - loss: 0.0397 - acc: 1.0000 - val_loss: 0.0693 - val_acc: 1.0000\n",
            "Epoch 576/1000\n",
            "44/44 [==============================] - 0s 452us/step - loss: 0.0396 - acc: 1.0000 - val_loss: 0.0690 - val_acc: 1.0000\n",
            "Epoch 577/1000\n",
            "44/44 [==============================] - 0s 499us/step - loss: 0.0394 - acc: 1.0000 - val_loss: 0.0688 - val_acc: 1.0000\n",
            "Epoch 578/1000\n",
            "44/44 [==============================] - 0s 482us/step - loss: 0.0393 - acc: 1.0000 - val_loss: 0.0685 - val_acc: 1.0000\n",
            "Epoch 579/1000\n",
            "44/44 [==============================] - 0s 484us/step - loss: 0.0391 - acc: 1.0000 - val_loss: 0.0678 - val_acc: 1.0000\n",
            "Epoch 580/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.0390 - acc: 1.0000 - val_loss: 0.0677 - val_acc: 1.0000\n",
            "Epoch 581/1000\n",
            "44/44 [==============================] - 0s 456us/step - loss: 0.0388 - acc: 1.0000 - val_loss: 0.0672 - val_acc: 1.0000\n",
            "Epoch 582/1000\n",
            "44/44 [==============================] - 0s 682us/step - loss: 0.0387 - acc: 1.0000 - val_loss: 0.0672 - val_acc: 1.0000\n",
            "Epoch 583/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.0385 - acc: 1.0000 - val_loss: 0.0673 - val_acc: 1.0000\n",
            "Epoch 584/1000\n",
            "44/44 [==============================] - 0s 480us/step - loss: 0.0384 - acc: 1.0000 - val_loss: 0.0673 - val_acc: 1.0000\n",
            "Epoch 585/1000\n",
            "44/44 [==============================] - 0s 483us/step - loss: 0.0383 - acc: 1.0000 - val_loss: 0.0673 - val_acc: 1.0000\n",
            "Epoch 586/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0381 - acc: 1.0000 - val_loss: 0.0669 - val_acc: 1.0000\n",
            "Epoch 587/1000\n",
            "44/44 [==============================] - 0s 421us/step - loss: 0.0380 - acc: 1.0000 - val_loss: 0.0669 - val_acc: 1.0000\n",
            "Epoch 588/1000\n",
            "44/44 [==============================] - 0s 518us/step - loss: 0.0378 - acc: 1.0000 - val_loss: 0.0660 - val_acc: 1.0000\n",
            "Epoch 589/1000\n",
            "44/44 [==============================] - 0s 427us/step - loss: 0.0377 - acc: 1.0000 - val_loss: 0.0657 - val_acc: 1.0000\n",
            "Epoch 590/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0375 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 1.0000\n",
            "Epoch 591/1000\n",
            "44/44 [==============================] - 0s 514us/step - loss: 0.0374 - acc: 1.0000 - val_loss: 0.0651 - val_acc: 1.0000\n",
            "Epoch 592/1000\n",
            "44/44 [==============================] - 0s 407us/step - loss: 0.0373 - acc: 1.0000 - val_loss: 0.0646 - val_acc: 1.0000\n",
            "Epoch 593/1000\n",
            "44/44 [==============================] - 0s 401us/step - loss: 0.0371 - acc: 1.0000 - val_loss: 0.0642 - val_acc: 1.0000\n",
            "Epoch 594/1000\n",
            "44/44 [==============================] - 0s 467us/step - loss: 0.0370 - acc: 1.0000 - val_loss: 0.0641 - val_acc: 1.0000\n",
            "Epoch 595/1000\n",
            "44/44 [==============================] - 0s 414us/step - loss: 0.0368 - acc: 1.0000 - val_loss: 0.0643 - val_acc: 1.0000\n",
            "Epoch 596/1000\n",
            "44/44 [==============================] - 0s 432us/step - loss: 0.0367 - acc: 1.0000 - val_loss: 0.0639 - val_acc: 1.0000\n",
            "Epoch 597/1000\n",
            "44/44 [==============================] - 0s 461us/step - loss: 0.0366 - acc: 1.0000 - val_loss: 0.0638 - val_acc: 1.0000\n",
            "Epoch 598/1000\n",
            "44/44 [==============================] - 0s 460us/step - loss: 0.0364 - acc: 1.0000 - val_loss: 0.0635 - val_acc: 1.0000\n",
            "Epoch 599/1000\n",
            "44/44 [==============================] - 0s 657us/step - loss: 0.0363 - acc: 1.0000 - val_loss: 0.0635 - val_acc: 1.0000\n",
            "Epoch 600/1000\n",
            "44/44 [==============================] - 0s 650us/step - loss: 0.0362 - acc: 1.0000 - val_loss: 0.0632 - val_acc: 1.0000\n",
            "Epoch 601/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.0360 - acc: 1.0000 - val_loss: 0.0626 - val_acc: 1.0000\n",
            "Epoch 602/1000\n",
            "44/44 [==============================] - 0s 751us/step - loss: 0.0359 - acc: 1.0000 - val_loss: 0.0624 - val_acc: 1.0000\n",
            "Epoch 603/1000\n",
            "44/44 [==============================] - 0s 724us/step - loss: 0.0358 - acc: 1.0000 - val_loss: 0.0625 - val_acc: 1.0000\n",
            "Epoch 604/1000\n",
            "44/44 [==============================] - 0s 723us/step - loss: 0.0356 - acc: 1.0000 - val_loss: 0.0620 - val_acc: 1.0000\n",
            "Epoch 605/1000\n",
            "44/44 [==============================] - 0s 607us/step - loss: 0.0355 - acc: 1.0000 - val_loss: 0.0620 - val_acc: 1.0000\n",
            "Epoch 606/1000\n",
            "44/44 [==============================] - 0s 683us/step - loss: 0.0353 - acc: 1.0000 - val_loss: 0.0620 - val_acc: 1.0000\n",
            "Epoch 607/1000\n",
            "44/44 [==============================] - 0s 583us/step - loss: 0.0352 - acc: 1.0000 - val_loss: 0.0619 - val_acc: 1.0000\n",
            "Epoch 608/1000\n",
            "44/44 [==============================] - 0s 645us/step - loss: 0.0351 - acc: 1.0000 - val_loss: 0.0615 - val_acc: 1.0000\n",
            "Epoch 609/1000\n",
            "44/44 [==============================] - 0s 873us/step - loss: 0.0349 - acc: 1.0000 - val_loss: 0.0609 - val_acc: 1.0000\n",
            "Epoch 610/1000\n",
            "44/44 [==============================] - 0s 758us/step - loss: 0.0349 - acc: 1.0000 - val_loss: 0.0600 - val_acc: 1.0000\n",
            "Epoch 611/1000\n",
            "44/44 [==============================] - 0s 801us/step - loss: 0.0347 - acc: 1.0000 - val_loss: 0.0598 - val_acc: 1.0000\n",
            "Epoch 612/1000\n",
            "44/44 [==============================] - 0s 953us/step - loss: 0.0346 - acc: 1.0000 - val_loss: 0.0596 - val_acc: 1.0000\n",
            "Epoch 613/1000\n",
            "44/44 [==============================] - 0s 757us/step - loss: 0.0344 - acc: 1.0000 - val_loss: 0.0597 - val_acc: 1.0000\n",
            "Epoch 614/1000\n",
            "44/44 [==============================] - 0s 718us/step - loss: 0.0343 - acc: 1.0000 - val_loss: 0.0593 - val_acc: 1.0000\n",
            "Epoch 615/1000\n",
            "44/44 [==============================] - 0s 916us/step - loss: 0.0342 - acc: 1.0000 - val_loss: 0.0593 - val_acc: 1.0000\n",
            "Epoch 616/1000\n",
            "44/44 [==============================] - 0s 942us/step - loss: 0.0341 - acc: 1.0000 - val_loss: 0.0590 - val_acc: 1.0000\n",
            "Epoch 617/1000\n",
            "44/44 [==============================] - 0s 620us/step - loss: 0.0339 - acc: 1.0000 - val_loss: 0.0591 - val_acc: 1.0000\n",
            "Epoch 618/1000\n",
            "44/44 [==============================] - 0s 659us/step - loss: 0.0338 - acc: 1.0000 - val_loss: 0.0592 - val_acc: 1.0000\n",
            "Epoch 619/1000\n",
            "44/44 [==============================] - 0s 597us/step - loss: 0.0337 - acc: 1.0000 - val_loss: 0.0588 - val_acc: 1.0000\n",
            "Epoch 620/1000\n",
            "44/44 [==============================] - 0s 650us/step - loss: 0.0336 - acc: 1.0000 - val_loss: 0.0586 - val_acc: 1.0000\n",
            "Epoch 621/1000\n",
            "44/44 [==============================] - 0s 583us/step - loss: 0.0334 - acc: 1.0000 - val_loss: 0.0584 - val_acc: 1.0000\n",
            "Epoch 622/1000\n",
            "44/44 [==============================] - 0s 608us/step - loss: 0.0333 - acc: 1.0000 - val_loss: 0.0582 - val_acc: 1.0000\n",
            "Epoch 623/1000\n",
            "44/44 [==============================] - 0s 635us/step - loss: 0.0332 - acc: 1.0000 - val_loss: 0.0583 - val_acc: 1.0000\n",
            "Epoch 624/1000\n",
            "44/44 [==============================] - 0s 728us/step - loss: 0.0331 - acc: 1.0000 - val_loss: 0.0580 - val_acc: 1.0000\n",
            "Epoch 625/1000\n",
            "44/44 [==============================] - 0s 626us/step - loss: 0.0329 - acc: 1.0000 - val_loss: 0.0577 - val_acc: 1.0000\n",
            "Epoch 626/1000\n",
            "44/44 [==============================] - 0s 690us/step - loss: 0.0328 - acc: 1.0000 - val_loss: 0.0574 - val_acc: 1.0000\n",
            "Epoch 627/1000\n",
            "44/44 [==============================] - 0s 788us/step - loss: 0.0327 - acc: 1.0000 - val_loss: 0.0574 - val_acc: 1.0000\n",
            "Epoch 628/1000\n",
            "44/44 [==============================] - 0s 635us/step - loss: 0.0326 - acc: 1.0000 - val_loss: 0.0568 - val_acc: 1.0000\n",
            "Epoch 629/1000\n",
            "44/44 [==============================] - 0s 751us/step - loss: 0.0325 - acc: 1.0000 - val_loss: 0.0567 - val_acc: 1.0000\n",
            "Epoch 630/1000\n",
            "44/44 [==============================] - 0s 436us/step - loss: 0.0323 - acc: 1.0000 - val_loss: 0.0565 - val_acc: 1.0000\n",
            "Epoch 631/1000\n",
            "44/44 [==============================] - 0s 569us/step - loss: 0.0322 - acc: 1.0000 - val_loss: 0.0563 - val_acc: 1.0000\n",
            "Epoch 632/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.0321 - acc: 1.0000 - val_loss: 0.0559 - val_acc: 1.0000\n",
            "Epoch 633/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.0320 - acc: 1.0000 - val_loss: 0.0556 - val_acc: 1.0000\n",
            "Epoch 634/1000\n",
            "44/44 [==============================] - 0s 523us/step - loss: 0.0319 - acc: 1.0000 - val_loss: 0.0554 - val_acc: 1.0000\n",
            "Epoch 635/1000\n",
            "44/44 [==============================] - 0s 440us/step - loss: 0.0317 - acc: 1.0000 - val_loss: 0.0556 - val_acc: 1.0000\n",
            "Epoch 636/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.0316 - acc: 1.0000 - val_loss: 0.0558 - val_acc: 1.0000\n",
            "Epoch 637/1000\n",
            "44/44 [==============================] - 0s 523us/step - loss: 0.0315 - acc: 1.0000 - val_loss: 0.0555 - val_acc: 1.0000\n",
            "Epoch 638/1000\n",
            "44/44 [==============================] - 0s 480us/step - loss: 0.0314 - acc: 1.0000 - val_loss: 0.0550 - val_acc: 1.0000\n",
            "Epoch 639/1000\n",
            "44/44 [==============================] - 0s 433us/step - loss: 0.0313 - acc: 1.0000 - val_loss: 0.0546 - val_acc: 1.0000\n",
            "Epoch 640/1000\n",
            "44/44 [==============================] - 0s 493us/step - loss: 0.0312 - acc: 1.0000 - val_loss: 0.0547 - val_acc: 1.0000\n",
            "Epoch 641/1000\n",
            "44/44 [==============================] - 0s 399us/step - loss: 0.0311 - acc: 1.0000 - val_loss: 0.0542 - val_acc: 1.0000\n",
            "Epoch 642/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0309 - acc: 1.0000 - val_loss: 0.0542 - val_acc: 1.0000\n",
            "Epoch 643/1000\n",
            "44/44 [==============================] - 0s 527us/step - loss: 0.0308 - acc: 1.0000 - val_loss: 0.0541 - val_acc: 1.0000\n",
            "Epoch 644/1000\n",
            "44/44 [==============================] - 0s 447us/step - loss: 0.0307 - acc: 1.0000 - val_loss: 0.0540 - val_acc: 1.0000\n",
            "Epoch 645/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.0306 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 1.0000\n",
            "Epoch 646/1000\n",
            "44/44 [==============================] - 0s 492us/step - loss: 0.0305 - acc: 1.0000 - val_loss: 0.0532 - val_acc: 1.0000\n",
            "Epoch 647/1000\n",
            "44/44 [==============================] - 0s 433us/step - loss: 0.0304 - acc: 1.0000 - val_loss: 0.0532 - val_acc: 1.0000\n",
            "Epoch 648/1000\n",
            "44/44 [==============================] - 0s 462us/step - loss: 0.0303 - acc: 1.0000 - val_loss: 0.0529 - val_acc: 1.0000\n",
            "Epoch 649/1000\n",
            "44/44 [==============================] - 0s 424us/step - loss: 0.0302 - acc: 1.0000 - val_loss: 0.0530 - val_acc: 1.0000\n",
            "Epoch 650/1000\n",
            "44/44 [==============================] - 0s 458us/step - loss: 0.0301 - acc: 1.0000 - val_loss: 0.0531 - val_acc: 1.0000\n",
            "Epoch 651/1000\n",
            "44/44 [==============================] - 0s 554us/step - loss: 0.0300 - acc: 1.0000 - val_loss: 0.0523 - val_acc: 1.0000\n",
            "Epoch 652/1000\n",
            "44/44 [==============================] - 0s 415us/step - loss: 0.0299 - acc: 1.0000 - val_loss: 0.0519 - val_acc: 1.0000\n",
            "Epoch 653/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0297 - acc: 1.0000 - val_loss: 0.0521 - val_acc: 1.0000\n",
            "Epoch 654/1000\n",
            "44/44 [==============================] - 0s 505us/step - loss: 0.0296 - acc: 1.0000 - val_loss: 0.0521 - val_acc: 1.0000\n",
            "Epoch 655/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.0295 - acc: 1.0000 - val_loss: 0.0521 - val_acc: 1.0000\n",
            "Epoch 656/1000\n",
            "44/44 [==============================] - 0s 428us/step - loss: 0.0294 - acc: 1.0000 - val_loss: 0.0516 - val_acc: 1.0000\n",
            "Epoch 657/1000\n",
            "44/44 [==============================] - 0s 557us/step - loss: 0.0293 - acc: 1.0000 - val_loss: 0.0516 - val_acc: 1.0000\n",
            "Epoch 658/1000\n",
            "44/44 [==============================] - 0s 419us/step - loss: 0.0292 - acc: 1.0000 - val_loss: 0.0517 - val_acc: 1.0000\n",
            "Epoch 659/1000\n",
            "44/44 [==============================] - 0s 443us/step - loss: 0.0291 - acc: 1.0000 - val_loss: 0.0512 - val_acc: 1.0000\n",
            "Epoch 660/1000\n",
            "44/44 [==============================] - 0s 623us/step - loss: 0.0290 - acc: 1.0000 - val_loss: 0.0507 - val_acc: 1.0000\n",
            "Epoch 661/1000\n",
            "44/44 [==============================] - 0s 417us/step - loss: 0.0289 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 1.0000\n",
            "Epoch 662/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.0288 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 1.0000\n",
            "Epoch 663/1000\n",
            "44/44 [==============================] - 0s 530us/step - loss: 0.0287 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 1.0000\n",
            "Epoch 664/1000\n",
            "44/44 [==============================] - 0s 505us/step - loss: 0.0286 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 1.0000\n",
            "Epoch 665/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.0285 - acc: 1.0000 - val_loss: 0.0502 - val_acc: 1.0000\n",
            "Epoch 666/1000\n",
            "44/44 [==============================] - 0s 495us/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.0500 - val_acc: 1.0000\n",
            "Epoch 667/1000\n",
            "44/44 [==============================] - 0s 449us/step - loss: 0.0283 - acc: 1.0000 - val_loss: 0.0498 - val_acc: 1.0000\n",
            "Epoch 668/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0282 - acc: 1.0000 - val_loss: 0.0490 - val_acc: 1.0000\n",
            "Epoch 669/1000\n",
            "44/44 [==============================] - 0s 571us/step - loss: 0.0281 - acc: 1.0000 - val_loss: 0.0489 - val_acc: 1.0000\n",
            "Epoch 670/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0280 - acc: 1.0000 - val_loss: 0.0486 - val_acc: 1.0000\n",
            "Epoch 671/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.0279 - acc: 1.0000 - val_loss: 0.0487 - val_acc: 1.0000\n",
            "Epoch 672/1000\n",
            "44/44 [==============================] - 0s 543us/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.0485 - val_acc: 1.0000\n",
            "Epoch 673/1000\n",
            "44/44 [==============================] - 0s 443us/step - loss: 0.0277 - acc: 1.0000 - val_loss: 0.0485 - val_acc: 1.0000\n",
            "Epoch 674/1000\n",
            "44/44 [==============================] - 0s 452us/step - loss: 0.0276 - acc: 1.0000 - val_loss: 0.0483 - val_acc: 1.0000\n",
            "Epoch 675/1000\n",
            "44/44 [==============================] - 0s 428us/step - loss: 0.0275 - acc: 1.0000 - val_loss: 0.0479 - val_acc: 1.0000\n",
            "Epoch 676/1000\n",
            "44/44 [==============================] - 0s 403us/step - loss: 0.0274 - acc: 1.0000 - val_loss: 0.0479 - val_acc: 1.0000\n",
            "Epoch 677/1000\n",
            "44/44 [==============================] - 0s 456us/step - loss: 0.0273 - acc: 1.0000 - val_loss: 0.0477 - val_acc: 1.0000\n",
            "Epoch 678/1000\n",
            "44/44 [==============================] - 0s 420us/step - loss: 0.0272 - acc: 1.0000 - val_loss: 0.0474 - val_acc: 1.0000\n",
            "Epoch 679/1000\n",
            "44/44 [==============================] - 0s 416us/step - loss: 0.0271 - acc: 1.0000 - val_loss: 0.0468 - val_acc: 1.0000\n",
            "Epoch 680/1000\n",
            "44/44 [==============================] - 0s 427us/step - loss: 0.0270 - acc: 1.0000 - val_loss: 0.0467 - val_acc: 1.0000\n",
            "Epoch 681/1000\n",
            "44/44 [==============================] - 0s 486us/step - loss: 0.0269 - acc: 1.0000 - val_loss: 0.0467 - val_acc: 1.0000\n",
            "Epoch 682/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.0268 - acc: 1.0000 - val_loss: 0.0468 - val_acc: 1.0000\n",
            "Epoch 683/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.0469 - val_acc: 1.0000\n",
            "Epoch 684/1000\n",
            "44/44 [==============================] - 0s 424us/step - loss: 0.0266 - acc: 1.0000 - val_loss: 0.0471 - val_acc: 1.0000\n",
            "Epoch 685/1000\n",
            "44/44 [==============================] - 0s 395us/step - loss: 0.0265 - acc: 1.0000 - val_loss: 0.0465 - val_acc: 1.0000\n",
            "Epoch 686/1000\n",
            "44/44 [==============================] - 0s 485us/step - loss: 0.0264 - acc: 1.0000 - val_loss: 0.0460 - val_acc: 1.0000\n",
            "Epoch 687/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.0263 - acc: 1.0000 - val_loss: 0.0459 - val_acc: 1.0000\n",
            "Epoch 688/1000\n",
            "44/44 [==============================] - 0s 412us/step - loss: 0.0263 - acc: 1.0000 - val_loss: 0.0460 - val_acc: 1.0000\n",
            "Epoch 689/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.0261 - acc: 1.0000 - val_loss: 0.0457 - val_acc: 1.0000\n",
            "Epoch 690/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0260 - acc: 1.0000 - val_loss: 0.0456 - val_acc: 1.0000\n",
            "Epoch 691/1000\n",
            "44/44 [==============================] - 0s 425us/step - loss: 0.0260 - acc: 1.0000 - val_loss: 0.0457 - val_acc: 1.0000\n",
            "Epoch 692/1000\n",
            "44/44 [==============================] - 0s 501us/step - loss: 0.0259 - acc: 1.0000 - val_loss: 0.0456 - val_acc: 1.0000\n",
            "Epoch 693/1000\n",
            "44/44 [==============================] - 0s 469us/step - loss: 0.0258 - acc: 1.0000 - val_loss: 0.0456 - val_acc: 1.0000\n",
            "Epoch 694/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.0453 - val_acc: 1.0000\n",
            "Epoch 695/1000\n",
            "44/44 [==============================] - 0s 497us/step - loss: 0.0256 - acc: 1.0000 - val_loss: 0.0448 - val_acc: 1.0000\n",
            "Epoch 696/1000\n",
            "44/44 [==============================] - 0s 444us/step - loss: 0.0255 - acc: 1.0000 - val_loss: 0.0446 - val_acc: 1.0000\n",
            "Epoch 697/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.0254 - acc: 1.0000 - val_loss: 0.0445 - val_acc: 1.0000\n",
            "Epoch 698/1000\n",
            "44/44 [==============================] - 0s 553us/step - loss: 0.0253 - acc: 1.0000 - val_loss: 0.0447 - val_acc: 1.0000\n",
            "Epoch 699/1000\n",
            "44/44 [==============================] - 0s 402us/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.0443 - val_acc: 1.0000\n",
            "Epoch 700/1000\n",
            "44/44 [==============================] - 0s 508us/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 1.0000\n",
            "Epoch 701/1000\n",
            "44/44 [==============================] - 0s 606us/step - loss: 0.0251 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 1.0000\n",
            "Epoch 702/1000\n",
            "44/44 [==============================] - 0s 442us/step - loss: 0.0250 - acc: 1.0000 - val_loss: 0.0440 - val_acc: 1.0000\n",
            "Epoch 703/1000\n",
            "44/44 [==============================] - 0s 449us/step - loss: 0.0249 - acc: 1.0000 - val_loss: 0.0433 - val_acc: 1.0000\n",
            "Epoch 704/1000\n",
            "44/44 [==============================] - 0s 541us/step - loss: 0.0248 - acc: 1.0000 - val_loss: 0.0428 - val_acc: 1.0000\n",
            "Epoch 705/1000\n",
            "44/44 [==============================] - 0s 467us/step - loss: 0.0247 - acc: 1.0000 - val_loss: 0.0428 - val_acc: 1.0000\n",
            "Epoch 706/1000\n",
            "44/44 [==============================] - 0s 424us/step - loss: 0.0246 - acc: 1.0000 - val_loss: 0.0427 - val_acc: 1.0000\n",
            "Epoch 707/1000\n",
            "44/44 [==============================] - 0s 516us/step - loss: 0.0246 - acc: 1.0000 - val_loss: 0.0423 - val_acc: 1.0000\n",
            "Epoch 708/1000\n",
            "44/44 [==============================] - 0s 440us/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.0423 - val_acc: 1.0000\n",
            "Epoch 709/1000\n",
            "44/44 [==============================] - 0s 465us/step - loss: 0.0244 - acc: 1.0000 - val_loss: 0.0420 - val_acc: 1.0000\n",
            "Epoch 710/1000\n",
            "44/44 [==============================] - 0s 447us/step - loss: 0.0243 - acc: 1.0000 - val_loss: 0.0420 - val_acc: 1.0000\n",
            "Epoch 711/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.0242 - acc: 1.0000 - val_loss: 0.0419 - val_acc: 1.0000\n",
            "Epoch 712/1000\n",
            "44/44 [==============================] - 0s 451us/step - loss: 0.0241 - acc: 1.0000 - val_loss: 0.0418 - val_acc: 1.0000\n",
            "Epoch 713/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.0240 - acc: 1.0000 - val_loss: 0.0418 - val_acc: 1.0000\n",
            "Epoch 714/1000\n",
            "44/44 [==============================] - 0s 401us/step - loss: 0.0239 - acc: 1.0000 - val_loss: 0.0419 - val_acc: 1.0000\n",
            "Epoch 715/1000\n",
            "44/44 [==============================] - 0s 426us/step - loss: 0.0239 - acc: 1.0000 - val_loss: 0.0419 - val_acc: 1.0000\n",
            "Epoch 716/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.0415 - val_acc: 1.0000\n",
            "Epoch 717/1000\n",
            "44/44 [==============================] - 0s 566us/step - loss: 0.0237 - acc: 1.0000 - val_loss: 0.0410 - val_acc: 1.0000\n",
            "Epoch 718/1000\n",
            "44/44 [==============================] - 0s 643us/step - loss: 0.0236 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 1.0000\n",
            "Epoch 719/1000\n",
            "44/44 [==============================] - 0s 406us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 1.0000\n",
            "Epoch 720/1000\n",
            "44/44 [==============================] - 0s 464us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 1.0000\n",
            "Epoch 721/1000\n",
            "44/44 [==============================] - 0s 459us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 0.0405 - val_acc: 1.0000\n",
            "Epoch 722/1000\n",
            "44/44 [==============================] - 0s 490us/step - loss: 0.0233 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 1.0000\n",
            "Epoch 723/1000\n",
            "44/44 [==============================] - 0s 468us/step - loss: 0.0232 - acc: 1.0000 - val_loss: 0.0404 - val_acc: 1.0000\n",
            "Epoch 724/1000\n",
            "44/44 [==============================] - 0s 560us/step - loss: 0.0231 - acc: 1.0000 - val_loss: 0.0402 - val_acc: 1.0000\n",
            "Epoch 725/1000\n",
            "44/44 [==============================] - 0s 442us/step - loss: 0.0230 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 1.0000\n",
            "Epoch 726/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.0401 - val_acc: 1.0000\n",
            "Epoch 727/1000\n",
            "44/44 [==============================] - 0s 507us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.0399 - val_acc: 1.0000\n",
            "Epoch 728/1000\n",
            "44/44 [==============================] - 0s 548us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 0.0398 - val_acc: 1.0000\n",
            "Epoch 729/1000\n",
            "44/44 [==============================] - 0s 645us/step - loss: 0.0227 - acc: 1.0000 - val_loss: 0.0395 - val_acc: 1.0000\n",
            "Epoch 730/1000\n",
            "44/44 [==============================] - 0s 498us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.0395 - val_acc: 1.0000\n",
            "Epoch 731/1000\n",
            "44/44 [==============================] - 0s 491us/step - loss: 0.0226 - acc: 1.0000 - val_loss: 0.0393 - val_acc: 1.0000\n",
            "Epoch 732/1000\n",
            "44/44 [==============================] - 0s 545us/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.0393 - val_acc: 1.0000\n",
            "Epoch 733/1000\n",
            "44/44 [==============================] - 0s 423us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.0393 - val_acc: 1.0000\n",
            "Epoch 734/1000\n",
            "44/44 [==============================] - 0s 587us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.0393 - val_acc: 1.0000\n",
            "Epoch 735/1000\n",
            "44/44 [==============================] - 0s 480us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.0392 - val_acc: 1.0000\n",
            "Epoch 736/1000\n",
            "44/44 [==============================] - 0s 563us/step - loss: 0.0222 - acc: 1.0000 - val_loss: 0.0390 - val_acc: 1.0000\n",
            "Epoch 737/1000\n",
            "44/44 [==============================] - 0s 564us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 1.0000\n",
            "Epoch 738/1000\n",
            "44/44 [==============================] - 0s 443us/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.0388 - val_acc: 1.0000\n",
            "Epoch 739/1000\n",
            "44/44 [==============================] - 0s 557us/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.0386 - val_acc: 1.0000\n",
            "Epoch 740/1000\n",
            "44/44 [==============================] - 0s 553us/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.0385 - val_acc: 1.0000\n",
            "Epoch 741/1000\n",
            "44/44 [==============================] - 0s 456us/step - loss: 0.0218 - acc: 1.0000 - val_loss: 0.0381 - val_acc: 1.0000\n",
            "Epoch 742/1000\n",
            "44/44 [==============================] - 0s 558us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.0381 - val_acc: 1.0000\n",
            "Epoch 743/1000\n",
            "44/44 [==============================] - 0s 503us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.0379 - val_acc: 1.0000\n",
            "Epoch 744/1000\n",
            "44/44 [==============================] - 0s 468us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.0380 - val_acc: 1.0000\n",
            "Epoch 745/1000\n",
            "44/44 [==============================] - 0s 776us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 0.0378 - val_acc: 1.0000\n",
            "Epoch 746/1000\n",
            "44/44 [==============================] - 0s 422us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.0376 - val_acc: 1.0000\n",
            "Epoch 747/1000\n",
            "44/44 [==============================] - 0s 502us/step - loss: 0.0214 - acc: 1.0000 - val_loss: 0.0374 - val_acc: 1.0000\n",
            "Epoch 748/1000\n",
            "44/44 [==============================] - 0s 637us/step - loss: 0.0213 - acc: 1.0000 - val_loss: 0.0374 - val_acc: 1.0000\n",
            "Epoch 749/1000\n",
            "44/44 [==============================] - 0s 524us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.0373 - val_acc: 1.0000\n",
            "Epoch 750/1000\n",
            "44/44 [==============================] - 0s 531us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 1.0000\n",
            "Epoch 751/1000\n",
            "44/44 [==============================] - 0s 480us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 1.0000\n",
            "Epoch 752/1000\n",
            "44/44 [==============================] - 0s 582us/step - loss: 0.0210 - acc: 1.0000 - val_loss: 0.0369 - val_acc: 1.0000\n",
            "Epoch 753/1000\n",
            "44/44 [==============================] - 0s 488us/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.0365 - val_acc: 1.0000\n",
            "Epoch 754/1000\n",
            "44/44 [==============================] - 0s 483us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 1.0000\n",
            "Epoch 755/1000\n",
            "44/44 [==============================] - 0s 589us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.0362 - val_acc: 1.0000\n",
            "Epoch 756/1000\n",
            "44/44 [==============================] - 0s 498us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.0362 - val_acc: 1.0000\n",
            "Epoch 757/1000\n",
            "44/44 [==============================] - 0s 484us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.0363 - val_acc: 1.0000\n",
            "Epoch 758/1000\n",
            "44/44 [==============================] - 0s 536us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.0361 - val_acc: 1.0000\n",
            "Epoch 759/1000\n",
            "44/44 [==============================] - 0s 524us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.0355 - val_acc: 1.0000\n",
            "Epoch 760/1000\n",
            "44/44 [==============================] - 0s 516us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.0351 - val_acc: 1.0000\n",
            "Epoch 761/1000\n",
            "44/44 [==============================] - 0s 523us/step - loss: 0.0204 - acc: 1.0000 - val_loss: 0.0351 - val_acc: 1.0000\n",
            "Epoch 762/1000\n",
            "44/44 [==============================] - 0s 496us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 1.0000\n",
            "Epoch 763/1000\n",
            "44/44 [==============================] - 0s 665us/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 1.0000\n",
            "Epoch 764/1000\n",
            "44/44 [==============================] - 0s 498us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 1.0000\n",
            "Epoch 765/1000\n",
            "44/44 [==============================] - 0s 483us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 0.0351 - val_acc: 1.0000\n",
            "Epoch 766/1000\n",
            "44/44 [==============================] - 0s 532us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 1.0000\n",
            "Epoch 767/1000\n",
            "44/44 [==============================] - 0s 545us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 1.0000\n",
            "Epoch 768/1000\n",
            "44/44 [==============================] - 0s 681us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 1.0000\n",
            "Epoch 769/1000\n",
            "44/44 [==============================] - 0s 597us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.0347 - val_acc: 1.0000\n",
            "Epoch 770/1000\n",
            "44/44 [==============================] - 0s 671us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 1.0000\n",
            "Epoch 771/1000\n",
            "44/44 [==============================] - 0s 582us/step - loss: 0.0197 - acc: 1.0000 - val_loss: 0.0348 - val_acc: 1.0000\n",
            "Epoch 772/1000\n",
            "44/44 [==============================] - 0s 706us/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 1.0000\n",
            "Epoch 773/1000\n",
            "44/44 [==============================] - 0s 784us/step - loss: 0.0195 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 1.0000\n",
            "Epoch 774/1000\n",
            "44/44 [==============================] - 0s 907us/step - loss: 0.0195 - acc: 1.0000 - val_loss: 0.0339 - val_acc: 1.0000\n",
            "Epoch 775/1000\n",
            "44/44 [==============================] - 0s 950us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.0339 - val_acc: 1.0000\n",
            "Epoch 776/1000\n",
            "44/44 [==============================] - 0s 953us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 1.0000\n",
            "Epoch 777/1000\n",
            "44/44 [==============================] - 0s 836us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 1.0000\n",
            "Epoch 778/1000\n",
            "44/44 [==============================] - 0s 801us/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.0339 - val_acc: 1.0000\n",
            "Epoch 779/1000\n",
            "44/44 [==============================] - 0s 852us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.0338 - val_acc: 1.0000\n",
            "Epoch 780/1000\n",
            "44/44 [==============================] - 0s 725us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.0336 - val_acc: 1.0000\n",
            "Epoch 781/1000\n",
            "44/44 [==============================] - 0s 747us/step - loss: 0.0190 - acc: 1.0000 - val_loss: 0.0333 - val_acc: 1.0000\n",
            "Epoch 782/1000\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.0332 - val_acc: 1.0000\n",
            "Epoch 783/1000\n",
            "44/44 [==============================] - 0s 727us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.0332 - val_acc: 1.0000\n",
            "Epoch 784/1000\n",
            "44/44 [==============================] - 0s 765us/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.0330 - val_acc: 1.0000\n",
            "Epoch 785/1000\n",
            "44/44 [==============================] - 0s 650us/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.0331 - val_acc: 1.0000\n",
            "Epoch 786/1000\n",
            "44/44 [==============================] - 0s 841us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.0326 - val_acc: 1.0000\n",
            "Epoch 787/1000\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.0324 - val_acc: 1.0000\n",
            "Epoch 788/1000\n",
            "44/44 [==============================] - 0s 837us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.0324 - val_acc: 1.0000\n",
            "Epoch 789/1000\n",
            "44/44 [==============================] - 0s 923us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.0324 - val_acc: 1.0000\n",
            "Epoch 790/1000\n",
            "44/44 [==============================] - 0s 938us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.0324 - val_acc: 1.0000\n",
            "Epoch 791/1000\n",
            "44/44 [==============================] - 0s 818us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 1.0000\n",
            "Epoch 792/1000\n",
            "44/44 [==============================] - 0s 889us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.0317 - val_acc: 1.0000\n",
            "Epoch 793/1000\n",
            "44/44 [==============================] - 0s 862us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.0318 - val_acc: 1.0000\n",
            "Epoch 794/1000\n",
            "44/44 [==============================] - 0s 760us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 0.0320 - val_acc: 1.0000\n",
            "Epoch 795/1000\n",
            "44/44 [==============================] - 0s 491us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 1.0000\n",
            "Epoch 796/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 1.0000\n",
            "Epoch 797/1000\n",
            "44/44 [==============================] - 0s 592us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.0318 - val_acc: 1.0000\n",
            "Epoch 798/1000\n",
            "44/44 [==============================] - 0s 475us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.0314 - val_acc: 1.0000\n",
            "Epoch 799/1000\n",
            "44/44 [==============================] - 0s 665us/step - loss: 0.0179 - acc: 1.0000 - val_loss: 0.0309 - val_acc: 1.0000\n",
            "Epoch 800/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 1.0000\n",
            "Epoch 801/1000\n",
            "44/44 [==============================] - 0s 565us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 1.0000\n",
            "Epoch 802/1000\n",
            "44/44 [==============================] - 0s 453us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 1.0000\n",
            "Epoch 803/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.0309 - val_acc: 1.0000\n",
            "Epoch 804/1000\n",
            "44/44 [==============================] - 0s 710us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.0309 - val_acc: 1.0000\n",
            "Epoch 805/1000\n",
            "44/44 [==============================] - 0s 469us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 1.0000\n",
            "Epoch 806/1000\n",
            "44/44 [==============================] - 0s 489us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.0310 - val_acc: 1.0000\n",
            "Epoch 807/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.0304 - val_acc: 1.0000\n",
            "Epoch 808/1000\n",
            "44/44 [==============================] - 0s 496us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.0303 - val_acc: 1.0000\n",
            "Epoch 809/1000\n",
            "44/44 [==============================] - 0s 639us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.0302 - val_acc: 1.0000\n",
            "Epoch 810/1000\n",
            "44/44 [==============================] - 0s 499us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.0301 - val_acc: 1.0000\n",
            "Epoch 811/1000\n",
            "44/44 [==============================] - 0s 512us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.0301 - val_acc: 1.0000\n",
            "Epoch 812/1000\n",
            "44/44 [==============================] - 0s 614us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.0303 - val_acc: 1.0000\n",
            "Epoch 813/1000\n",
            "44/44 [==============================] - 0s 506us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.0303 - val_acc: 1.0000\n",
            "Epoch 814/1000\n",
            "44/44 [==============================] - 0s 665us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.0302 - val_acc: 1.0000\n",
            "Epoch 815/1000\n",
            "44/44 [==============================] - 0s 546us/step - loss: 0.0170 - acc: 1.0000 - val_loss: 0.0297 - val_acc: 1.0000\n",
            "Epoch 816/1000\n",
            "44/44 [==============================] - 0s 593us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0295 - val_acc: 1.0000\n",
            "Epoch 817/1000\n",
            "44/44 [==============================] - 0s 478us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0294 - val_acc: 1.0000\n",
            "Epoch 818/1000\n",
            "44/44 [==============================] - 0s 572us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.0295 - val_acc: 1.0000\n",
            "Epoch 819/1000\n",
            "44/44 [==============================] - 0s 723us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.0295 - val_acc: 1.0000\n",
            "Epoch 820/1000\n",
            "44/44 [==============================] - 0s 545us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.0294 - val_acc: 1.0000\n",
            "Epoch 821/1000\n",
            "44/44 [==============================] - 0s 532us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.0294 - val_acc: 1.0000\n",
            "Epoch 822/1000\n",
            "44/44 [==============================] - 0s 580us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.0292 - val_acc: 1.0000\n",
            "Epoch 823/1000\n",
            "44/44 [==============================] - 0s 602us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.0293 - val_acc: 1.0000\n",
            "Epoch 824/1000\n",
            "44/44 [==============================] - 0s 580us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.0290 - val_acc: 1.0000\n",
            "Epoch 825/1000\n",
            "44/44 [==============================] - 0s 562us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.0287 - val_acc: 1.0000\n",
            "Epoch 826/1000\n",
            "44/44 [==============================] - 0s 568us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.0288 - val_acc: 1.0000\n",
            "Epoch 827/1000\n",
            "44/44 [==============================] - 0s 555us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.0288 - val_acc: 1.0000\n",
            "Epoch 828/1000\n",
            "44/44 [==============================] - 0s 506us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.0287 - val_acc: 1.0000\n",
            "Epoch 829/1000\n",
            "44/44 [==============================] - 0s 582us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 1.0000\n",
            "Epoch 830/1000\n",
            "44/44 [==============================] - 0s 557us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.0283 - val_acc: 1.0000\n",
            "Epoch 831/1000\n",
            "44/44 [==============================] - 0s 533us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 1.0000\n",
            "Epoch 832/1000\n",
            "44/44 [==============================] - 0s 539us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 1.0000\n",
            "Epoch 833/1000\n",
            "44/44 [==============================] - 0s 476us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 1.0000\n",
            "Epoch 834/1000\n",
            "44/44 [==============================] - 0s 682us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.0278 - val_acc: 1.0000\n",
            "Epoch 835/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.0278 - val_acc: 1.0000\n",
            "Epoch 836/1000\n",
            "44/44 [==============================] - 0s 440us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 1.0000\n",
            "Epoch 837/1000\n",
            "44/44 [==============================] - 0s 432us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.0279 - val_acc: 1.0000\n",
            "Epoch 838/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.0278 - val_acc: 1.0000\n",
            "Epoch 839/1000\n",
            "44/44 [==============================] - 0s 469us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 1.0000\n",
            "Epoch 840/1000\n",
            "44/44 [==============================] - 0s 558us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.0275 - val_acc: 1.0000\n",
            "Epoch 841/1000\n",
            "44/44 [==============================] - 0s 462us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.0273 - val_acc: 1.0000\n",
            "Epoch 842/1000\n",
            "44/44 [==============================] - 0s 619us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 1.0000\n",
            "Epoch 843/1000\n",
            "44/44 [==============================] - 0s 463us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.0272 - val_acc: 1.0000\n",
            "Epoch 844/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.0269 - val_acc: 1.0000\n",
            "Epoch 845/1000\n",
            "44/44 [==============================] - 0s 553us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.0269 - val_acc: 1.0000\n",
            "Epoch 846/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.0268 - val_acc: 1.0000\n",
            "Epoch 847/1000\n",
            "44/44 [==============================] - 0s 481us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.0269 - val_acc: 1.0000\n",
            "Epoch 848/1000\n",
            "44/44 [==============================] - 0s 580us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0269 - val_acc: 1.0000\n",
            "Epoch 849/1000\n",
            "44/44 [==============================] - 0s 503us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0269 - val_acc: 1.0000\n",
            "Epoch 850/1000\n",
            "44/44 [==============================] - 0s 549us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.0267 - val_acc: 1.0000\n",
            "Epoch 851/1000\n",
            "44/44 [==============================] - 0s 532us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 1.0000\n",
            "Epoch 852/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 1.0000\n",
            "Epoch 853/1000\n",
            "44/44 [==============================] - 0s 574us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 1.0000\n",
            "Epoch 854/1000\n",
            "44/44 [==============================] - 0s 467us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0265 - val_acc: 1.0000\n",
            "Epoch 855/1000\n",
            "44/44 [==============================] - 0s 480us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0264 - val_acc: 1.0000\n",
            "Epoch 856/1000\n",
            "44/44 [==============================] - 0s 518us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 1.0000\n",
            "Epoch 857/1000\n",
            "44/44 [==============================] - 0s 417us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 1.0000\n",
            "Epoch 858/1000\n",
            "44/44 [==============================] - 0s 420us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 1.0000\n",
            "Epoch 859/1000\n",
            "44/44 [==============================] - 0s 581us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 1.0000\n",
            "Epoch 860/1000\n",
            "44/44 [==============================] - 0s 491us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 1.0000\n",
            "Epoch 861/1000\n",
            "44/44 [==============================] - 0s 437us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.0258 - val_acc: 1.0000\n",
            "Epoch 862/1000\n",
            "44/44 [==============================] - 0s 509us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.0259 - val_acc: 1.0000\n",
            "Epoch 863/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.0258 - val_acc: 1.0000\n",
            "Epoch 864/1000\n",
            "44/44 [==============================] - 0s 453us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 1.0000\n",
            "Epoch 865/1000\n",
            "44/44 [==============================] - 0s 572us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0254 - val_acc: 1.0000\n",
            "Epoch 866/1000\n",
            "44/44 [==============================] - 0s 436us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0253 - val_acc: 1.0000\n",
            "Epoch 867/1000\n",
            "44/44 [==============================] - 0s 426us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.0252 - val_acc: 1.0000\n",
            "Epoch 868/1000\n",
            "44/44 [==============================] - 0s 478us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.0254 - val_acc: 1.0000\n",
            "Epoch 869/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0254 - val_acc: 1.0000\n",
            "Epoch 870/1000\n",
            "44/44 [==============================] - 0s 431us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 1.0000\n",
            "Epoch 871/1000\n",
            "44/44 [==============================] - 0s 484us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 1.0000\n",
            "Epoch 872/1000\n",
            "44/44 [==============================] - 0s 498us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 1.0000\n",
            "Epoch 873/1000\n",
            "44/44 [==============================] - 0s 490us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 1.0000\n",
            "Epoch 874/1000\n",
            "44/44 [==============================] - 0s 580us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 1.0000\n",
            "Epoch 875/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0248 - val_acc: 1.0000\n",
            "Epoch 876/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0247 - val_acc: 1.0000\n",
            "Epoch 877/1000\n",
            "44/44 [==============================] - 0s 416us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0247 - val_acc: 1.0000\n",
            "Epoch 878/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.0244 - val_acc: 1.0000\n",
            "Epoch 879/1000\n",
            "44/44 [==============================] - 0s 455us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 1.0000\n",
            "Epoch 880/1000\n",
            "44/44 [==============================] - 0s 489us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 1.0000\n",
            "Epoch 881/1000\n",
            "44/44 [==============================] - 0s 469us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 1.0000\n",
            "Epoch 882/1000\n",
            "44/44 [==============================] - 0s 594us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 1.0000\n",
            "Epoch 883/1000\n",
            "44/44 [==============================] - 0s 524us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 1.0000\n",
            "Epoch 884/1000\n",
            "44/44 [==============================] - 0s 517us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 1.0000\n",
            "Epoch 885/1000\n",
            "44/44 [==============================] - 0s 526us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.0239 - val_acc: 1.0000\n",
            "Epoch 886/1000\n",
            "44/44 [==============================] - 0s 462us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
            "Epoch 887/1000\n",
            "44/44 [==============================] - 0s 562us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
            "Epoch 888/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
            "Epoch 889/1000\n",
            "44/44 [==============================] - 0s 503us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 1.0000\n",
            "Epoch 890/1000\n",
            "44/44 [==============================] - 0s 564us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 1.0000\n",
            "Epoch 891/1000\n",
            "44/44 [==============================] - 0s 589us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 1.0000\n",
            "Epoch 892/1000\n",
            "44/44 [==============================] - 0s 500us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 1.0000\n",
            "Epoch 893/1000\n",
            "44/44 [==============================] - 0s 491us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
            "Epoch 894/1000\n",
            "44/44 [==============================] - 0s 480us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 1.0000\n",
            "Epoch 895/1000\n",
            "44/44 [==============================] - 0s 518us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
            "Epoch 896/1000\n",
            "44/44 [==============================] - 0s 500us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
            "Epoch 897/1000\n",
            "44/44 [==============================] - 0s 535us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 1.0000\n",
            "Epoch 898/1000\n",
            "44/44 [==============================] - 0s 628us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 1.0000\n",
            "Epoch 899/1000\n",
            "44/44 [==============================] - 0s 465us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 1.0000\n",
            "Epoch 900/1000\n",
            "44/44 [==============================] - 0s 563us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 1.0000\n",
            "Epoch 901/1000\n",
            "44/44 [==============================] - 0s 630us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 1.0000\n",
            "Epoch 902/1000\n",
            "44/44 [==============================] - 0s 499us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 1.0000\n",
            "Epoch 903/1000\n",
            "44/44 [==============================] - 0s 537us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.0227 - val_acc: 1.0000\n",
            "Epoch 904/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 1.0000\n",
            "Epoch 905/1000\n",
            "44/44 [==============================] - 0s 444us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 1.0000\n",
            "Epoch 906/1000\n",
            "44/44 [==============================] - 0s 621us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 1.0000\n",
            "Epoch 907/1000\n",
            "44/44 [==============================] - 0s 458us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0224 - val_acc: 1.0000\n",
            "Epoch 908/1000\n",
            "44/44 [==============================] - 0s 486us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0223 - val_acc: 1.0000\n",
            "Epoch 909/1000\n",
            "44/44 [==============================] - 0s 624us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0221 - val_acc: 1.0000\n",
            "Epoch 910/1000\n",
            "44/44 [==============================] - 0s 502us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 1.0000\n",
            "Epoch 911/1000\n",
            "44/44 [==============================] - 0s 469us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 1.0000\n",
            "Epoch 912/1000\n",
            "44/44 [==============================] - 0s 469us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 1.0000\n",
            "Epoch 913/1000\n",
            "44/44 [==============================] - 0s 483us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 1.0000\n",
            "Epoch 914/1000\n",
            "44/44 [==============================] - 0s 531us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0220 - val_acc: 1.0000\n",
            "Epoch 915/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0217 - val_acc: 1.0000\n",
            "Epoch 916/1000\n",
            "44/44 [==============================] - 0s 451us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 1.0000\n",
            "Epoch 917/1000\n",
            "44/44 [==============================] - 0s 659us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 1.0000\n",
            "Epoch 918/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 1.0000\n",
            "Epoch 919/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0216 - val_acc: 1.0000\n",
            "Epoch 920/1000\n",
            "44/44 [==============================] - 0s 543us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 1.0000\n",
            "Epoch 921/1000\n",
            "44/44 [==============================] - 0s 424us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0214 - val_acc: 1.0000\n",
            "Epoch 922/1000\n",
            "44/44 [==============================] - 0s 502us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0213 - val_acc: 1.0000\n",
            "Epoch 923/1000\n",
            "44/44 [==============================] - 0s 521us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0213 - val_acc: 1.0000\n",
            "Epoch 924/1000\n",
            "44/44 [==============================] - 0s 573us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0213 - val_acc: 1.0000\n",
            "Epoch 925/1000\n",
            "44/44 [==============================] - 0s 577us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0211 - val_acc: 1.0000\n",
            "Epoch 926/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 1.0000\n",
            "Epoch 927/1000\n",
            "44/44 [==============================] - 0s 453us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 1.0000\n",
            "Epoch 928/1000\n",
            "44/44 [==============================] - 0s 551us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 1.0000\n",
            "Epoch 929/1000\n",
            "44/44 [==============================] - 0s 668us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 1.0000\n",
            "Epoch 930/1000\n",
            "44/44 [==============================] - 0s 744us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 1.0000\n",
            "Epoch 931/1000\n",
            "44/44 [==============================] - 0s 821us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0205 - val_acc: 1.0000\n",
            "Epoch 932/1000\n",
            "44/44 [==============================] - 0s 674us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 1.0000\n",
            "Epoch 933/1000\n",
            "44/44 [==============================] - 0s 667us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 1.0000\n",
            "Epoch 934/1000\n",
            "44/44 [==============================] - 0s 793us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 1.0000\n",
            "Epoch 935/1000\n",
            "44/44 [==============================] - 0s 719us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
            "Epoch 936/1000\n",
            "44/44 [==============================] - 0s 704us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
            "Epoch 937/1000\n",
            "44/44 [==============================] - 0s 890us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
            "Epoch 938/1000\n",
            "44/44 [==============================] - 0s 761us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
            "Epoch 939/1000\n",
            "44/44 [==============================] - 0s 807us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 1.0000\n",
            "Epoch 940/1000\n",
            "44/44 [==============================] - 0s 724us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 1.0000\n",
            "Epoch 941/1000\n",
            "44/44 [==============================] - 0s 746us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 1.0000\n",
            "Epoch 942/1000\n",
            "44/44 [==============================] - 0s 820us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 1.0000\n",
            "Epoch 943/1000\n",
            "44/44 [==============================] - 0s 880us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 1.0000\n",
            "Epoch 944/1000\n",
            "44/44 [==============================] - 0s 920us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0201 - val_acc: 1.0000\n",
            "Epoch 945/1000\n",
            "44/44 [==============================] - 0s 705us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 1.0000\n",
            "Epoch 946/1000\n",
            "44/44 [==============================] - 0s 735us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 1.0000\n",
            "Epoch 947/1000\n",
            "44/44 [==============================] - 0s 796us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 1.0000\n",
            "Epoch 948/1000\n",
            "44/44 [==============================] - 0s 675us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 1.0000\n",
            "Epoch 949/1000\n",
            "44/44 [==============================] - 0s 949us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 1.0000\n",
            "Epoch 950/1000\n",
            "44/44 [==============================] - 0s 741us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 1.0000\n",
            "Epoch 951/1000\n",
            "44/44 [==============================] - 0s 666us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 1.0000\n",
            "Epoch 952/1000\n",
            "44/44 [==============================] - 0s 861us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 1.0000\n",
            "Epoch 953/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0195 - val_acc: 1.0000\n",
            "Epoch 954/1000\n",
            "44/44 [==============================] - 0s 481us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
            "Epoch 955/1000\n",
            "44/44 [==============================] - 0s 574us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
            "Epoch 956/1000\n",
            "44/44 [==============================] - 0s 482us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
            "Epoch 957/1000\n",
            "44/44 [==============================] - 0s 492us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 1.0000\n",
            "Epoch 958/1000\n",
            "44/44 [==============================] - 0s 554us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 1.0000\n",
            "Epoch 959/1000\n",
            "44/44 [==============================] - 0s 519us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 1.0000\n",
            "Epoch 960/1000\n",
            "44/44 [==============================] - 0s 440us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0190 - val_acc: 1.0000\n",
            "Epoch 961/1000\n",
            "44/44 [==============================] - 0s 458us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 1.0000\n",
            "Epoch 962/1000\n",
            "44/44 [==============================] - 0s 542us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 1.0000\n",
            "Epoch 963/1000\n",
            "44/44 [==============================] - 0s 728us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0188 - val_acc: 1.0000\n",
            "Epoch 964/1000\n",
            "44/44 [==============================] - 0s 525us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 1.0000\n",
            "Epoch 965/1000\n",
            "44/44 [==============================] - 0s 549us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 1.0000\n",
            "Epoch 966/1000\n",
            "44/44 [==============================] - 0s 433us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 1.0000\n",
            "Epoch 967/1000\n",
            "44/44 [==============================] - 0s 533us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 1.0000\n",
            "Epoch 968/1000\n",
            "44/44 [==============================] - 0s 513us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 1.0000\n",
            "Epoch 969/1000\n",
            "44/44 [==============================] - 0s 513us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 1.0000\n",
            "Epoch 970/1000\n",
            "44/44 [==============================] - 0s 468us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
            "Epoch 971/1000\n",
            "44/44 [==============================] - 0s 582us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
            "Epoch 972/1000\n",
            "44/44 [==============================] - 0s 468us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
            "Epoch 973/1000\n",
            "44/44 [==============================] - 0s 558us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 1.0000\n",
            "Epoch 974/1000\n",
            "44/44 [==============================] - 0s 453us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 1.0000\n",
            "Epoch 975/1000\n",
            "44/44 [==============================] - 0s 609us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 1.0000\n",
            "Epoch 976/1000\n",
            "44/44 [==============================] - 0s 578us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 1.0000\n",
            "Epoch 977/1000\n",
            "44/44 [==============================] - 0s 502us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 1.0000\n",
            "Epoch 978/1000\n",
            "44/44 [==============================] - 0s 508us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 1.0000\n",
            "Epoch 979/1000\n",
            "44/44 [==============================] - 0s 500us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 1.0000\n",
            "Epoch 980/1000\n",
            "44/44 [==============================] - 0s 474us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
            "Epoch 981/1000\n",
            "44/44 [==============================] - 0s 588us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0177 - val_acc: 1.0000\n",
            "Epoch 982/1000\n",
            "44/44 [==============================] - 0s 497us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 1.0000\n",
            "Epoch 983/1000\n",
            "44/44 [==============================] - 0s 485us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
            "Epoch 984/1000\n",
            "44/44 [==============================] - 0s 560us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 1.0000\n",
            "Epoch 985/1000\n",
            "44/44 [==============================] - 0s 486us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
            "Epoch 986/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 1.0000\n",
            "Epoch 987/1000\n",
            "44/44 [==============================] - 0s 474us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 1.0000\n",
            "Epoch 988/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
            "Epoch 989/1000\n",
            "44/44 [==============================] - 0s 528us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
            "Epoch 990/1000\n",
            "44/44 [==============================] - 0s 481us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 1.0000\n",
            "Epoch 991/1000\n",
            "44/44 [==============================] - 0s 491us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
            "Epoch 992/1000\n",
            "44/44 [==============================] - 0s 566us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
            "Epoch 993/1000\n",
            "44/44 [==============================] - 0s 486us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
            "Epoch 994/1000\n",
            "44/44 [==============================] - 0s 545us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
            "Epoch 995/1000\n",
            "44/44 [==============================] - 0s 719us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 1.0000\n",
            "Epoch 996/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 1.0000\n",
            "Epoch 997/1000\n",
            "44/44 [==============================] - 0s 650us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 1.0000\n",
            "Epoch 998/1000\n",
            "44/44 [==============================] - 0s 530us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 1.0000\n",
            "Epoch 999/1000\n",
            "44/44 [==============================] - 0s 519us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
            "Epoch 1000/1000\n",
            "44/44 [==============================] - 0s 562us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0166 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PY3fF5GCDDh3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3170add4-e066-476a-dab9-4e6f97524707"
      },
      "source": [
        "# Determine Weights & Biases\n",
        "#Print model parameters & summary\n",
        "#save numpy array as csv file\n",
        "from numpy import asarray\n",
        "from numpy import savetxt\n",
        "summary = model.summary()\n",
        "print(summary)\n",
        "\n",
        "#Print shape of the weights\n",
        "for weight in model.get_weights():\n",
        "  print(weight.shape)\n",
        "\n",
        "print(model.layers[0].trainable_weights)\n",
        "units = int(int(model.layers[0].trainable_weights[0].shape[1])/4)\n",
        "print(\"No units: \", units)\n",
        "W = model.layers[0].get_weights()[0]\n",
        "U = model.layers[0].get_weights()[1]\n",
        "b = model.layers[0].get_weights()[2]\n",
        "\n",
        "W_i = W[:, :units]\n",
        "W_f = W[:, units: units * 2]\n",
        "W_c = W[:, units * 2: units * 3]\n",
        "W_o = W[:, units * 3:]\n",
        "\n",
        "print('W_i:')\n",
        "print (W_i)\n",
        "savetxt('W_i.csv', W_i, delimiter=',')\n",
        "\n",
        "print('W_f:')\n",
        "print (W_f)\n",
        "savetxt('W_f.csv', W_f, delimiter=',')\n",
        "\n",
        "print('W_c:')\n",
        "print (W_c)\n",
        "savetxt('W_c.csv', W_c, delimiter=',')\n",
        "\n",
        "print('W_o:')\n",
        "print (W_o)\n",
        "savetxt('W_o.csv', W_o, delimiter=',')\n",
        "\n",
        "U_i = U[:, :units]\n",
        "U_f = U[:, units: units * 2]\n",
        "U_c = U[:, units * 2: units * 3]\n",
        "U_o = U[:, units * 3:]\n",
        "\n",
        "print('U_i:')\n",
        "print (U_i)\n",
        "savetxt('U_i.csv', U_i, delimiter=',')\n",
        "\n",
        "print('U_f:')\n",
        "print (U_f)\n",
        "savetxt('U_f.csv', U_f, delimiter=',')\n",
        "\n",
        "print('U_c:')\n",
        "print (U_c)\n",
        "savetxt('U_c.csv', U_c, delimiter=',')\n",
        "\n",
        "print('U_o:')\n",
        "print (U_o)\n",
        "savetxt('U_o.csv', U_o, delimiter=',')\n",
        "\n",
        "\n",
        "b_i = b[:units]\n",
        "b_f = b[units: units * 2]\n",
        "b_c = b[units * 2: units * 3]\n",
        "b_o = b[units * 3:]\n",
        "\n",
        "print('b_i:')\n",
        "print (b_i)\n",
        "savetxt('b_i.csv', b_i, delimiter=',')\n",
        "\n",
        "print('b_f:')\n",
        "print (b_f)\n",
        "savetxt('b_f.csv', b_f, delimiter=',')\n",
        "\n",
        "print('b_c:')\n",
        "print (b_c)\n",
        "savetxt('b_c.csv', b_c, delimiter=',')\n",
        "\n",
        "print('b_o:')\n",
        "print (b_o)\n",
        "savetxt('b_o.csv', b_o, delimiter=',')\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 3)                 408       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 412\n",
            "Trainable params: 412\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "(30, 12)\n",
            "(3, 12)\n",
            "(12,)\n",
            "(3, 1)\n",
            "(1,)\n",
            "[<tf.Variable 'lstm_1/kernel:0' shape=(30, 12) dtype=float32_ref>, <tf.Variable 'lstm_1/recurrent_kernel:0' shape=(3, 12) dtype=float32_ref>, <tf.Variable 'lstm_1/bias:0' shape=(12,) dtype=float32_ref>]\n",
            "No units:  3\n",
            "W_i:\n",
            "[[-1.83530033e-01  4.68517601e-01 -2.84092695e-01]\n",
            " [ 1.46784395e-01  2.91617036e-01  2.46250033e-01]\n",
            " [-1.56641960e-01  4.38249528e-01  4.33678292e-02]\n",
            " [-1.35637343e-01  6.16129398e-01 -2.84804940e-01]\n",
            " [ 5.31251431e-02 -2.12507531e-01  3.26956451e-01]\n",
            " [-1.98363364e-01  4.04083937e-01 -3.60771045e-02]\n",
            " [ 7.20704854e-01 -8.94343182e-02  5.19974530e-01]\n",
            " [-2.08677307e-01 -1.49467900e-01 -7.07379282e-02]\n",
            " [ 3.03612649e-01  4.15424854e-01  8.70023593e-02]\n",
            " [-2.18603015e-01  4.48639207e-02 -1.64656162e-01]\n",
            " [-1.72582954e-01  9.97498408e-02 -8.75501856e-02]\n",
            " [-4.44738626e-01 -9.45496410e-02 -5.39905056e-02]\n",
            " [ 1.65222302e-01 -5.70966303e-03 -6.28164038e-02]\n",
            " [ 1.10985883e-01  4.35393423e-01  8.37817416e-02]\n",
            " [ 8.69129524e-02  1.64810661e-02 -2.80401498e-01]\n",
            " [ 7.34925568e-01  4.08168919e-02  4.66361851e-01]\n",
            " [-9.20576081e-02  5.81732333e-01  3.84870917e-01]\n",
            " [-2.63306145e-02  5.59917212e-01 -1.64065614e-01]\n",
            " [ 4.05954927e-01 -1.96719974e-01  2.31649563e-01]\n",
            " [-1.21363498e-01  3.99663076e-02  8.18965286e-02]\n",
            " [ 2.53779680e-01 -4.75911126e-02  2.94610947e-01]\n",
            " [-9.04262304e-01  2.84168422e-01 -4.17100191e-01]\n",
            " [ 2.24457234e-01 -6.07876442e-02 -2.66275823e-01]\n",
            " [ 3.53828877e-01  3.53813678e-01  4.62731361e-01]\n",
            " [-1.44738972e-01  3.79587620e-01 -2.33365148e-01]\n",
            " [-1.35902673e-01 -1.04139475e-02 -1.29830971e-01]\n",
            " [ 3.27177048e-01  5.77972054e-01  2.05890059e-01]\n",
            " [-2.91046858e-01  4.12860453e-01  1.24173611e-03]\n",
            " [ 5.48350275e-01  9.80835408e-02  1.89890973e-02]\n",
            " [-3.42767692e+00  6.33192778e-01 -3.21319747e+00]]\n",
            "W_f:\n",
            "[[ 0.132175   -0.09643099  0.15202394]\n",
            " [-0.3297931  -0.18741219  0.05834109]\n",
            " [ 0.2716197   0.15549532 -0.2176831 ]\n",
            " [-0.11216739 -0.10786471 -0.343727  ]\n",
            " [ 0.11831269 -0.02555528  0.03754553]\n",
            " [ 0.13555506 -0.08464205  0.33873263]\n",
            " [-0.09336081 -0.19648862 -0.06258789]\n",
            " [ 0.23534659 -0.21875231  0.23619357]\n",
            " [-0.00553966 -0.00802994 -0.12876354]\n",
            " [ 0.24325684  0.23920056 -0.17996058]\n",
            " [-0.24283575  0.19742623  0.36032227]\n",
            " [-0.18530235 -0.11423638 -0.14518145]\n",
            " [-0.3684088   0.27131757  0.05781907]\n",
            " [-0.34984833  0.00238082 -0.03085494]\n",
            " [-0.16630502  0.09205183 -0.37674046]\n",
            " [ 0.10451564  0.36346063  0.21179387]\n",
            " [-0.09869385  0.36286744  0.37042698]\n",
            " [-0.20046389  0.01257575 -0.10454735]\n",
            " [-0.21427257 -0.37309048 -0.01072219]\n",
            " [-0.12188101  0.18515995  0.02470469]\n",
            " [ 0.3176891   0.12902066  0.19554934]\n",
            " [-0.05019271  0.08904275  0.34909484]\n",
            " [-0.25684384 -0.28507522 -0.00156906]\n",
            " [ 0.28606114  0.2275044  -0.33891243]\n",
            " [-0.07872337  0.17299452 -0.22726363]\n",
            " [-0.07069847  0.331068   -0.16980252]\n",
            " [-0.15050474  0.30529937  0.14373466]\n",
            " [ 0.37312797 -0.00772059 -0.36201882]\n",
            " [-0.34131232  0.13609591  0.04019344]\n",
            " [ 0.28009292 -0.08376712  0.3740683 ]]\n",
            "W_c:\n",
            "[[ 5.36133528e-01  7.47584328e-02  3.14612120e-01]\n",
            " [ 5.28800905e-01 -3.89697194e-01  5.66703141e-01]\n",
            " [ 1.22556418e-01  2.26037711e-01  3.60685408e-01]\n",
            " [ 4.75725770e-01 -7.63640329e-02 -1.33614942e-01]\n",
            " [ 4.22331333e-01 -1.37249380e-01  1.52805477e-01]\n",
            " [-1.33111954e-01 -9.44408849e-02 -5.15878871e-02]\n",
            " [-2.82793697e-02 -5.22261798e-01  1.93399996e-01]\n",
            " [-5.74077368e-02  3.62061322e-01  3.49205971e-01]\n",
            " [ 3.79334390e-01 -1.23760991e-01  3.08223099e-01]\n",
            " [ 1.56317219e-01 -9.13360715e-02  4.19191331e-01]\n",
            " [ 1.07036680e-02  3.28271776e-01  3.21572572e-01]\n",
            " [ 4.92045492e-01  4.43360358e-01  2.47450814e-01]\n",
            " [ 7.04269826e-01 -3.99580896e-02  2.88353622e-01]\n",
            " [ 3.40296984e-01  9.24444422e-02  4.12575573e-01]\n",
            " [ 1.17584035e-01  1.23897105e-01  4.31940466e-01]\n",
            " [ 5.39900482e-01 -6.45321906e-01 -6.50500283e-02]\n",
            " [ 7.23007262e-01  3.02434489e-02  6.44167960e-01]\n",
            " [ 4.34893936e-01  1.25762209e-01  5.00215232e-01]\n",
            " [ 5.66497207e-01 -2.65651971e-01  1.09737635e-01]\n",
            " [ 3.67209673e-01 -3.08319062e-01  1.00707941e-01]\n",
            " [-1.11214444e-03 -2.69780397e-01  1.08694464e-01]\n",
            " [ 5.88766634e-01  6.35551810e-01  5.22570491e-01]\n",
            " [ 7.35134900e-01 -2.00329766e-01  5.74002743e-01]\n",
            " [-6.86928481e-02 -6.80735260e-02  4.92259651e-01]\n",
            " [ 6.29979491e-01 -3.07993628e-02  2.11076707e-01]\n",
            " [ 2.28282943e-01  1.55413374e-01  1.09799802e-01]\n",
            " [ 1.62398115e-01  1.52213335e-01  8.51679444e-02]\n",
            " [ 1.65022373e-01  5.54316603e-02  2.10001647e-01]\n",
            " [ 6.64189696e-01 -4.34337378e-01  6.82757497e-01]\n",
            " [-1.03128240e-01  2.93220329e+00  3.14140283e-02]]\n",
            "W_o:\n",
            "[[-0.12738423  0.45821398 -0.31349596]\n",
            " [ 0.5379186   0.43557382  0.24411951]\n",
            " [ 0.42478707  0.02704882  0.3340113 ]\n",
            " [-0.2136429   0.1136961   0.16512808]\n",
            " [ 0.45585212  0.24535649  0.2441885 ]\n",
            " [ 0.18634892 -0.04925797  0.27880064]\n",
            " [ 0.41758928  0.05252935  0.3798682 ]\n",
            " [ 0.46680924  0.45809355  0.25637406]\n",
            " [-0.19582291  0.3408629   0.04856687]\n",
            " [ 0.14296551 -0.14478871  0.33137482]\n",
            " [ 0.35640916  0.52382135  0.08780228]\n",
            " [ 0.4997628   0.31953105  0.32514182]\n",
            " [-0.13086501  0.2561747   0.30126578]\n",
            " [-0.18000418 -0.02177403 -0.1319066 ]\n",
            " [-0.2834768  -0.06220157 -0.09625418]\n",
            " [ 0.07198512  0.13513064  0.10954612]\n",
            " [ 0.12074612 -0.06445898 -0.00559095]\n",
            " [ 0.03292721  0.53484017  0.18064442]\n",
            " [ 0.40154943 -0.04790122  0.06836742]\n",
            " [-0.06672578  0.3907015   0.6312919 ]\n",
            " [ 0.39165124  0.3072686   0.63342136]\n",
            " [ 0.07703735  0.46825287 -0.28817987]\n",
            " [ 0.27245203  0.34666315  0.06938181]\n",
            " [ 0.57048076  0.05481831  0.22332853]\n",
            " [ 0.42727497  0.03042078  0.62995297]\n",
            " [ 0.48620027  0.08463184  0.13869837]\n",
            " [ 0.5083644   0.601475    0.4410454 ]\n",
            " [ 0.4849273   0.4869323   0.01840433]\n",
            " [-0.01953786 -0.08729833  0.15940578]\n",
            " [-1.1542791   0.06417882 -0.7323848 ]]\n",
            "U_i:\n",
            "[[ 0.12336798 -0.26256737  0.4248357 ]\n",
            " [-0.58244365  0.13638154 -0.22785917]\n",
            " [ 0.15805283  0.48719367  0.05391592]]\n",
            "U_f:\n",
            "[[ 0.36498597 -0.49594355  0.03308986]\n",
            " [-0.17269391 -0.5485349   0.01708786]\n",
            " [-0.148451    0.17000327  0.43492323]]\n",
            "U_c:\n",
            "[[ 0.09538739 -0.18153313  0.13894424]\n",
            " [-0.28578395  0.14437146 -0.16227052]\n",
            " [-0.0042397   0.3855691  -0.03018465]]\n",
            "U_o:\n",
            "[[ 0.31577802  0.42475548 -0.11658525]\n",
            " [ 0.29424682  0.00560439  0.20922232]\n",
            " [ 0.36444333  0.3029014  -0.34712657]]\n",
            "b_i:\n",
            "[0.49767676 0.31716555 0.38244626]\n",
            "b_f:\n",
            "[1. 1. 1.]\n",
            "b_c:\n",
            "[ 0.3945471  -0.62688076  0.38857168]\n",
            "b_o:\n",
            "[0.25369555 0.35889745 0.27463225]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lia4oNWp-lfu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "0764dd1f-0ab2-4a67-bf73-5f58d61b043a"
      },
      "source": [
        "#Model Summary\n",
        "print(model.summary())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 3)                 408       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 412\n",
            "Trainable params: 412\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzXb9mHB-tKW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c3e7e689-a421-4f43-e107-48e69307537f"
      },
      "source": [
        "#Installing h5py Python library to save trained models\n",
        "!pip install h5py"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgHnw2Ii-v_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save final keras LSTM Model\n",
        "model.save('B-T-median_LSTM.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1oT7yjB_BDq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "02e32240-29f7-41d0-f195-a3da69b0f348"
      },
      "source": [
        "#Diagnostic plot Ia: Model Performance (training loss vs test loss) for 1000 epochs\n",
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'])\n",
        "pyplot.plot(history.history['val_loss'])\n",
        "pyplot.title('Loss in training vs validation datasets')\n",
        "pyplot.ylabel('Loss')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
        "pyplot.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sqqYSKD_Pv_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ab4c1b30-dc59-413d-d5f6-e3879873a331"
      },
      "source": [
        "#Diagnostic Plot IIa: Model Performance (training accuracy vs test accuracy) for 1000 epochs\n",
        "pyplot.plot(history.history['acc'])\n",
        "pyplot.plot(history.history['val_acc'])\n",
        "pyplot.title('Accuracy in Training vs Validation datasets')\n",
        "pyplot.ylabel('Accuracy')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.legend(['Training Accuracy', 'Test Accuracy'], loc='lower right')\n",
        "pyplot.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deZwU1dn3/881C8wg6LCJyiLEYBQ3\ngkQjmsUFl7glLhGjwTUEDYlLYkzuGLf87jyaJ8sdlWi8DaiJDhJJDCauRE30SRBQcUUDGoRBMOyo\nzDBLX78/6vRQ0/TM9AzT03T39/169Wu6lq4+VdVTV52lzjF3R0REildJrhMgIiK5pUAgIlLkFAhE\nRIqcAoGISJFTIBARKXIKBCIiRU6BQDrMzD40s4/tAOn4vJm93tXr5iMz+52ZXR/et7mv8XU78T2l\n4fwP61xKO/RdnU6ndIwCQRczs2fMbL2Z9cx1WrLF3Xu7+zsd+YyZfSZcQD40s4/MzGPTnbqwuPsz\n7r5fV6/b3czsCDP7wMx6pVn2iplN7sj2unJfzew5Mzs/tu2mcP6XdcX2u0pqOvP9e7qbAkEXMrPh\nwGcAB07p5u8u687v6yh3fzZcQHoDyYtUVXJe6oXFzErMrCh+n+7+HPA+cFp8vpmNBvYGHshFuqR4\nFMU/WjeaCMwF7gbOiy8ws0oz+5mZvWtmG8OdRWVYdoSZ/cPMNpjZ8uQdR8hdXBzbxvlm9lxs2s3s\nG2a2GFgc5v0ybGOTmb1gZp+JrV9qZv9lZm+HO9AXzGyomU01s5+lpHe2mV2RbifD9348vL87fP4v\nYZvPm9lenTl44Zj8yMz+CXwEDDOzi81sUdj22ynH4xgzWxqbrjGzK83s1XCMq5M5s46sG5Z/38xW\nmdkKM/ta2OfhadJ8jpnNTZl3lZn9Ibw/KZb+mtaOKXAv0e8nbiLwsLuvD4HxwZCmDeG3sW8rxzF1\nXw82s4UhDdVAfD/7m9kjZrY65GQfNrPBYdnNwGHAHSHX9j9mVhY/FmZWZVERzmozWxqOm4VlF5vZ\n38zsFyHN75jZsa3sf5emM8y/LRzzTWY238zGxbb3aTN7MSx738z+b2zZ4WY2N6R5oZl9to3jUWJm\nt5jZf8Lv6BUzG9XaPu6w3F2vLnoBS4BLgYOBBmBQbNlU4BlgMFAKjCP6oe8JfACcDZQD/YHR4TPP\nABfHtnE+8Fxs2oEngX5AZZh3bthGGfBtYBVQEZZdBbwKfAIw4KCw7iHAe0BJWG8AsDme/pT9dODj\n4f3dwNqwjTLgPmBGO8dpeNhGWcr854ClwL7hWJQBJwMfC+k9CqgFDgzrHwMsjX2+higQ7xb261/J\n49fBdU8Kx2NfYCegOqR3eJp96U0UtD4Wm/cScEZ4vxoYF973A8a0cUwagD3CdCmwEjgpTJeE898H\nqABuAxbEPv874PrUfSX6jdUA3wrHdEL4nuS6A4EvAZXAzsAfgAdTzsn5semy+LEA7g+f6RPO0xLg\nvLDs4vBdF4b9+SawvJX979J0hnlfDce8DLgaWAH0DMvmA2eH932AQ8P7oUS/5+PCMT8eWAP0b+V4\nnAjMA3YJ648Cdsv1tajD165cJ6BQXsAR4Yc7IEy/CVwR3pcQXcAOSvO57wN/bGWbz9B+IDiqnXSt\nT34v8BZwaivrLQLGh/dTgEfa2GZqILgrtuwLwJvtpGk4rQeCa9v57J+Bb4T36S7uE2LTPwdu68S6\n9wI/ii3bh1YCQVg+A/iv2Lob2Rp83yO6IPbJ4Df0DPDd8P4EouKislbWHRDStFOYbi0QHAUsByz2\n2XnJddNsdyywOuWcnB+bbg4ERBfsRmDv2PJvAHPC+4vjvwWiC7gT/kdSvrdL05lmfSO64dovTP8D\nuJZwgY+t9wNgesq8vwLntHI8jiX6Xz+UcCOVjy8VDXWd84An3H1NmL6frcVDA4ju4t5O87mhrczP\n1PL4hJl9JxRFbDSzDUR3KgMy+K57iHIThL+/7UAaVsXebya6S+6s1P05KRQ3rQv7cyxb92d709La\nunukpKNFmtK4nyhHB3AO8Ad3rwvTXyKqL1oWinMObWM79xDdxRL+3u/ujdBcrPeTULyyiejOG9o+\nFsl9qfFw1QreTb4xs95mdpeZLQvbfSqDbSbtSnSn/25s3rtEud6k1GMM6c9Jl6fTzL5rZm+a2Uai\nG6KdYp+5gOju/S0zm2dmXwjz9wTODsVCG8Jv7tMhfdtw9yeAO4DbgffN7A4z69NWunZECgRdwKKy\n/i8DnwtluKuAK4CDzOwgoqxlHZCu7Hx5K/MhKnKItyTZLc06zf84FtUHfDekpa+7VxHdnVoG3/U7\n4NSQ3n2Bh1pZL9vi+1MJPAj8H6JiqirgCbbuT7asBIbEpoe2s/5jwGAzO4AoINyfXODuz7v7KUQX\nzT8T5R5a8yDwMTP7HPBFosCQNJEot3UUUXD/eJjf3rFI3ReAeAutq4ARwCHuvnPYflxb3RP/B2gi\nunjGt72inTRlPZ1mdiRwJXA6UAX0BT4kHC93f8vdJxCdl58Bs8ysguh/ZLq7V8VeO7n7/033PWFb\n/+PuY4D9iYLLlR3b9dxTIOgaXyT6hxgFjA6vfYFngYnungCmAT83sz3C3d1hFlVO3gccY2ZfDhVx\n/S1qLQKwEDjNzHpZVDl7UTvp6EOUVV8NlJnZtUTZ8aS7gB+Z2UiLHGhm/QHcvYao3PS3wCx3r93e\ng9IFegI9iPanycxOAo7uhu+dCVxkZp+wqEnnD9ta2d3rgVlExUs7Ed2tJhsIfMXMdnb3BqKiiUQb\n2/mAqOz7HmCxuy+MLe4DbCEqv+4F/HeG+/IcUGJmU8Lv68vAmJTtbgbWh9/CtSmff5+o7D9dehuI\ngtePwx37CKIboN9lmLZspjP5v7CGqAjreqJzA4CZfdXMBoT/zY1EF/gE0e//S2Y2PvyfVpjZkWa2\nR7rvMbNDwquM6MatnjbO8Y5KgaBrnEd0F7HM3VclX0QVeueEH8l3iCpq5wPrgJuJyhSXEd3pfTvM\nX0hUiQvwC6If1vtEF4f72knH40R3p/8iylbX0bJY4+dEF7kngE3Ab4gq35LuAQ6gY8VCWePuG4gu\nLH8kOjZnEN1VZ/t7HybK6v+dqDXW/wuLtrTxsfuJyuZnuntTbP55wLuhOOMitha/teYeojvse1Pm\nTyeqb3gPeJ2ojLtd7r6FqHjqa0TFI1+iZW7v50Q5jLVhm4+mbOJ/2FpU8vM0X3Ep0W90KfC3kP7U\ntOcinY8Ac4jO31Ki3/vK2PpfABaZ2QfAT4Gz3L3e3ZeG7/4h0Q3IMqL/zZJWvqeK6P9oQ/ielSGt\necVaFslJMQvN5H4H7On6YTQLRT4vErU4ybu7PZH2KEcgAJhZOXAZUQugog8CZvYlM+thZv2Am4A/\nKQhIoVIgECx6MGkDsDtR1leiZpBriFrn1IVpkYKkoiERkSKnHIGISJHboTsqS2fAgAE+fPjwXCdD\nRCSvvPDCC2vcfWC6ZXkXCIYPH86CBQtynQwRkbxiZu+2tkxFQyIiRU6BQESkyCkQiIgUOQUCEZEi\np0AgIlLkshYIzGxaGL7ttVaWWxjibUkY3m1MuvVERCS7spkjuJtomLfWnACMDK9JRL09iohIN8va\ncwTu/ndLM9h3zKnAvaGDs7kWDYK9u7uvbOMzO5SZC5ZTsy4MumQGO3B3Hbt/8AoHrHqIZVWH0K+2\n1ebEIrID6zfmVPYe87ku324uHygbTMu+8mvCvG0CgZlNIso1MGzYsNTFOfHhlka+++ArLeZZtsfN\n2g7/7nkxAPuvjrrzT/gOnFgRSWv+zrtDgQWCjLn7ncCdAGPHjt0hbrs3b2kEYHBVJSs21DKkbyXP\nXZ06et4O5PrY+wGfoGTKvFylREQ6qa0Br7dHLlsNraDlWLBD6NxYpzlR2xANQtVvpx45TkknmBqL\nichWubwizAYmhtZDnwY25lP9QDIQ9M3HQFBSmusUiMgOJGtFQ2ZWDXweGGBmNcB1RINI4+53EI0p\n+gWigT82AxdkKy3ZUFsfcgS9ynOckk5QjkBEYrLZaujsdpY7eTzqk3IEIlIodGvYSXXJOoJeeRgI\nlCMQkRhdETqptj4ax7xf7ygQ9KnIoyIiU45ARLbKi+ajO6LN9VHz0YP37MtpnxzMGWOH5DhFHaCi\nIRGJUSDopGTRUP+devLzs0bnODUdpByBiMSoaKiTkpXFlT3y8KK6Iz8CLSLdToGgk5J1BBVleXgI\nVTQkIjF5eBXbMdQ2NNGjtISy0jw8hCoaEpGYPLyK7RjqGprys1gIlCMQkRYUCDLg7myqawCiXkff\n31THuo/qqSzP0wuqniMQkRi1GsrA1KeX8NMn/sUDkz7NBXfPZ3PoXmLkrr1znLJOUtGQiMQoEGTg\n7/9aA8Br721ic30TZxw8hDHD+nLA4F1ynLJOKlGOQES2UiDogPUf1QNw5Cd25cQDd89xaraDcgQi\nEqNbww5YtzkKBJU98vywqbJYRGLy/IrWvZI5gop8rSROUmWxiMToitAB60IgyLvWQp4yuqeKhkQk\nRoEgA4lwIW0OBPn2/ECiqeW0ioZEJEaBoB2L3/+ABe+uB2DVpjogH3MEiZbTKhoSkRhdEdpx/cOv\nN7//oK6RyvLS/Buw3lNyBAoEIhKj5qPt2FTbyP6Dd+bByePYVNvATj3L2Klnnh02FQ2JSBvy7IrW\n/Wobmth7UG8qykvzt7XQNjmCPN0PEckKlRG0o7a+KX8DQFJqHYFyBCISoxxBO+oamrqvcrhuI6x4\nEXYdBZtWRNNdYcsHLadVRyAiMQoE7ajtzkAw53pYMA12HhwFgmypyNM+kkQkKxQI2uDuUSDorucG\n6jZFf5NB4JgbYOihXbNtM+g9CD5aA7sf2DXbFJGCoEDQinUf1fNff3gV9258gCy1LH/Q/rDnYV37\nHf1GdO32RCTvZbWw2MyON7O3zGyJmX0vzfI9zeyvZvaKmT1jZkOymZ6OeHn5Bh57fRXQjQ+QbdO6\nR4PMi0j2ZS0QmFkpMBU4ARgFnG1mo1JW+ylwr7sfCNwI/J9spaejkoPPQDcGArX3F5EcyGaO4BBg\nibu/4+71wAzg1JR1RgFPhfdPp1meM7UNsUCQq6IhtfcXkW6QzUAwGFgem64J8+JeBk4L778E9DGz\n/qkbMrNJZrbAzBasXr06K4lNFQ8E3fYcgXIEIpIDuW5Q/h3gc2b2EvA5YAXQlLqSu9/p7mPdfezA\ngQO7JWF1uSgaUudwIpID2Ww1tAIYGpseEuY1c/f3CDkCM+sNnO7uG7KYpozlpmhIXUGISPfL5i3n\nfGCkmY0wsx7ABGB2fAUzG2DWfNv7fWBaFtPTIS0CQc6KhpQjEJHsy9qVxt0bgSnA48AiYKa7v25m\nN5rZKWG1zwNvmdm/gEHAf2crPR1VGysa6rbeRlVZLCI5kNUrnLs/AjySMu/a2PsHgQezmYbOqgs5\nghtO2Y/h/Xt1z5eqjkBEckBPFrdic30Tw/v34rxxw7vvS9VqSERyQLecrahtyEH306osFpEcUCBo\nRV13djaXpByBiOSAAkErauu7sfvpJNURiEgO6ErTim4dhyBJg8yLSA7oStOKbh2HICmhISVFpPsp\nELSiLidFQ6osFpHup0DQipzkCDTIvIjkgAJBKzbnIkeQ2mpIdQQi0g10pUkjkXC2NCb0HIGIFAUF\ngjTqGqMLcu4ri3V6RCT7dKVJI9nhnCqLRaQYKBCkkeyCWg+UiUgx0JUmjWTPo+piQkSKgQJBGrX1\n0Z25ioZEpBioG+o0ajPNETQ1RMU5JeWQaNj+L1aOQERyQIEgjc31jQBtNx9dNhfuPhESjV375eU7\nQcNH0XvVEYhIN1AgSKMuk8ri9e9GQSCZGxg8Fvb5wnZ+s8FeR8HSZ6FqGJht5/ZERNqnQJBGRkVD\nyfL88l6wZSMMPhg+8+2uScAeo7tmOyIiGVDZQxoZVRYny/NLQyxVeb6I5CkFgjQyyxGENv8l5dFf\nleeLSJ7S1SuNZB1BRXkbhydZNFTaI/qrQCAieUpXrzTqG6O7/R6lbRye5qKhkCNQ0ZCI5CkFgjQS\n7pQYWFutdpJFQ805AgUCEclPCgRpNCac0pJ2mm42BwJVFotIfstqIDCz483sLTNbYmbfS7N8mJk9\nbWYvmdkrZra9DfG7RCLhlLTXhj9ZNJTMCaiOQETyVNauXmZWCkwFTgBGAWeb2aiU1a4BZrr7J4EJ\nwK+ylZ6OaEw4Ze3mCEIgSOYEVDQkInkqm7exhwBL3P0dd68HZgCnpqzjwM7h/S7Ae1lMT8aaEk5J\ne4EgNUegQWREJE9l8+o1GFgem64J8+KuB841sxrgEeCb6TZkZpPMbIGZLVi9enU20toskXDWflSf\nQY4g+RyBcgQikt9yfRt7NnC3uw8BvgD81mzbwnZ3v9Pdx7r72IEDB2Y1Qbc9vYSHX36P9Zvb6U00\nGQiSyVUdgYjkqWxevVYAQ2PTQ8K8uIuAmQDu/k+gAhiQxTS167HXVmW2YnPRUDiEajUkInkqm4Fg\nPjDSzEaYWQ+iyuDZKessA44GMLN9iQJBdst+2uEZr9gE2NYeQlU0JCJ5KmuBwN0bgSnA48AiotZB\nr5vZjWZ2Sljt28DXzOxloBo4390zvhbnVKKpZS5AOQIRyVNZ7Yba3R8hqgSOz7s29v4N4PBspiFr\nPNGyXkBjB4hInlINZ2d5U8viIBUNiUieUiDorERCRUMiUhAUCDormSNIVmkoRyAieUqBIEV7z5E1\n80TLegE9RyAieUpXrxRlbY1BEJdsNZQMBioaEpE81e5Vz8y+aWZ9uyMxO4LyTLME21QWK6aKSH7K\n5Oo1CJhvZjNDt9IF3U4ykeljDHqOQEQKRLuBwN2vAUYCvwHOBxab2Y/NbK8spy0nGpoyDATuaj4q\nIgUho/KM8LTvqvBqBPoCD5rZT7KYtpxoaEpktqI3pTxQpqIhEclP7T5ZbGaXAROBNcBdwFXu3hB6\nCV0MfDe7SexejYmOFA3FLv4qGhKRPJVJFxP9gNPc/d34THdPmNlJ2UlW7jSm5gga6mDmV2HzWvjM\nd2DtYnj9IVj/b6jsB2WV0XoqGhKRPJVJIHgUWJecMLOdgX3d/Xl3X5S1lOVIso7g1189OJqxaQUs\nfiJ6v2QOvPcibFgGg8fCXkfCkEOgx06wxydzlGIRke2TSSC4HRgTm/4wzbyC0ZhIcNbYoRy3327R\njOS4AxDVCySaYMin4CsPbJ0/dHr3JlJEpAtlUsNp8a6h3T1BlnstzaXGJqesNNZC1mOBINEUnihW\nMZCIFI5MAsE7ZvYtMysPr8uAd7KdsFxpaEpQHn+6uEWOILFtJbGISJ7L5Io2GRhHNMxkDXAoMCmb\nicqlxoS3HLjeEy3fK0cgIgWm3SIed/8P0TCTRSEqGorFx22Khpr0zICIFJRMniOoIBpkfj+iMYUB\ncPcLs5iunKlvSlAeryNIxHMETdt2LSEikucyubX9LbAbcBzwN2AI8EE2E5UrC5au23Zm2hyBAoGI\nFI5MAsHH3f2HwEfufg9wIlE9QcFZsaEWgM9/YuDWmZ6aI0goRyAiBSWTQNAQ/m4ws/2BXYBds5ek\n3Kmtj+7+96iq3DqzRash33ZAGhGRPJfJ8wB3hvEIrgFmA72BH2Y1VTmyOQSCyvLYHb+KhkSkwLUZ\nCELHcpvcfT3wd+Bj3ZKqHKltiC76FfFAkO7JYhUNiUgBabNoKDxFXFC9i7alrqEJM+hZ1l7zUQUC\nESkcmdQRzDGz75jZUDPrl3xlPWU5UFvfRGV5KS0GYWvuXcNiD5TpOQIRKRyZ1BGcFf5+IzbPyaCY\nyMyOB34JlAJ3uftNKct/ARwZJnsBu7p7VQZpyorahqaW9QOwtWiotIdaDYlIQcrkyeIRndmwmZUC\nU4HxRF1TzDez2e7+RmzbV8TW/yaQ076c6xoSLesHYGvRUGmPKAjoyWIRKTCZPFk8Md18d7+3nY8e\nAixx93fCdmYApwJvtLL+2cB17aUnmxpSnyqGWI6gXJXFIlKQMika+lTsfQVwNPAi0F4gGAwsj00n\nO6zbhpntCYwAnmpl+SRCR3fDhg3LIMmd05hItOxnCLY+UFZark7nRKQgZVI09M34tJlVATO6OB0T\ngAfd4010WqThTuBOgLFjx2Y4qHDHNTSl9DwKW4uGSsrV6ZyIFKTOXNE+Irp7b88KYGhsekiYl84E\noLoTaelSjaljEcDWTueSRUOuymIRKSyZ1BE8TNRKCKLAMQqYmcG25wMjzWwEUQCYAHwlzfb3AfoC\n/8wwzVnTmEgZnQxaVhY3NUbvVTQkIgUkkzqCn8beNwLvuntNex9y90YzmwI8TtR8dJq7v25mNwIL\n3H12WHUCMCM+HGauNDQlKE8dfSxeR5AI3S5phDIRKSCZBIJlwEp3rwMws0ozG+7uS9v7oLs/AjyS\nMu/alOnrM05tljU2OT3KUouGknUEZdAQ9U6qOgIRKSSZXNF+D8T6YqYpzCs4DQlP02ooXjQUcgQq\nGhKRApJJIChz9/rkRHjfI3tJyp3GpgTlqa2G4k8WN4XDoMpiESkgmQSC1WZ2SnLCzE4F1mQvSbkT\njVecWlmcrCMo21pHoByBiBSQTOoIJgP3mdltYboGSPu0cb5raOuBspLyWKsh1RGISOHI5IGyt4FP\nm1nvMP1h1lOVI0Ma/s3Ja1+CdzbB8vmwZSPMvSNaWNoDGj6K3qtoSEQKSCbPEfwY+Im7bwjTfYFv\nu/s12U5cd7u37nKoA+69Z9uFww+Hf/89KiIauE+3p01EJFsyKRo6wd3/Kznh7uvN7AtEQ1cWh+Nv\ngk9fAod9o/11RUTyTCaF3aVm1jM5YWaVQM821i88qhMQkQKWSY7gPuCvZjYdMOB8IE3ZSQFTIBCR\nApZJZfHNZvYycAxRn0OPA3tmO2Hdzd2x1haqclhEClimt7rvEwWBM4GjgEVZS1GObGlMtL5Qzw2I\nSAFrNUdgZnsTjRp2NtEDZA8A5u5HtvaZfLa5vomK1hYqRyAiBaytoqE3gWeBk9x9CYCZXdHG+nmt\ntiHtmDgR1RGISAFr6wp3GrASeNrM/tfMjobWi9HzXW19W4FAOQIRKVytBgJ3f8jdJwD7AE8DlwO7\nmtntZnZsdyWwu9S1lSNQ0ZCIFLB2yzzc/SN3v9/dTyYabvIl4Oqsp6ybtRkIVDQkIgWsQ1c4d1/v\n7ne6+9HZSlCuNCXaGCBNgUBECpiucEFTWyNlqmhIRAqYAkHQ5ojJqiwWkQKmQBC0WTSkHIGIFDAF\ngqDNoiHVEYhIAdMVLnAFAhEpUrrCBU1tdDWkoiERKWQKBEGizRyBAoGIFC4FgiCh5whEpEhl9Qpn\nZseb2VtmtsTMvtfKOl82szfM7HUzuz+b6WlLW3FARUMiUsgyGaGsU8ysFJgKjAdqgPlmNtvd34it\nMxL4PnB4GAt512ylpz1ttxpSIBCRwpXNHMEhwBJ3f8fd64EZwKkp63wNmOru6wHc/T9ZTE+b2mw1\nVKKiIREpXNm8wg0Glsema8K8uL2Bvc3s/5nZXDM7Pt2GzGySmS0wswWrV6/OSmLV15CIFKtcX+HK\ngJHA54lGQvtfM6tKXSl0dDfW3ccOHDgwKwlps45ARUMiUsCyGQhWAENj00PCvLgaYLa7N7j7v4F/\nEQWGbtdmqyFVFotIActmIJgPjDSzEWbWA5gAzE5Z5yGi3ABmNoCoqOidLKapVXqOQESKVdYCgbs3\nAlOAx4FFwEx3f93MbjSzU8JqjwNrzewNolHQrnL3tdlKU1vUDbWIFKusNR8FcPdHgEdS5l0be+/A\nleGVU9uUDJWUw8jx8NYjULFLTtIkItIdshoI8kki4SxM7MUB/RKUnn0/9OofBYCPVkPvnD3eICKS\ndQoEQdR81En0HUHpoFFbF1QNbfUzIiKFINfNR3cYCXcM9MyAiBQdXfWCKBA4pkAgIkVGV70g4VCC\nY2a5ToqISLdSIAiaElGOQEVDIlJsdNUL3F05AhEpSgoEQTRUpQKBiBQfBYKgudWQupwWkSKjq16Q\ncKeEBIZyBCJSXBQIgoQ7JQaoaEhEiowCQfDCu+vB1WpIRIqPrnpBzfraqPmoioZEpMgoEARm0Kdn\nqXIEIlJ0dNULGpucEnPVEYhI0VEgCBqaXEVDIlKUFAiCxkRCvY+KSFHSVS9oaExQQkJFQyJSdBQI\ngoaExiMQkeKkq17Q2JTASKA6AhEpNgoEROMVJzyEAMUBESkyCgRAQyIBoPEIRKQo6apH9AwBoOaj\nIlKUFAhICQRqNSQiRUaBABUNiUhxy+pVz8yON7O3zGyJmX0vzfLzzWy1mS0Mr4uzmZ7WNOcIXEVD\nIlJ8yrK1YTMrBaYC44EaYL6ZzXb3N1JWfcDdp2QrHZloaEpQShM9Gj9QjkBEik42r3qHAEvc/R13\nrwdmAKdm8fs6rTHhTC//CSXeCKU9cp0cEZFulbUcATAYWB6brgEOTbPe6Wb2WeBfwBXuvjx1BTOb\nBEwCGDZsWJcntK6hiaH2n2jisG90+fZFcqWhoYGamhrq6upynRTpJhUVFQwZMoTy8vKMP5PNQJCJ\nh4Fqd99iZl8H7gGOSl3J3e8E7gQYO3asd3Uiahua6IXz/p6nMGiXwV29eZGcqampoU+fPgwfPhxT\ni7iC5+6sXbuWmpoaRowYkfHnslk0tAIYGpseEuY1c/e17r4lTN4FHJzF9LSqtr6JUktQUprruCjS\nterq6ujfv7+CQJEwM/r379/hHGA2A8F8YKSZjTCzHsAEYHZ8BTPbPTZ5CrAoi+lpVW19E4ZTWlaa\ni68XySoFgeLSmfOdtVtgd280synA40ApMM3dXzezG4EF7j4b+JaZnQI0AuuA87OVnrbUNjRRSoLS\nEgUCESk+WW0r6e6PuPve7r6Xu/93mHdtCAK4+/fdfT93P8jdj3T3N7OZntY0B4IyFQ2JdKW1a9cy\nevRoRo8ezW677cbgwYObp+vr6zPaxgUXXMBbb73V5jpTp07lvvvu64okA/D+++9TVlbGXXfd1WXb\n3JEV/ZVvwdJ1zH17LUeToFR1BCJdqn///ixcuBCA66+/nt69e/Od73ynxTrujrtTUpL+vnT69Ont\nfs83vtG1rf1mzpzJYYcdRqC38JMAABH5SURBVHV1NRdfnL3nXBsbGynbAW5Ac5+CHPvqb+ZR29DE\ndT0T9OhAcyuRfHPDw6/zxnubunSbo/bYmetO3q/Dn1uyZAmnnHIKn/zkJ3nppZd48sknueGGG3jx\nxRepra3lrLPO4tprrwXgiCOO4LbbbmP//fdnwIABTJ48mUcffZRevXrxpz/9iV133ZVrrrmGAQMG\ncPnll3PEEUdwxBFH8NRTT7Fx40amT5/OuHHj+Oijj5g4cSKLFi1i1KhRLF26lLvuuovRo0dvk77q\n6mpuvfVWzjjjDFauXMnuu0fVmX/5y1/44Q9/SFNTE4MGDeKJJ57ggw8+YMqUKbz00ksA3HjjjZx0\n0kkMGDCADRs2ADBjxgzmzJnDXXfdxbnnnkufPn144YUX+PznP89pp53GFVdcQV1dHb169eLuu+9m\n5MiRNDY2ctVVV/Hkk09SUlLC5MmT+fjHP86dd97Jgw8+CMCjjz7KtGnT+P3vf9+p85dU1IGgoSlB\nbUMTFx8xgp1fLcVKVUcg0l3efPNN7r33XsaOHQvATTfdRL9+/WhsbOTII4/kjDPOYNSoUS0+s3Hj\nRj73uc9x0003ceWVVzJt2jS+971teq/B3Zk3bx6zZ8/mxhtv5LHHHuPWW29lt912Y9asWbz88suM\nGTMmbbqWLl3KunXrOPjggznzzDOZOXMml112GatWreKSSy7h2WefZc8992TdunVAlNMZOHAgr7zy\nCu7efPFvy8qVK5k7dy4lJSVs3LiRZ599lrKyMh577DGuueYaHnjgAW6//Xbee+89Xn75ZUpLS1m3\nbh1VVVVMmTKFtWvX0r9/f6ZPn86FF17Y0UO/jaIOBLUNTQDstksF5gkwBQIpXJ25c8+mvfbaqzkI\nQHQX/pvf/IbGxkbee+893njjjW0CQWVlJSeccAIABx98MM8++2zabZ922mnN6yxduhSA5557jquv\nvhqAgw46iP32S388ZsyYwVlnnQXAhAkTuPTSS7nsssv45z//yZFHHsmee+4JQL9+/QCYM2cODz30\nEBC12Onbty+NjY1t7vuZZ57ZXBS2YcMGJk6cyNtvv91inTlz5nD55ZdTGm5Qk993zjnncP/993PO\nOefwwgsvUF1d3eZ3ZaK4A0F9FAgqe5RCoglaKaMUka630047Nb9fvHgxv/zlL5k3bx5VVVWce+65\nadvC9+ixtQuY0tLSVi+4PXv2bHed1lRXV7NmzRruueceAN577z3eeeedDm2jpKQE963PvqbuS3zf\nf/CDH3Dcccdx6aWXsmTJEo4//vg2t33hhRdy+umnA3DWWWc1B4rtUdRXvuZAUF4K3qQcgUiObNq0\niT59+rDzzjuzcuVKHn/88S7/jsMPP5yZM2cC8Oqrr/LGG6n9X8Ibb7xBY2MjK1asYOnSpSxdupSr\nrrqKGTNmMG7cOJ5++mneffddgOaiofHjxzN16lQgKpJav349JSUl9O3bl8WLF5NIJPjjH//Yaro2\nbtzI4MFRjwZ333138/zx48dzxx130NTU1OL7hg4dyoABA7jppps4//zzt++gBMUdCBrigSABeo5A\nJCfGjBnDqFGj2GeffZg4cSKHH354l3/HN7/5TVasWMGoUaO44YYbGDVqFLvsskuLdaqrq/nSl77U\nYt7pp59OdXU1gwYN4vbbb+fUU0/loIMO4pxzzgHguuuu4/3332f//fdn9OjRzcVVN998M8cddxzj\nxo1jyJAhrabr6quv5qqrrmLMmDEtchFf//rX2W233TjwwAM56KCDmoMYwFe+8hVGjBjB3nvvvd3H\nBcDiX5wPxo4d6wsWLOiSbb24bD2n/eofTL/gUxxZvTd89jtw1DVdsm2RHcGiRYvYd999c52MHUJj\nYyONjY1UVFSwePFijj32WBYvXrxDNN/sqMmTJ3PYYYdx3nnnpV2e7ryb2QvuPjbd+vl3BDrpiddX\n8dDCFl0dsfbD6IGWyrISwFU0JFLAPvzwQ44++mgaGxtxd37961/nZRAYPXo0ffv25ZZbbumybebf\nUeikDZsbWPz+h9vM/+SwKkYOrIwmVDQkUrCqqqp44YUXcp2M7ZZ8QK8rFU0g+PKnhvLlTw1Nv7Ax\nPOqu0clEpAjpygdRiyFQIBCRoqQrH0TPEICKhkSkKCkQQCxHoEAgIsVHgQCiZwhAOQKRLtYV3VAD\nTJs2jVWrVrW6vL6+nn79+nHNNWr+3RkKBACJEAhURyDSpZLdUC9cuJDJkydzxRVXNE/Hu4toT3uB\n4PHHH2fUqFE88MADXZHsVnW0u4p8UTSthtqkymIpBo9+D1a92rXb3O0AOOGmTn30nnvuYerUqdTX\n1zNu3Dhuu+02EokEF1xwAQsXLsTdmTRpEoMGDWLhwoWcddZZVFZWMm/evG2CSHV1NVdeeSW/+MUv\nmDdvHocccggAzz//PJdffjmbN2+moqKCp59+mh49emzTvfOll17KkCFDeO2116iqqmLu3Llcc801\nzJkzh2uuuYZly5bx9ttvM2LECG644QbOP/98PvzwQ0pKSvjVr37FoYceCsCPf/xjqqurKSkp4aST\nTmLixImce+65zJ8/H4ge9DrvvPOYN2/edhz0rqdAAKosFulmr732Gn/84x/5xz/+QVlZGZMmTWLG\njBnstdderFmzhldfjQLWhg0bqKqq4tZbb+W2225LO3bA5s2beeaZZ5pzDdXV1RxyyCHU1dUxYcIE\nZs2axZgxY9i4cSM9e/bkV7/61TbdO7fnzTff5O9//zsVFRVs3ryZJ598koqKCt58803OO+88nn/+\neR5++GEeffRR5s2bR2VlJevWraNfv35UVlby2muvsf/++zN9+nQuuOCCLj+e20uBAFRZLMWhk3fu\n2TBnzhzmz5/f3A11bW0tQ4cO5bjjjuOtt97iW9/6FieeeCLHHntsu9uaPXs248ePp6KigjPPPJOD\nDz6Yn/3sZyxatIhhw4Y1jzuQ7Feote6d23LqqadSUVEBwJYtW5gyZQovv/wyZWVlzd1Hz5kzhwsv\nvJDKysoW273ooouYPn06N998M7///e+bB7DZkSgQwNbKYhUNiXQLd+fCCy/kRz/60TbLXnnlFR59\n9FGmTp3KrFmzuPPOO9vcVnV1NXPnzmX48OEArF69mr/97W9UVVV1KE1lZWUkQn1hW91G/+xnP2Po\n0KH87ne/o6Ghgd69e7e53TPPPJMf//jHHH744Rx22GEdTld30JUPVDQk0s2OOeYYZs6cyZo1a4Co\nddGyZctYvXo17s6ZZ57JjTfeyIsvvghAnz59+OCDD7bZzoYNG5g7dy41NTXN3UbfcsstVFdXM2rU\nKJYtW9a8jU2bNtHU1NRq987Dhw9v7oJi1qxZraZ948aN7L777pgZ99xzT3OPoePHj2fatGnU1ta2\n2G6vXr046qijmDJlyg5ZLATFlCN48bfwz9vSL2tKdjGhQCDSHQ444ACuu+46jjnmGBKJBOXl5dxx\nxx2UlpZy0UUX4e6YGTfffDMAF1xwARdffPE2lcWzZs1i/PjxlMfGG//iF7/ID37wA6ZOnUp1dTWX\nXHIJdXV1VFZW8tRTT/H1r3+dxYsXc+CBB1JWVsYll1zC5MmTuf766/na175GVVUVn/3sZ1tN+5Qp\nUzjjjDOYNm0aJ554YvMgOCeddBIvv/wyY8eOpby8nJNPPrk5x3POOefwyCOPcPTRR2frkG6X4umG\n+s2/wCttNC0rq4Bjroed9+hs0kR2OOqGesdw0003sWXLFq677rpu+T51Q92afU6MXiIi3ejkk09m\n+fLlPPXUU7lOSquyWkdgZseb2VtmtsTMvtfGeqebmZtZ2mglIpKvHn74YRYuXJhR66RcyVogMLNS\nYCpwAjAKONvMRqVZrw9wGfB8ttIiUszyrfhXtk9nznc2cwSHAEvc/R13rwdmAKemWe9HwM1AXZpl\nIrIdKioqWLt2rYJBkXB31q5d2/zMQ6ayWUcwGFgem64BDo2vYGZjgKHu/hczuyqLaREpSkOGDKGm\npobVq1fnOinSTSoqKhgyZEiHPpOzymIzKwF+DpyfwbqTgEkAw4YNy27CRApIeXk5I0aMyHUyZAeX\nzaKhFUB8bMghYV5SH2B/4BkzWwp8GpidrsLY3e9097HuPnbgwIFZTLKISPHJZiCYD4w0sxFm1gOY\nAMxOLnT3je4+wN2Hu/twYC5wirt34iEBERHprKwFAndvBKYAjwOLgJnu/rqZ3Whmp2Tre0VEpGPy\n7sliM1sNvNvJjw8A1nRhcvKB9rk4aJ+Lw/bs857unrZsPe8CwfYwswWtPWJdqLTPxUH7XByytc/q\nfVREpMgpEIiIFLliCwRtj3BRmLTPxUH7XByyss9FVUcgIiLbKrYcgYiIpFAgEBEpckUTCDIdGyHf\nmNlQM3vazN4ws9fN7LIwv5+ZPWlmi8PfvmG+mdkt4Ti8Ejr+yztmVmpmL5nZn8P0CDN7PuzXA+Fp\ndsysZ5heEpYPz2W6O8vMqszsQTN708wWmdlhRXCOrwi/6dfMrNrMKgrxPJvZNDP7j5m9FpvX4XNr\nZueF9Reb2XkdSUNRBIJMx0bIU43At919FFF/Td8I+/Y94K/uPhL4a5iG6BiMDK9JwO3dn+QucRnR\nE+tJNwO/cPePA+uBi8L8i4D1Yf4vwnr56JfAY+6+D3AQ0b4X7Dk2s8HAt4Cx7r4/UErUTU0hnue7\ngeNT5nXo3JpZP+A6oh6eDwGuSwaPjLh7wb+Aw4DHY9PfB76f63RlaV//BIwH3gJ2D/N2B94K738N\nnB1bv3m9fHkRdWD4V+Ao4M+AET1tWZZ6vom6ODksvC8L61mu96GD+7sL8O/UdBf4OU52Y98vnLc/\nA8cV6nkGhgOvdfbcAmcDv47Nb7Fee6+iyBGQfmyEwTlKS9aE7PAniUZ7G+TuK8OiVcCg8L4QjsX/\nAN8FEmG6P7DBo/6toOU+Ne9vWL4xrJ9PRgCrgemhOOwuM9uJAj7H7r4C+CmwDFhJdN5eoLDPc1xH\nz+12nfNiCQQFz8x6A7OAy919U3yZR7cIBdFO2MxOAv7j7i/kOi3dqAwYA9zu7p8EPmJrUQFQWOcY\nIBRrnEoUBPcAdmLb4pOi0B3ntlgCQXtjI+Q1MysnCgL3ufsfwuz3zWz3sHx34D9hfr4fi8OBU8IY\nFjOIiod+CVSZWXKgpfg+Ne9vWL4LsLY7E9wFaoAad0+O6/0gUWAo1HMMcAzwb3df7e4NwB+Izn0h\nn+e4jp7b7TrnxRII2hwbIZ+ZmQG/ARa5+89ji2YDyZYD5xHVHSTnTwytDz4NbIxlQXd47v59dx/i\n0RgWE4Cn3P0c4GngjLBa6v4mj8MZYf28unN291XAcjP7RJh1NPAGBXqOg2XAp82sV/iNJ/e5YM9z\nio6e28eBY82sb8hNHRvmZSbXlSTdWBnzBeBfwNvAD3Kdni7cryOIso2vAAvD6wtE5aN/BRYDc4B+\nYX0jakH1NvAqUauMnO9HJ/f988Cfw/uPAfOAJcDvgZ5hfkWYXhKWfyzX6e7kvo4GFoTz/BDQt9DP\nMXAD8CbwGvBboGchnmegmqgepIEo93dRZ84tcGHY/yXABR1Jg7qYEBEpcsVSNCQiIq1QIBARKXIK\nBCIiRU6BQESkyCkQiIgUOQUCkRRm1mRmC2OvLuut1syGx3uZFNkRlLW/ikjRqXX30blOhEh3UY5A\nJENmttTMfmJmr5rZPDP7eJg/3MyeCv3D/9XMhoX5g8zsj2b2cniNC5sqNbP/DX3tP2FmlTnbKREU\nCETSqUwpGjortmyjux8A3EbUCyrArcA97n4gcB9wS5h/C/A3dz+IqG+g18P8kcBUd98P2ACcnuX9\nEWmTniwWSWFmH7p77zTzlwJHufs7oaO/Ve7e38zWEPUd3xDmr3T3AWa2Ghji7lti2xgOPOnRgCOY\n2dVAubv/f9nfM5H0lCMQ6Rhv5X1HbIm9b0J1dZJjCgQiHXNW7O8/w/t/EPWECnAO8Gx4/1fgEmge\nY3mX7kqkSEfoTkRkW5VmtjA2/Zi7J5uQ9jWzV4ju6s8O875JNHrYVUQjiV0Q5l8G3GlmFxHd+V9C\n1MukyA5FdQQiGQp1BGPdfU2u0yLSlVQ0JCJS5JQjEBEpcsoRiIgUOQUCEZEip0AgIlLkFAhERIqc\nAoGISJH7/wFexKl5Ud/RVgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}