{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_B-T-Median.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0rXl9KMAmmxd4AX/u9JkQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DipankarJDutta/DipankarJDutta-Biomarker-discovery-from-B-T-cells-in-FASD-GDM-with-LSTM/blob/Visualisation/LSTM_B_T_Median_base-model_visualized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfPN8Hkp_22L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading essentials\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "from numpy import reshape\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN3LIBHE9XH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fixing random seed to 007 for reproducibility\n",
        "from numpy.random import seed\n",
        "seed(7)\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMq2vKCJNlmL",
        "colab_type": "code",
        "outputId": "3aa69896-5f81-45ce-c6a6-0d20baae3d4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Load data\n",
        "dataset = loadtxt('B-T-median.csv', delimiter = ',')\n",
        "print (dataset)\n",
        "print(np.size(dataset))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.361 0.723 0.802 ... 0.379 0.833 1.   ]\n",
            " [0.692 0.676 0.686 ... 0.    0.    1.   ]\n",
            " [1.    1.    0.711 ... 0.    0.    0.   ]\n",
            " ...\n",
            " [1.    0.824 0.158 ... 0.    0.    0.   ]\n",
            " [1.    0.866 0.377 ... 0.    0.    0.   ]\n",
            " [1.    0.839 0.083 ... 0.899 0.882 1.   ]]\n",
            "1680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf6EYfq1OSND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape 2D dataset into a 3D dataset with columns as features with one time-step\n",
        "x = dataset.reshape(56, 1, 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TND5ZTvdTwij",
        "colab_type": "code",
        "outputId": "9e4e8426-fe4b-4923-f266-cf448f7febe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Confirm data shape of 56 samples (rows), 1 time-step per feature (columns as features with one time-step), 29 features/z-scored inclevel gene values (16 from B-cells & 13 from T-cells, in that order) & the last 1 column as binary output of good (1) and bad (0) learners as differentiated by the population median.\n",
        "print(x.shape)\n",
        "print(x.size)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(56, 1, 30)\n",
            "1680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKPgSQezs0kL",
        "colab_type": "code",
        "outputId": "cd77df7d-eaa6-4d40-951c-5cfdd3c6caa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#print x\n",
        "print(x)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[0.361 0.723 0.802 ... 0.379 0.833 1.   ]]\n",
            "\n",
            " [[0.692 0.676 0.686 ... 0.    0.    1.   ]]\n",
            "\n",
            " [[1.    1.    0.711 ... 0.    0.    0.   ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[1.    0.824 0.158 ... 0.    0.    0.   ]]\n",
            "\n",
            " [[1.    0.866 0.377 ... 0.    0.    0.   ]]\n",
            "\n",
            " [[1.    0.839 0.083 ... 0.899 0.882 1.   ]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbfEdKabnlcK",
        "colab_type": "code",
        "outputId": "1b077e5b-85a2-43fc-8859-8969977ce2da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "#Specify binary output of good (1) and bad (0) learners, y, in x & print y. Learner type differentiated by population median.\n",
        "y = x [:, :, -1]\n",
        "print(y)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBx8zDJlVjje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define LSTM One to One Model with Sigmoid activation on the output layer for binary classification\n",
        "model = Sequential()\n",
        "model.add(LSTM(5, input_shape=(1,30)))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1vO6vpKmAgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the model \n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x30BNEbImxA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "669b4f9d-d4ca-41ce-c07a-d1e483fc6c98"
      },
      "source": [
        "#Fit the model with a 80-20 split of dataset & shuffling sample order within an epoch\n",
        "history = model.fit(x, y, validation_split = 0.2, batch_size = 8, epochs = 1000, shuffle = True, verbose=1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 44 samples, validate on 12 samples\n",
            "Epoch 1/1000\n",
            "44/44 [==============================] - 1s 29ms/step - loss: 0.7141 - acc: 0.4773 - val_loss: 0.7110 - val_acc: 0.4167\n",
            "Epoch 2/1000\n",
            "44/44 [==============================] - 0s 482us/step - loss: 0.7096 - acc: 0.4773 - val_loss: 0.7019 - val_acc: 0.4167\n",
            "Epoch 3/1000\n",
            "44/44 [==============================] - 0s 561us/step - loss: 0.7043 - acc: 0.4318 - val_loss: 0.6955 - val_acc: 0.3333\n",
            "Epoch 4/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.7012 - acc: 0.3636 - val_loss: 0.6886 - val_acc: 0.5000\n",
            "Epoch 5/1000\n",
            "44/44 [==============================] - 0s 443us/step - loss: 0.6989 - acc: 0.5000 - val_loss: 0.6820 - val_acc: 0.7500\n",
            "Epoch 6/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.6950 - acc: 0.5227 - val_loss: 0.6785 - val_acc: 0.7500\n",
            "Epoch 7/1000\n",
            "44/44 [==============================] - 0s 432us/step - loss: 0.6929 - acc: 0.5227 - val_loss: 0.6753 - val_acc: 0.7500\n",
            "Epoch 8/1000\n",
            "44/44 [==============================] - 0s 493us/step - loss: 0.6903 - acc: 0.5227 - val_loss: 0.6739 - val_acc: 0.7500\n",
            "Epoch 9/1000\n",
            "44/44 [==============================] - 0s 420us/step - loss: 0.6886 - acc: 0.5227 - val_loss: 0.6729 - val_acc: 0.7500\n",
            "Epoch 10/1000\n",
            "44/44 [==============================] - 0s 434us/step - loss: 0.6865 - acc: 0.5455 - val_loss: 0.6714 - val_acc: 0.7500\n",
            "Epoch 11/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.6843 - acc: 0.5682 - val_loss: 0.6688 - val_acc: 0.7500\n",
            "Epoch 12/1000\n",
            "44/44 [==============================] - 0s 459us/step - loss: 0.6822 - acc: 0.5227 - val_loss: 0.6649 - val_acc: 0.7500\n",
            "Epoch 13/1000\n",
            "44/44 [==============================] - 0s 407us/step - loss: 0.6810 - acc: 0.5682 - val_loss: 0.6598 - val_acc: 0.8333\n",
            "Epoch 14/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.6774 - acc: 0.5455 - val_loss: 0.6579 - val_acc: 0.8333\n",
            "Epoch 15/1000\n",
            "44/44 [==============================] - 0s 428us/step - loss: 0.6752 - acc: 0.5455 - val_loss: 0.6549 - val_acc: 0.8333\n",
            "Epoch 16/1000\n",
            "44/44 [==============================] - 0s 412us/step - loss: 0.6726 - acc: 0.5455 - val_loss: 0.6533 - val_acc: 0.8333\n",
            "Epoch 17/1000\n",
            "44/44 [==============================] - 0s 444us/step - loss: 0.6704 - acc: 0.5455 - val_loss: 0.6503 - val_acc: 0.8333\n",
            "Epoch 18/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.6676 - acc: 0.5227 - val_loss: 0.6505 - val_acc: 0.8333\n",
            "Epoch 19/1000\n",
            "44/44 [==============================] - 0s 421us/step - loss: 0.6646 - acc: 0.5682 - val_loss: 0.6484 - val_acc: 0.8333\n",
            "Epoch 20/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.6624 - acc: 0.5682 - val_loss: 0.6462 - val_acc: 0.8333\n",
            "Epoch 21/1000\n",
            "44/44 [==============================] - 0s 447us/step - loss: 0.6588 - acc: 0.5909 - val_loss: 0.6462 - val_acc: 0.8333\n",
            "Epoch 22/1000\n",
            "44/44 [==============================] - 0s 392us/step - loss: 0.6564 - acc: 0.7273 - val_loss: 0.6466 - val_acc: 0.7500\n",
            "Epoch 23/1000\n",
            "44/44 [==============================] - 0s 399us/step - loss: 0.6533 - acc: 0.7273 - val_loss: 0.6448 - val_acc: 0.7500\n",
            "Epoch 24/1000\n",
            "44/44 [==============================] - 0s 431us/step - loss: 0.6498 - acc: 0.7727 - val_loss: 0.6432 - val_acc: 0.7500\n",
            "Epoch 25/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.6461 - acc: 0.7727 - val_loss: 0.6399 - val_acc: 0.7500\n",
            "Epoch 26/1000\n",
            "44/44 [==============================] - 0s 394us/step - loss: 0.6423 - acc: 0.7955 - val_loss: 0.6377 - val_acc: 0.7500\n",
            "Epoch 27/1000\n",
            "44/44 [==============================] - 0s 488us/step - loss: 0.6384 - acc: 0.8182 - val_loss: 0.6344 - val_acc: 0.8333\n",
            "Epoch 28/1000\n",
            "44/44 [==============================] - 0s 543us/step - loss: 0.6342 - acc: 0.7955 - val_loss: 0.6302 - val_acc: 0.8333\n",
            "Epoch 29/1000\n",
            "44/44 [==============================] - 0s 560us/step - loss: 0.6304 - acc: 0.7727 - val_loss: 0.6262 - val_acc: 0.9167\n",
            "Epoch 30/1000\n",
            "44/44 [==============================] - 0s 587us/step - loss: 0.6265 - acc: 0.7955 - val_loss: 0.6226 - val_acc: 0.9167\n",
            "Epoch 31/1000\n",
            "44/44 [==============================] - 0s 564us/step - loss: 0.6221 - acc: 0.7727 - val_loss: 0.6168 - val_acc: 0.8333\n",
            "Epoch 32/1000\n",
            "44/44 [==============================] - 0s 531us/step - loss: 0.6196 - acc: 0.7500 - val_loss: 0.6089 - val_acc: 0.8333\n",
            "Epoch 33/1000\n",
            "44/44 [==============================] - 0s 541us/step - loss: 0.6154 - acc: 0.7045 - val_loss: 0.6034 - val_acc: 0.8333\n",
            "Epoch 34/1000\n",
            "44/44 [==============================] - 0s 605us/step - loss: 0.6105 - acc: 0.7273 - val_loss: 0.6031 - val_acc: 0.8333\n",
            "Epoch 35/1000\n",
            "44/44 [==============================] - 0s 552us/step - loss: 0.6072 - acc: 0.8409 - val_loss: 0.6054 - val_acc: 0.9167\n",
            "Epoch 36/1000\n",
            "44/44 [==============================] - 0s 765us/step - loss: 0.6023 - acc: 0.8636 - val_loss: 0.6007 - val_acc: 0.9167\n",
            "Epoch 37/1000\n",
            "44/44 [==============================] - 0s 1ms/step - loss: 0.5976 - acc: 0.8864 - val_loss: 0.6018 - val_acc: 0.8333\n",
            "Epoch 38/1000\n",
            "44/44 [==============================] - 0s 581us/step - loss: 0.5929 - acc: 0.9091 - val_loss: 0.5985 - val_acc: 0.8333\n",
            "Epoch 39/1000\n",
            "44/44 [==============================] - 0s 556us/step - loss: 0.5885 - acc: 0.9318 - val_loss: 0.5909 - val_acc: 0.9167\n",
            "Epoch 40/1000\n",
            "44/44 [==============================] - 0s 620us/step - loss: 0.5836 - acc: 0.8864 - val_loss: 0.5856 - val_acc: 0.9167\n",
            "Epoch 41/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.5792 - acc: 0.8864 - val_loss: 0.5850 - val_acc: 0.9167\n",
            "Epoch 42/1000\n",
            "44/44 [==============================] - 0s 417us/step - loss: 0.5732 - acc: 0.9318 - val_loss: 0.5813 - val_acc: 0.9167\n",
            "Epoch 43/1000\n",
            "44/44 [==============================] - 0s 449us/step - loss: 0.5678 - acc: 0.9318 - val_loss: 0.5783 - val_acc: 0.9167\n",
            "Epoch 44/1000\n",
            "44/44 [==============================] - 0s 481us/step - loss: 0.5621 - acc: 0.9545 - val_loss: 0.5776 - val_acc: 0.8333\n",
            "Epoch 45/1000\n",
            "44/44 [==============================] - 0s 464us/step - loss: 0.5572 - acc: 0.9773 - val_loss: 0.5756 - val_acc: 0.8333\n",
            "Epoch 46/1000\n",
            "44/44 [==============================] - 0s 460us/step - loss: 0.5519 - acc: 0.9773 - val_loss: 0.5731 - val_acc: 0.8333\n",
            "Epoch 47/1000\n",
            "44/44 [==============================] - 0s 431us/step - loss: 0.5471 - acc: 0.9773 - val_loss: 0.5706 - val_acc: 0.8333\n",
            "Epoch 48/1000\n",
            "44/44 [==============================] - 0s 452us/step - loss: 0.5416 - acc: 0.9773 - val_loss: 0.5623 - val_acc: 0.8333\n",
            "Epoch 49/1000\n",
            "44/44 [==============================] - 0s 585us/step - loss: 0.5351 - acc: 0.9773 - val_loss: 0.5540 - val_acc: 0.8333\n",
            "Epoch 50/1000\n",
            "44/44 [==============================] - 0s 501us/step - loss: 0.5297 - acc: 0.9773 - val_loss: 0.5475 - val_acc: 0.8333\n",
            "Epoch 51/1000\n",
            "44/44 [==============================] - 0s 533us/step - loss: 0.5276 - acc: 0.9318 - val_loss: 0.5342 - val_acc: 0.9167\n",
            "Epoch 52/1000\n",
            "44/44 [==============================] - 0s 447us/step - loss: 0.5203 - acc: 0.9545 - val_loss: 0.5363 - val_acc: 0.9167\n",
            "Epoch 53/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.5140 - acc: 0.9773 - val_loss: 0.5344 - val_acc: 0.9167\n",
            "Epoch 54/1000\n",
            "44/44 [==============================] - 0s 503us/step - loss: 0.5086 - acc: 0.9773 - val_loss: 0.5310 - val_acc: 0.8333\n",
            "Epoch 55/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.5036 - acc: 0.9773 - val_loss: 0.5288 - val_acc: 0.8333\n",
            "Epoch 56/1000\n",
            "44/44 [==============================] - 0s 428us/step - loss: 0.4982 - acc: 0.9773 - val_loss: 0.5237 - val_acc: 0.8333\n",
            "Epoch 57/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.4928 - acc: 0.9773 - val_loss: 0.5224 - val_acc: 0.8333\n",
            "Epoch 58/1000\n",
            "44/44 [==============================] - 0s 462us/step - loss: 0.4875 - acc: 0.9773 - val_loss: 0.5182 - val_acc: 0.8333\n",
            "Epoch 59/1000\n",
            "44/44 [==============================] - 0s 636us/step - loss: 0.4822 - acc: 0.9773 - val_loss: 0.5110 - val_acc: 0.9167\n",
            "Epoch 60/1000\n",
            "44/44 [==============================] - 0s 516us/step - loss: 0.4764 - acc: 0.9773 - val_loss: 0.5090 - val_acc: 0.8333\n",
            "Epoch 61/1000\n",
            "44/44 [==============================] - 0s 427us/step - loss: 0.4707 - acc: 0.9773 - val_loss: 0.5099 - val_acc: 0.8333\n",
            "Epoch 62/1000\n",
            "44/44 [==============================] - 0s 431us/step - loss: 0.4653 - acc: 0.9773 - val_loss: 0.5078 - val_acc: 0.8333\n",
            "Epoch 63/1000\n",
            "44/44 [==============================] - 0s 524us/step - loss: 0.4597 - acc: 0.9773 - val_loss: 0.5091 - val_acc: 0.8333\n",
            "Epoch 64/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.4556 - acc: 0.9773 - val_loss: 0.5093 - val_acc: 0.8333\n",
            "Epoch 65/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.4493 - acc: 0.9773 - val_loss: 0.5037 - val_acc: 0.8333\n",
            "Epoch 66/1000\n",
            "44/44 [==============================] - 0s 466us/step - loss: 0.4442 - acc: 0.9773 - val_loss: 0.4926 - val_acc: 0.8333\n",
            "Epoch 67/1000\n",
            "44/44 [==============================] - 0s 554us/step - loss: 0.4377 - acc: 0.9773 - val_loss: 0.4892 - val_acc: 0.8333\n",
            "Epoch 68/1000\n",
            "44/44 [==============================] - 0s 570us/step - loss: 0.4320 - acc: 0.9773 - val_loss: 0.4893 - val_acc: 0.8333\n",
            "Epoch 69/1000\n",
            "44/44 [==============================] - 0s 639us/step - loss: 0.4269 - acc: 0.9773 - val_loss: 0.4865 - val_acc: 0.8333\n",
            "Epoch 70/1000\n",
            "44/44 [==============================] - 0s 536us/step - loss: 0.4214 - acc: 0.9773 - val_loss: 0.4856 - val_acc: 0.8333\n",
            "Epoch 71/1000\n",
            "44/44 [==============================] - 0s 570us/step - loss: 0.4180 - acc: 0.9773 - val_loss: 0.4712 - val_acc: 0.8333\n",
            "Epoch 72/1000\n",
            "44/44 [==============================] - 0s 525us/step - loss: 0.4099 - acc: 0.9773 - val_loss: 0.4718 - val_acc: 0.8333\n",
            "Epoch 73/1000\n",
            "44/44 [==============================] - 0s 502us/step - loss: 0.4042 - acc: 0.9773 - val_loss: 0.4686 - val_acc: 0.8333\n",
            "Epoch 74/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.3981 - acc: 1.0000 - val_loss: 0.4720 - val_acc: 0.8333\n",
            "Epoch 75/1000\n",
            "44/44 [==============================] - 0s 538us/step - loss: 0.3920 - acc: 1.0000 - val_loss: 0.4701 - val_acc: 0.8333\n",
            "Epoch 76/1000\n",
            "44/44 [==============================] - 0s 568us/step - loss: 0.3872 - acc: 1.0000 - val_loss: 0.4697 - val_acc: 0.8333\n",
            "Epoch 77/1000\n",
            "44/44 [==============================] - 0s 506us/step - loss: 0.3805 - acc: 1.0000 - val_loss: 0.4603 - val_acc: 0.8333\n",
            "Epoch 78/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.3746 - acc: 1.0000 - val_loss: 0.4510 - val_acc: 0.8333\n",
            "Epoch 79/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.3680 - acc: 1.0000 - val_loss: 0.4468 - val_acc: 0.8333\n",
            "Epoch 80/1000\n",
            "44/44 [==============================] - 0s 449us/step - loss: 0.3610 - acc: 1.0000 - val_loss: 0.4516 - val_acc: 0.8333\n",
            "Epoch 81/1000\n",
            "44/44 [==============================] - 0s 526us/step - loss: 0.3561 - acc: 1.0000 - val_loss: 0.4551 - val_acc: 0.8333\n",
            "Epoch 82/1000\n",
            "44/44 [==============================] - 0s 500us/step - loss: 0.3489 - acc: 1.0000 - val_loss: 0.4478 - val_acc: 0.8333\n",
            "Epoch 83/1000\n",
            "44/44 [==============================] - 0s 409us/step - loss: 0.3424 - acc: 1.0000 - val_loss: 0.4375 - val_acc: 0.8333\n",
            "Epoch 84/1000\n",
            "44/44 [==============================] - 0s 498us/step - loss: 0.3385 - acc: 1.0000 - val_loss: 0.4210 - val_acc: 0.9167\n",
            "Epoch 85/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.3319 - acc: 1.0000 - val_loss: 0.4241 - val_acc: 0.8333\n",
            "Epoch 86/1000\n",
            "44/44 [==============================] - 0s 523us/step - loss: 0.3264 - acc: 1.0000 - val_loss: 0.4316 - val_acc: 0.8333\n",
            "Epoch 87/1000\n",
            "44/44 [==============================] - 0s 492us/step - loss: 0.3203 - acc: 1.0000 - val_loss: 0.4273 - val_acc: 0.8333\n",
            "Epoch 88/1000\n",
            "44/44 [==============================] - 0s 476us/step - loss: 0.3147 - acc: 1.0000 - val_loss: 0.4190 - val_acc: 0.8333\n",
            "Epoch 89/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.3105 - acc: 1.0000 - val_loss: 0.4106 - val_acc: 0.8333\n",
            "Epoch 90/1000\n",
            "44/44 [==============================] - 0s 586us/step - loss: 0.3057 - acc: 1.0000 - val_loss: 0.4179 - val_acc: 0.8333\n",
            "Epoch 91/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.2999 - acc: 1.0000 - val_loss: 0.4103 - val_acc: 0.8333\n",
            "Epoch 92/1000\n",
            "44/44 [==============================] - 0s 485us/step - loss: 0.2949 - acc: 1.0000 - val_loss: 0.4111 - val_acc: 0.8333\n",
            "Epoch 93/1000\n",
            "44/44 [==============================] - 0s 458us/step - loss: 0.2901 - acc: 1.0000 - val_loss: 0.4056 - val_acc: 0.8333\n",
            "Epoch 94/1000\n",
            "44/44 [==============================] - 0s 452us/step - loss: 0.2862 - acc: 1.0000 - val_loss: 0.3928 - val_acc: 0.9167\n",
            "Epoch 95/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.2816 - acc: 1.0000 - val_loss: 0.3970 - val_acc: 0.8333\n",
            "Epoch 96/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.2770 - acc: 1.0000 - val_loss: 0.3949 - val_acc: 0.8333\n",
            "Epoch 97/1000\n",
            "44/44 [==============================] - 0s 451us/step - loss: 0.2730 - acc: 1.0000 - val_loss: 0.3798 - val_acc: 0.9167\n",
            "Epoch 98/1000\n",
            "44/44 [==============================] - 0s 470us/step - loss: 0.2676 - acc: 1.0000 - val_loss: 0.3779 - val_acc: 0.9167\n",
            "Epoch 99/1000\n",
            "44/44 [==============================] - 0s 586us/step - loss: 0.2638 - acc: 1.0000 - val_loss: 0.3837 - val_acc: 0.8333\n",
            "Epoch 100/1000\n",
            "44/44 [==============================] - 0s 609us/step - loss: 0.2596 - acc: 1.0000 - val_loss: 0.3861 - val_acc: 0.8333\n",
            "Epoch 101/1000\n",
            "44/44 [==============================] - 0s 537us/step - loss: 0.2548 - acc: 1.0000 - val_loss: 0.3833 - val_acc: 0.8333\n",
            "Epoch 102/1000\n",
            "44/44 [==============================] - 0s 623us/step - loss: 0.2509 - acc: 1.0000 - val_loss: 0.3742 - val_acc: 0.9167\n",
            "Epoch 103/1000\n",
            "44/44 [==============================] - 0s 468us/step - loss: 0.2467 - acc: 1.0000 - val_loss: 0.3715 - val_acc: 0.9167\n",
            "Epoch 104/1000\n",
            "44/44 [==============================] - 0s 658us/step - loss: 0.2430 - acc: 1.0000 - val_loss: 0.3735 - val_acc: 0.8333\n",
            "Epoch 105/1000\n",
            "44/44 [==============================] - 0s 537us/step - loss: 0.2393 - acc: 1.0000 - val_loss: 0.3694 - val_acc: 0.9167\n",
            "Epoch 106/1000\n",
            "44/44 [==============================] - 0s 430us/step - loss: 0.2359 - acc: 1.0000 - val_loss: 0.3655 - val_acc: 0.9167\n",
            "Epoch 107/1000\n",
            "44/44 [==============================] - 0s 414us/step - loss: 0.2321 - acc: 1.0000 - val_loss: 0.3587 - val_acc: 0.9167\n",
            "Epoch 108/1000\n",
            "44/44 [==============================] - 0s 475us/step - loss: 0.2283 - acc: 1.0000 - val_loss: 0.3465 - val_acc: 0.9167\n",
            "Epoch 109/1000\n",
            "44/44 [==============================] - 0s 436us/step - loss: 0.2255 - acc: 1.0000 - val_loss: 0.3441 - val_acc: 0.9167\n",
            "Epoch 110/1000\n",
            "44/44 [==============================] - 0s 432us/step - loss: 0.2223 - acc: 1.0000 - val_loss: 0.3387 - val_acc: 0.9167\n",
            "Epoch 111/1000\n",
            "44/44 [==============================] - 0s 410us/step - loss: 0.2187 - acc: 1.0000 - val_loss: 0.3418 - val_acc: 0.9167\n",
            "Epoch 112/1000\n",
            "44/44 [==============================] - 0s 462us/step - loss: 0.2154 - acc: 1.0000 - val_loss: 0.3457 - val_acc: 0.9167\n",
            "Epoch 113/1000\n",
            "44/44 [==============================] - 0s 517us/step - loss: 0.2126 - acc: 1.0000 - val_loss: 0.3459 - val_acc: 0.9167\n",
            "Epoch 114/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.2110 - acc: 1.0000 - val_loss: 0.3351 - val_acc: 0.9167\n",
            "Epoch 115/1000\n",
            "44/44 [==============================] - 0s 456us/step - loss: 0.2066 - acc: 1.0000 - val_loss: 0.3371 - val_acc: 0.9167\n",
            "Epoch 116/1000\n",
            "44/44 [==============================] - 0s 461us/step - loss: 0.2036 - acc: 1.0000 - val_loss: 0.3339 - val_acc: 0.9167\n",
            "Epoch 117/1000\n",
            "44/44 [==============================] - 0s 465us/step - loss: 0.2006 - acc: 1.0000 - val_loss: 0.3277 - val_acc: 0.9167\n",
            "Epoch 118/1000\n",
            "44/44 [==============================] - 0s 535us/step - loss: 0.1977 - acc: 1.0000 - val_loss: 0.3264 - val_acc: 0.9167\n",
            "Epoch 119/1000\n",
            "44/44 [==============================] - 0s 638us/step - loss: 0.1952 - acc: 1.0000 - val_loss: 0.3271 - val_acc: 0.9167\n",
            "Epoch 120/1000\n",
            "44/44 [==============================] - 0s 575us/step - loss: 0.1927 - acc: 1.0000 - val_loss: 0.3236 - val_acc: 0.9167\n",
            "Epoch 121/1000\n",
            "44/44 [==============================] - 0s 526us/step - loss: 0.1894 - acc: 1.0000 - val_loss: 0.3162 - val_acc: 0.9167\n",
            "Epoch 122/1000\n",
            "44/44 [==============================] - 0s 569us/step - loss: 0.1868 - acc: 1.0000 - val_loss: 0.3126 - val_acc: 0.9167\n",
            "Epoch 123/1000\n",
            "44/44 [==============================] - 0s 630us/step - loss: 0.1841 - acc: 1.0000 - val_loss: 0.3072 - val_acc: 0.9167\n",
            "Epoch 124/1000\n",
            "44/44 [==============================] - 0s 549us/step - loss: 0.1817 - acc: 1.0000 - val_loss: 0.3059 - val_acc: 0.9167\n",
            "Epoch 125/1000\n",
            "44/44 [==============================] - 0s 577us/step - loss: 0.1790 - acc: 1.0000 - val_loss: 0.3045 - val_acc: 0.9167\n",
            "Epoch 126/1000\n",
            "44/44 [==============================] - 0s 555us/step - loss: 0.1765 - acc: 1.0000 - val_loss: 0.3081 - val_acc: 0.9167\n",
            "Epoch 127/1000\n",
            "44/44 [==============================] - 0s 545us/step - loss: 0.1751 - acc: 1.0000 - val_loss: 0.3008 - val_acc: 0.9167\n",
            "Epoch 128/1000\n",
            "44/44 [==============================] - 0s 540us/step - loss: 0.1722 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.9167\n",
            "Epoch 129/1000\n",
            "44/44 [==============================] - 0s 546us/step - loss: 0.1701 - acc: 1.0000 - val_loss: 0.2910 - val_acc: 0.9167\n",
            "Epoch 130/1000\n",
            "44/44 [==============================] - 0s 564us/step - loss: 0.1673 - acc: 1.0000 - val_loss: 0.2905 - val_acc: 0.9167\n",
            "Epoch 131/1000\n",
            "44/44 [==============================] - 0s 569us/step - loss: 0.1650 - acc: 1.0000 - val_loss: 0.2915 - val_acc: 0.9167\n",
            "Epoch 132/1000\n",
            "44/44 [==============================] - 0s 492us/step - loss: 0.1630 - acc: 1.0000 - val_loss: 0.2878 - val_acc: 0.9167\n",
            "Epoch 133/1000\n",
            "44/44 [==============================] - 0s 452us/step - loss: 0.1607 - acc: 1.0000 - val_loss: 0.2880 - val_acc: 0.9167\n",
            "Epoch 134/1000\n",
            "44/44 [==============================] - 0s 582us/step - loss: 0.1584 - acc: 1.0000 - val_loss: 0.2832 - val_acc: 0.9167\n",
            "Epoch 135/1000\n",
            "44/44 [==============================] - 0s 519us/step - loss: 0.1566 - acc: 1.0000 - val_loss: 0.2795 - val_acc: 0.9167\n",
            "Epoch 136/1000\n",
            "44/44 [==============================] - 0s 740us/step - loss: 0.1542 - acc: 1.0000 - val_loss: 0.2708 - val_acc: 0.9167\n",
            "Epoch 137/1000\n",
            "44/44 [==============================] - 0s 575us/step - loss: 0.1524 - acc: 1.0000 - val_loss: 0.2669 - val_acc: 0.9167\n",
            "Epoch 138/1000\n",
            "44/44 [==============================] - 0s 487us/step - loss: 0.1505 - acc: 1.0000 - val_loss: 0.2654 - val_acc: 0.9167\n",
            "Epoch 139/1000\n",
            "44/44 [==============================] - 0s 530us/step - loss: 0.1490 - acc: 1.0000 - val_loss: 0.2699 - val_acc: 0.9167\n",
            "Epoch 140/1000\n",
            "44/44 [==============================] - 0s 460us/step - loss: 0.1466 - acc: 1.0000 - val_loss: 0.2683 - val_acc: 0.9167\n",
            "Epoch 141/1000\n",
            "44/44 [==============================] - 0s 491us/step - loss: 0.1445 - acc: 1.0000 - val_loss: 0.2625 - val_acc: 0.9167\n",
            "Epoch 142/1000\n",
            "44/44 [==============================] - 0s 497us/step - loss: 0.1433 - acc: 1.0000 - val_loss: 0.2551 - val_acc: 0.9167\n",
            "Epoch 143/1000\n",
            "44/44 [==============================] - 0s 528us/step - loss: 0.1412 - acc: 1.0000 - val_loss: 0.2545 - val_acc: 0.9167\n",
            "Epoch 144/1000\n",
            "44/44 [==============================] - 0s 495us/step - loss: 0.1391 - acc: 1.0000 - val_loss: 0.2584 - val_acc: 0.9167\n",
            "Epoch 145/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.1371 - acc: 1.0000 - val_loss: 0.2623 - val_acc: 0.9167\n",
            "Epoch 146/1000\n",
            "44/44 [==============================] - 0s 474us/step - loss: 0.1357 - acc: 1.0000 - val_loss: 0.2589 - val_acc: 0.9167\n",
            "Epoch 147/1000\n",
            "44/44 [==============================] - 0s 426us/step - loss: 0.1339 - acc: 1.0000 - val_loss: 0.2543 - val_acc: 0.9167\n",
            "Epoch 148/1000\n",
            "44/44 [==============================] - 0s 463us/step - loss: 0.1330 - acc: 1.0000 - val_loss: 0.2570 - val_acc: 0.9167\n",
            "Epoch 149/1000\n",
            "44/44 [==============================] - 0s 491us/step - loss: 0.1305 - acc: 1.0000 - val_loss: 0.2495 - val_acc: 0.9167\n",
            "Epoch 150/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.1294 - acc: 1.0000 - val_loss: 0.2405 - val_acc: 0.9167\n",
            "Epoch 151/1000\n",
            "44/44 [==============================] - 0s 419us/step - loss: 0.1278 - acc: 1.0000 - val_loss: 0.2431 - val_acc: 0.9167\n",
            "Epoch 152/1000\n",
            "44/44 [==============================] - 0s 488us/step - loss: 0.1259 - acc: 1.0000 - val_loss: 0.2425 - val_acc: 0.9167\n",
            "Epoch 153/1000\n",
            "44/44 [==============================] - 0s 520us/step - loss: 0.1245 - acc: 1.0000 - val_loss: 0.2402 - val_acc: 0.9167\n",
            "Epoch 154/1000\n",
            "44/44 [==============================] - 0s 465us/step - loss: 0.1228 - acc: 1.0000 - val_loss: 0.2334 - val_acc: 0.9167\n",
            "Epoch 155/1000\n",
            "44/44 [==============================] - 0s 458us/step - loss: 0.1216 - acc: 1.0000 - val_loss: 0.2306 - val_acc: 0.9167\n",
            "Epoch 156/1000\n",
            "44/44 [==============================] - 0s 640us/step - loss: 0.1201 - acc: 1.0000 - val_loss: 0.2302 - val_acc: 0.9167\n",
            "Epoch 157/1000\n",
            "44/44 [==============================] - 0s 455us/step - loss: 0.1184 - acc: 1.0000 - val_loss: 0.2346 - val_acc: 0.9167\n",
            "Epoch 158/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.1177 - acc: 1.0000 - val_loss: 0.2381 - val_acc: 0.9167\n",
            "Epoch 159/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.1160 - acc: 1.0000 - val_loss: 0.2308 - val_acc: 0.9167\n",
            "Epoch 160/1000\n",
            "44/44 [==============================] - 0s 502us/step - loss: 0.1144 - acc: 1.0000 - val_loss: 0.2283 - val_acc: 0.9167\n",
            "Epoch 161/1000\n",
            "44/44 [==============================] - 0s 484us/step - loss: 0.1131 - acc: 1.0000 - val_loss: 0.2236 - val_acc: 0.9167\n",
            "Epoch 162/1000\n",
            "44/44 [==============================] - 0s 434us/step - loss: 0.1118 - acc: 1.0000 - val_loss: 0.2227 - val_acc: 0.9167\n",
            "Epoch 163/1000\n",
            "44/44 [==============================] - 0s 465us/step - loss: 0.1104 - acc: 1.0000 - val_loss: 0.2226 - val_acc: 0.9167\n",
            "Epoch 164/1000\n",
            "44/44 [==============================] - 0s 518us/step - loss: 0.1092 - acc: 1.0000 - val_loss: 0.2225 - val_acc: 0.9167\n",
            "Epoch 165/1000\n",
            "44/44 [==============================] - 0s 475us/step - loss: 0.1082 - acc: 1.0000 - val_loss: 0.2168 - val_acc: 0.9167\n",
            "Epoch 166/1000\n",
            "44/44 [==============================] - 0s 546us/step - loss: 0.1067 - acc: 1.0000 - val_loss: 0.2153 - val_acc: 0.9167\n",
            "Epoch 167/1000\n",
            "44/44 [==============================] - 0s 436us/step - loss: 0.1055 - acc: 1.0000 - val_loss: 0.2118 - val_acc: 0.9167\n",
            "Epoch 168/1000\n",
            "44/44 [==============================] - 0s 505us/step - loss: 0.1044 - acc: 1.0000 - val_loss: 0.2064 - val_acc: 0.9167\n",
            "Epoch 169/1000\n",
            "44/44 [==============================] - 0s 427us/step - loss: 0.1033 - acc: 1.0000 - val_loss: 0.2057 - val_acc: 0.9167\n",
            "Epoch 170/1000\n",
            "44/44 [==============================] - 0s 463us/step - loss: 0.1020 - acc: 1.0000 - val_loss: 0.2063 - val_acc: 0.9167\n",
            "Epoch 171/1000\n",
            "44/44 [==============================] - 0s 504us/step - loss: 0.1009 - acc: 1.0000 - val_loss: 0.2051 - val_acc: 0.9167\n",
            "Epoch 172/1000\n",
            "44/44 [==============================] - 0s 465us/step - loss: 0.0998 - acc: 1.0000 - val_loss: 0.2019 - val_acc: 0.9167\n",
            "Epoch 173/1000\n",
            "44/44 [==============================] - 0s 548us/step - loss: 0.0986 - acc: 1.0000 - val_loss: 0.2016 - val_acc: 0.9167\n",
            "Epoch 174/1000\n",
            "44/44 [==============================] - 0s 529us/step - loss: 0.0975 - acc: 1.0000 - val_loss: 0.2007 - val_acc: 0.9167\n",
            "Epoch 175/1000\n",
            "44/44 [==============================] - 0s 532us/step - loss: 0.0963 - acc: 1.0000 - val_loss: 0.2017 - val_acc: 0.9167\n",
            "Epoch 176/1000\n",
            "44/44 [==============================] - 0s 453us/step - loss: 0.0952 - acc: 1.0000 - val_loss: 0.2022 - val_acc: 0.9167\n",
            "Epoch 177/1000\n",
            "44/44 [==============================] - 0s 528us/step - loss: 0.0942 - acc: 1.0000 - val_loss: 0.2013 - val_acc: 0.9167\n",
            "Epoch 178/1000\n",
            "44/44 [==============================] - 0s 563us/step - loss: 0.0933 - acc: 1.0000 - val_loss: 0.2034 - val_acc: 0.9167\n",
            "Epoch 179/1000\n",
            "44/44 [==============================] - 0s 547us/step - loss: 0.0925 - acc: 1.0000 - val_loss: 0.2015 - val_acc: 0.9167\n",
            "Epoch 180/1000\n",
            "44/44 [==============================] - 0s 728us/step - loss: 0.0915 - acc: 1.0000 - val_loss: 0.2007 - val_acc: 0.9167\n",
            "Epoch 181/1000\n",
            "44/44 [==============================] - 0s 558us/step - loss: 0.0910 - acc: 1.0000 - val_loss: 0.2044 - val_acc: 0.9167\n",
            "Epoch 182/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.0896 - acc: 1.0000 - val_loss: 0.2001 - val_acc: 0.9167\n",
            "Epoch 183/1000\n",
            "44/44 [==============================] - 0s 551us/step - loss: 0.0886 - acc: 1.0000 - val_loss: 0.1899 - val_acc: 0.9167\n",
            "Epoch 184/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.0873 - acc: 1.0000 - val_loss: 0.1854 - val_acc: 1.0000\n",
            "Epoch 185/1000\n",
            "44/44 [==============================] - 0s 572us/step - loss: 0.0866 - acc: 1.0000 - val_loss: 0.1798 - val_acc: 1.0000\n",
            "Epoch 186/1000\n",
            "44/44 [==============================] - 0s 518us/step - loss: 0.0858 - acc: 1.0000 - val_loss: 0.1793 - val_acc: 1.0000\n",
            "Epoch 187/1000\n",
            "44/44 [==============================] - 0s 523us/step - loss: 0.0853 - acc: 1.0000 - val_loss: 0.1841 - val_acc: 0.9167\n",
            "Epoch 188/1000\n",
            "44/44 [==============================] - 0s 527us/step - loss: 0.0838 - acc: 1.0000 - val_loss: 0.1818 - val_acc: 1.0000\n",
            "Epoch 189/1000\n",
            "44/44 [==============================] - 0s 531us/step - loss: 0.0830 - acc: 1.0000 - val_loss: 0.1797 - val_acc: 1.0000\n",
            "Epoch 190/1000\n",
            "44/44 [==============================] - 0s 485us/step - loss: 0.0821 - acc: 1.0000 - val_loss: 0.1818 - val_acc: 0.9167\n",
            "Epoch 191/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0814 - acc: 1.0000 - val_loss: 0.1817 - val_acc: 0.9167\n",
            "Epoch 192/1000\n",
            "44/44 [==============================] - 0s 615us/step - loss: 0.0804 - acc: 1.0000 - val_loss: 0.1773 - val_acc: 1.0000\n",
            "Epoch 193/1000\n",
            "44/44 [==============================] - 0s 486us/step - loss: 0.0796 - acc: 1.0000 - val_loss: 0.1750 - val_acc: 1.0000\n",
            "Epoch 194/1000\n",
            "44/44 [==============================] - 0s 456us/step - loss: 0.0787 - acc: 1.0000 - val_loss: 0.1703 - val_acc: 1.0000\n",
            "Epoch 195/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0782 - acc: 1.0000 - val_loss: 0.1668 - val_acc: 1.0000\n",
            "Epoch 196/1000\n",
            "44/44 [==============================] - 0s 461us/step - loss: 0.0773 - acc: 1.0000 - val_loss: 0.1663 - val_acc: 1.0000\n",
            "Epoch 197/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0765 - acc: 1.0000 - val_loss: 0.1670 - val_acc: 1.0000\n",
            "Epoch 198/1000\n",
            "44/44 [==============================] - 0s 459us/step - loss: 0.0757 - acc: 1.0000 - val_loss: 0.1679 - val_acc: 1.0000\n",
            "Epoch 199/1000\n",
            "44/44 [==============================] - 0s 509us/step - loss: 0.0750 - acc: 1.0000 - val_loss: 0.1693 - val_acc: 1.0000\n",
            "Epoch 200/1000\n",
            "44/44 [==============================] - 0s 507us/step - loss: 0.0741 - acc: 1.0000 - val_loss: 0.1682 - val_acc: 1.0000\n",
            "Epoch 201/1000\n",
            "44/44 [==============================] - 0s 470us/step - loss: 0.0735 - acc: 1.0000 - val_loss: 0.1673 - val_acc: 1.0000\n",
            "Epoch 202/1000\n",
            "44/44 [==============================] - 0s 516us/step - loss: 0.0728 - acc: 1.0000 - val_loss: 0.1646 - val_acc: 1.0000\n",
            "Epoch 203/1000\n",
            "44/44 [==============================] - 0s 528us/step - loss: 0.0720 - acc: 1.0000 - val_loss: 0.1653 - val_acc: 1.0000\n",
            "Epoch 204/1000\n",
            "44/44 [==============================] - 0s 493us/step - loss: 0.0713 - acc: 1.0000 - val_loss: 0.1651 - val_acc: 1.0000\n",
            "Epoch 205/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.0707 - acc: 1.0000 - val_loss: 0.1625 - val_acc: 1.0000\n",
            "Epoch 206/1000\n",
            "44/44 [==============================] - 0s 513us/step - loss: 0.0699 - acc: 1.0000 - val_loss: 0.1621 - val_acc: 1.0000\n",
            "Epoch 207/1000\n",
            "44/44 [==============================] - 0s 521us/step - loss: 0.0694 - acc: 1.0000 - val_loss: 0.1602 - val_acc: 1.0000\n",
            "Epoch 208/1000\n",
            "44/44 [==============================] - 0s 564us/step - loss: 0.0686 - acc: 1.0000 - val_loss: 0.1601 - val_acc: 1.0000\n",
            "Epoch 209/1000\n",
            "44/44 [==============================] - 0s 479us/step - loss: 0.0680 - acc: 1.0000 - val_loss: 0.1595 - val_acc: 1.0000\n",
            "Epoch 210/1000\n",
            "44/44 [==============================] - 0s 430us/step - loss: 0.0674 - acc: 1.0000 - val_loss: 0.1581 - val_acc: 1.0000\n",
            "Epoch 211/1000\n",
            "44/44 [==============================] - 0s 476us/step - loss: 0.0666 - acc: 1.0000 - val_loss: 0.1538 - val_acc: 1.0000\n",
            "Epoch 212/1000\n",
            "44/44 [==============================] - 0s 492us/step - loss: 0.0661 - acc: 1.0000 - val_loss: 0.1489 - val_acc: 1.0000\n",
            "Epoch 213/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.0660 - acc: 1.0000 - val_loss: 0.1452 - val_acc: 1.0000\n",
            "Epoch 214/1000\n",
            "44/44 [==============================] - 0s 428us/step - loss: 0.0651 - acc: 1.0000 - val_loss: 0.1486 - val_acc: 1.0000\n",
            "Epoch 215/1000\n",
            "44/44 [==============================] - 0s 444us/step - loss: 0.0642 - acc: 1.0000 - val_loss: 0.1495 - val_acc: 1.0000\n",
            "Epoch 216/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.0636 - acc: 1.0000 - val_loss: 0.1511 - val_acc: 1.0000\n",
            "Epoch 217/1000\n",
            "44/44 [==============================] - 0s 372us/step - loss: 0.0631 - acc: 1.0000 - val_loss: 0.1507 - val_acc: 1.0000\n",
            "Epoch 218/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.0625 - acc: 1.0000 - val_loss: 0.1493 - val_acc: 1.0000\n",
            "Epoch 219/1000\n",
            "44/44 [==============================] - 0s 422us/step - loss: 0.0619 - acc: 1.0000 - val_loss: 0.1474 - val_acc: 1.0000\n",
            "Epoch 220/1000\n",
            "44/44 [==============================] - 0s 434us/step - loss: 0.0615 - acc: 1.0000 - val_loss: 0.1431 - val_acc: 1.0000\n",
            "Epoch 221/1000\n",
            "44/44 [==============================] - 0s 433us/step - loss: 0.0609 - acc: 1.0000 - val_loss: 0.1438 - val_acc: 1.0000\n",
            "Epoch 222/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.0603 - acc: 1.0000 - val_loss: 0.1408 - val_acc: 1.0000\n",
            "Epoch 223/1000\n",
            "44/44 [==============================] - 0s 414us/step - loss: 0.0597 - acc: 1.0000 - val_loss: 0.1402 - val_acc: 1.0000\n",
            "Epoch 224/1000\n",
            "44/44 [==============================] - 0s 536us/step - loss: 0.0592 - acc: 1.0000 - val_loss: 0.1376 - val_acc: 1.0000\n",
            "Epoch 225/1000\n",
            "44/44 [==============================] - 0s 557us/step - loss: 0.0587 - acc: 1.0000 - val_loss: 0.1383 - val_acc: 1.0000\n",
            "Epoch 226/1000\n",
            "44/44 [==============================] - 0s 455us/step - loss: 0.0581 - acc: 1.0000 - val_loss: 0.1360 - val_acc: 1.0000\n",
            "Epoch 227/1000\n",
            "44/44 [==============================] - 0s 420us/step - loss: 0.0576 - acc: 1.0000 - val_loss: 0.1360 - val_acc: 1.0000\n",
            "Epoch 228/1000\n",
            "44/44 [==============================] - 0s 421us/step - loss: 0.0571 - acc: 1.0000 - val_loss: 0.1340 - val_acc: 1.0000\n",
            "Epoch 229/1000\n",
            "44/44 [==============================] - 0s 440us/step - loss: 0.0566 - acc: 1.0000 - val_loss: 0.1334 - val_acc: 1.0000\n",
            "Epoch 230/1000\n",
            "44/44 [==============================] - 0s 458us/step - loss: 0.0562 - acc: 1.0000 - val_loss: 0.1346 - val_acc: 1.0000\n",
            "Epoch 231/1000\n",
            "44/44 [==============================] - 0s 479us/step - loss: 0.0556 - acc: 1.0000 - val_loss: 0.1353 - val_acc: 1.0000\n",
            "Epoch 232/1000\n",
            "44/44 [==============================] - 0s 514us/step - loss: 0.0551 - acc: 1.0000 - val_loss: 0.1339 - val_acc: 1.0000\n",
            "Epoch 233/1000\n",
            "44/44 [==============================] - 0s 471us/step - loss: 0.0546 - acc: 1.0000 - val_loss: 0.1339 - val_acc: 1.0000\n",
            "Epoch 234/1000\n",
            "44/44 [==============================] - 0s 481us/step - loss: 0.0541 - acc: 1.0000 - val_loss: 0.1326 - val_acc: 1.0000\n",
            "Epoch 235/1000\n",
            "44/44 [==============================] - 0s 452us/step - loss: 0.0538 - acc: 1.0000 - val_loss: 0.1276 - val_acc: 1.0000\n",
            "Epoch 236/1000\n",
            "44/44 [==============================] - 0s 429us/step - loss: 0.0533 - acc: 1.0000 - val_loss: 0.1255 - val_acc: 1.0000\n",
            "Epoch 237/1000\n",
            "44/44 [==============================] - 0s 429us/step - loss: 0.0528 - acc: 1.0000 - val_loss: 0.1265 - val_acc: 1.0000\n",
            "Epoch 238/1000\n",
            "44/44 [==============================] - 0s 434us/step - loss: 0.0524 - acc: 1.0000 - val_loss: 0.1286 - val_acc: 1.0000\n",
            "Epoch 239/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.0518 - acc: 1.0000 - val_loss: 0.1268 - val_acc: 1.0000\n",
            "Epoch 240/1000\n",
            "44/44 [==============================] - 0s 451us/step - loss: 0.0514 - acc: 1.0000 - val_loss: 0.1264 - val_acc: 1.0000\n",
            "Epoch 241/1000\n",
            "44/44 [==============================] - 0s 466us/step - loss: 0.0510 - acc: 1.0000 - val_loss: 0.1259 - val_acc: 1.0000\n",
            "Epoch 242/1000\n",
            "44/44 [==============================] - 0s 460us/step - loss: 0.0506 - acc: 1.0000 - val_loss: 0.1252 - val_acc: 1.0000\n",
            "Epoch 243/1000\n",
            "44/44 [==============================] - 0s 475us/step - loss: 0.0501 - acc: 1.0000 - val_loss: 0.1239 - val_acc: 1.0000\n",
            "Epoch 244/1000\n",
            "44/44 [==============================] - 0s 425us/step - loss: 0.0498 - acc: 1.0000 - val_loss: 0.1247 - val_acc: 1.0000\n",
            "Epoch 245/1000\n",
            "44/44 [==============================] - 0s 479us/step - loss: 0.0493 - acc: 1.0000 - val_loss: 0.1228 - val_acc: 1.0000\n",
            "Epoch 246/1000\n",
            "44/44 [==============================] - 0s 491us/step - loss: 0.0489 - acc: 1.0000 - val_loss: 0.1226 - val_acc: 1.0000\n",
            "Epoch 247/1000\n",
            "44/44 [==============================] - 0s 495us/step - loss: 0.0486 - acc: 1.0000 - val_loss: 0.1250 - val_acc: 1.0000\n",
            "Epoch 248/1000\n",
            "44/44 [==============================] - 0s 546us/step - loss: 0.0481 - acc: 1.0000 - val_loss: 0.1227 - val_acc: 1.0000\n",
            "Epoch 249/1000\n",
            "44/44 [==============================] - 0s 444us/step - loss: 0.0478 - acc: 1.0000 - val_loss: 0.1204 - val_acc: 1.0000\n",
            "Epoch 250/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0473 - acc: 1.0000 - val_loss: 0.1192 - val_acc: 1.0000\n",
            "Epoch 251/1000\n",
            "44/44 [==============================] - 0s 452us/step - loss: 0.0469 - acc: 1.0000 - val_loss: 0.1184 - val_acc: 1.0000\n",
            "Epoch 252/1000\n",
            "44/44 [==============================] - 0s 425us/step - loss: 0.0466 - acc: 1.0000 - val_loss: 0.1197 - val_acc: 1.0000\n",
            "Epoch 253/1000\n",
            "44/44 [==============================] - 0s 488us/step - loss: 0.0462 - acc: 1.0000 - val_loss: 0.1169 - val_acc: 1.0000\n",
            "Epoch 254/1000\n",
            "44/44 [==============================] - 0s 426us/step - loss: 0.0459 - acc: 1.0000 - val_loss: 0.1148 - val_acc: 1.0000\n",
            "Epoch 255/1000\n",
            "44/44 [==============================] - 0s 472us/step - loss: 0.0454 - acc: 1.0000 - val_loss: 0.1150 - val_acc: 1.0000\n",
            "Epoch 256/1000\n",
            "44/44 [==============================] - 0s 621us/step - loss: 0.0451 - acc: 1.0000 - val_loss: 0.1164 - val_acc: 1.0000\n",
            "Epoch 257/1000\n",
            "44/44 [==============================] - 0s 483us/step - loss: 0.0447 - acc: 1.0000 - val_loss: 0.1145 - val_acc: 1.0000\n",
            "Epoch 258/1000\n",
            "44/44 [==============================] - 0s 507us/step - loss: 0.0444 - acc: 1.0000 - val_loss: 0.1128 - val_acc: 1.0000\n",
            "Epoch 259/1000\n",
            "44/44 [==============================] - 0s 467us/step - loss: 0.0440 - acc: 1.0000 - val_loss: 0.1141 - val_acc: 1.0000\n",
            "Epoch 260/1000\n",
            "44/44 [==============================] - 0s 455us/step - loss: 0.0436 - acc: 1.0000 - val_loss: 0.1132 - val_acc: 1.0000\n",
            "Epoch 261/1000\n",
            "44/44 [==============================] - 0s 493us/step - loss: 0.0433 - acc: 1.0000 - val_loss: 0.1117 - val_acc: 1.0000\n",
            "Epoch 262/1000\n",
            "44/44 [==============================] - 0s 501us/step - loss: 0.0429 - acc: 1.0000 - val_loss: 0.1100 - val_acc: 1.0000\n",
            "Epoch 263/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.0426 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 1.0000\n",
            "Epoch 264/1000\n",
            "44/44 [==============================] - 0s 484us/step - loss: 0.0423 - acc: 1.0000 - val_loss: 0.1101 - val_acc: 1.0000\n",
            "Epoch 265/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.0420 - acc: 1.0000 - val_loss: 0.1095 - val_acc: 1.0000\n",
            "Epoch 266/1000\n",
            "44/44 [==============================] - 0s 471us/step - loss: 0.0417 - acc: 1.0000 - val_loss: 0.1076 - val_acc: 1.0000\n",
            "Epoch 267/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0415 - acc: 1.0000 - val_loss: 0.1043 - val_acc: 1.0000\n",
            "Epoch 268/1000\n",
            "44/44 [==============================] - 0s 516us/step - loss: 0.0410 - acc: 1.0000 - val_loss: 0.1036 - val_acc: 1.0000\n",
            "Epoch 269/1000\n",
            "44/44 [==============================] - 0s 563us/step - loss: 0.0407 - acc: 1.0000 - val_loss: 0.1032 - val_acc: 1.0000\n",
            "Epoch 270/1000\n",
            "44/44 [==============================] - 0s 470us/step - loss: 0.0404 - acc: 1.0000 - val_loss: 0.1031 - val_acc: 1.0000\n",
            "Epoch 271/1000\n",
            "44/44 [==============================] - 0s 467us/step - loss: 0.0401 - acc: 1.0000 - val_loss: 0.1035 - val_acc: 1.0000\n",
            "Epoch 272/1000\n",
            "44/44 [==============================] - 0s 509us/step - loss: 0.0398 - acc: 1.0000 - val_loss: 0.1031 - val_acc: 1.0000\n",
            "Epoch 273/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.0395 - acc: 1.0000 - val_loss: 0.1016 - val_acc: 1.0000\n",
            "Epoch 274/1000\n",
            "44/44 [==============================] - 0s 481us/step - loss: 0.0392 - acc: 1.0000 - val_loss: 0.1010 - val_acc: 1.0000\n",
            "Epoch 275/1000\n",
            "44/44 [==============================] - 0s 542us/step - loss: 0.0389 - acc: 1.0000 - val_loss: 0.1008 - val_acc: 1.0000\n",
            "Epoch 276/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.0386 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 1.0000\n",
            "Epoch 277/1000\n",
            "44/44 [==============================] - 0s 480us/step - loss: 0.0383 - acc: 1.0000 - val_loss: 0.0994 - val_acc: 1.0000\n",
            "Epoch 278/1000\n",
            "44/44 [==============================] - 0s 542us/step - loss: 0.0381 - acc: 1.0000 - val_loss: 0.1000 - val_acc: 1.0000\n",
            "Epoch 279/1000\n",
            "44/44 [==============================] - 0s 482us/step - loss: 0.0378 - acc: 1.0000 - val_loss: 0.0985 - val_acc: 1.0000\n",
            "Epoch 280/1000\n",
            "44/44 [==============================] - 0s 442us/step - loss: 0.0375 - acc: 1.0000 - val_loss: 0.0985 - val_acc: 1.0000\n",
            "Epoch 281/1000\n",
            "44/44 [==============================] - 0s 475us/step - loss: 0.0372 - acc: 1.0000 - val_loss: 0.0983 - val_acc: 1.0000\n",
            "Epoch 282/1000\n",
            "44/44 [==============================] - 0s 458us/step - loss: 0.0369 - acc: 1.0000 - val_loss: 0.0976 - val_acc: 1.0000\n",
            "Epoch 283/1000\n",
            "44/44 [==============================] - 0s 486us/step - loss: 0.0367 - acc: 1.0000 - val_loss: 0.0955 - val_acc: 1.0000\n",
            "Epoch 284/1000\n",
            "44/44 [==============================] - 0s 478us/step - loss: 0.0364 - acc: 1.0000 - val_loss: 0.0956 - val_acc: 1.0000\n",
            "Epoch 285/1000\n",
            "44/44 [==============================] - 0s 470us/step - loss: 0.0361 - acc: 1.0000 - val_loss: 0.0955 - val_acc: 1.0000\n",
            "Epoch 286/1000\n",
            "44/44 [==============================] - 0s 539us/step - loss: 0.0359 - acc: 1.0000 - val_loss: 0.0948 - val_acc: 1.0000\n",
            "Epoch 287/1000\n",
            "44/44 [==============================] - 0s 437us/step - loss: 0.0356 - acc: 1.0000 - val_loss: 0.0933 - val_acc: 1.0000\n",
            "Epoch 288/1000\n",
            "44/44 [==============================] - 0s 543us/step - loss: 0.0353 - acc: 1.0000 - val_loss: 0.0931 - val_acc: 1.0000\n",
            "Epoch 289/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0352 - acc: 1.0000 - val_loss: 0.0907 - val_acc: 1.0000\n",
            "Epoch 290/1000\n",
            "44/44 [==============================] - 0s 517us/step - loss: 0.0348 - acc: 1.0000 - val_loss: 0.0905 - val_acc: 1.0000\n",
            "Epoch 291/1000\n",
            "44/44 [==============================] - 0s 453us/step - loss: 0.0346 - acc: 1.0000 - val_loss: 0.0913 - val_acc: 1.0000\n",
            "Epoch 292/1000\n",
            "44/44 [==============================] - 0s 525us/step - loss: 0.0343 - acc: 1.0000 - val_loss: 0.0929 - val_acc: 1.0000\n",
            "Epoch 293/1000\n",
            "44/44 [==============================] - 0s 491us/step - loss: 0.0341 - acc: 1.0000 - val_loss: 0.0938 - val_acc: 1.0000\n",
            "Epoch 294/1000\n",
            "44/44 [==============================] - 0s 509us/step - loss: 0.0339 - acc: 1.0000 - val_loss: 0.0940 - val_acc: 1.0000\n",
            "Epoch 295/1000\n",
            "44/44 [==============================] - 0s 506us/step - loss: 0.0336 - acc: 1.0000 - val_loss: 0.0918 - val_acc: 1.0000\n",
            "Epoch 296/1000\n",
            "44/44 [==============================] - 0s 738us/step - loss: 0.0334 - acc: 1.0000 - val_loss: 0.0905 - val_acc: 1.0000\n",
            "Epoch 297/1000\n",
            "44/44 [==============================] - 0s 497us/step - loss: 0.0331 - acc: 1.0000 - val_loss: 0.0889 - val_acc: 1.0000\n",
            "Epoch 298/1000\n",
            "44/44 [==============================] - 0s 549us/step - loss: 0.0329 - acc: 1.0000 - val_loss: 0.0889 - val_acc: 1.0000\n",
            "Epoch 299/1000\n",
            "44/44 [==============================] - 0s 539us/step - loss: 0.0327 - acc: 1.0000 - val_loss: 0.0887 - val_acc: 1.0000\n",
            "Epoch 300/1000\n",
            "44/44 [==============================] - 0s 492us/step - loss: 0.0324 - acc: 1.0000 - val_loss: 0.0876 - val_acc: 1.0000\n",
            "Epoch 301/1000\n",
            "44/44 [==============================] - 0s 467us/step - loss: 0.0322 - acc: 1.0000 - val_loss: 0.0861 - val_acc: 1.0000\n",
            "Epoch 302/1000\n",
            "44/44 [==============================] - 0s 513us/step - loss: 0.0320 - acc: 1.0000 - val_loss: 0.0846 - val_acc: 1.0000\n",
            "Epoch 303/1000\n",
            "44/44 [==============================] - 0s 482us/step - loss: 0.0318 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 1.0000\n",
            "Epoch 304/1000\n",
            "44/44 [==============================] - 0s 520us/step - loss: 0.0316 - acc: 1.0000 - val_loss: 0.0823 - val_acc: 1.0000\n",
            "Epoch 305/1000\n",
            "44/44 [==============================] - 0s 416us/step - loss: 0.0314 - acc: 1.0000 - val_loss: 0.0828 - val_acc: 1.0000\n",
            "Epoch 306/1000\n",
            "44/44 [==============================] - 0s 428us/step - loss: 0.0311 - acc: 1.0000 - val_loss: 0.0828 - val_acc: 1.0000\n",
            "Epoch 307/1000\n",
            "44/44 [==============================] - 0s 499us/step - loss: 0.0309 - acc: 1.0000 - val_loss: 0.0837 - val_acc: 1.0000\n",
            "Epoch 308/1000\n",
            "44/44 [==============================] - 0s 479us/step - loss: 0.0307 - acc: 1.0000 - val_loss: 0.0831 - val_acc: 1.0000\n",
            "Epoch 309/1000\n",
            "44/44 [==============================] - 0s 499us/step - loss: 0.0305 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 1.0000\n",
            "Epoch 310/1000\n",
            "44/44 [==============================] - 0s 471us/step - loss: 0.0303 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 1.0000\n",
            "Epoch 311/1000\n",
            "44/44 [==============================] - 0s 558us/step - loss: 0.0301 - acc: 1.0000 - val_loss: 0.0840 - val_acc: 1.0000\n",
            "Epoch 312/1000\n",
            "44/44 [==============================] - 0s 415us/step - loss: 0.0299 - acc: 1.0000 - val_loss: 0.0844 - val_acc: 1.0000\n",
            "Epoch 313/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0297 - acc: 1.0000 - val_loss: 0.0828 - val_acc: 1.0000\n",
            "Epoch 314/1000\n",
            "44/44 [==============================] - 0s 544us/step - loss: 0.0295 - acc: 1.0000 - val_loss: 0.0812 - val_acc: 1.0000\n",
            "Epoch 315/1000\n",
            "44/44 [==============================] - 0s 433us/step - loss: 0.0293 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 1.0000\n",
            "Epoch 316/1000\n",
            "44/44 [==============================] - 0s 409us/step - loss: 0.0291 - acc: 1.0000 - val_loss: 0.0799 - val_acc: 1.0000\n",
            "Epoch 317/1000\n",
            "44/44 [==============================] - 0s 474us/step - loss: 0.0289 - acc: 1.0000 - val_loss: 0.0791 - val_acc: 1.0000\n",
            "Epoch 318/1000\n",
            "44/44 [==============================] - 0s 540us/step - loss: 0.0287 - acc: 1.0000 - val_loss: 0.0780 - val_acc: 1.0000\n",
            "Epoch 319/1000\n",
            "44/44 [==============================] - 0s 666us/step - loss: 0.0285 - acc: 1.0000 - val_loss: 0.0772 - val_acc: 1.0000\n",
            "Epoch 320/1000\n",
            "44/44 [==============================] - 0s 571us/step - loss: 0.0284 - acc: 1.0000 - val_loss: 0.0757 - val_acc: 1.0000\n",
            "Epoch 321/1000\n",
            "44/44 [==============================] - 0s 519us/step - loss: 0.0281 - acc: 1.0000 - val_loss: 0.0761 - val_acc: 1.0000\n",
            "Epoch 322/1000\n",
            "44/44 [==============================] - 0s 442us/step - loss: 0.0279 - acc: 1.0000 - val_loss: 0.0764 - val_acc: 1.0000\n",
            "Epoch 323/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0277 - acc: 1.0000 - val_loss: 0.0761 - val_acc: 1.0000\n",
            "Epoch 324/1000\n",
            "44/44 [==============================] - 0s 452us/step - loss: 0.0276 - acc: 1.0000 - val_loss: 0.0764 - val_acc: 1.0000\n",
            "Epoch 325/1000\n",
            "44/44 [==============================] - 0s 505us/step - loss: 0.0274 - acc: 1.0000 - val_loss: 0.0758 - val_acc: 1.0000\n",
            "Epoch 326/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.0272 - acc: 1.0000 - val_loss: 0.0761 - val_acc: 1.0000\n",
            "Epoch 327/1000\n",
            "44/44 [==============================] - 0s 499us/step - loss: 0.0270 - acc: 1.0000 - val_loss: 0.0748 - val_acc: 1.0000\n",
            "Epoch 328/1000\n",
            "44/44 [==============================] - 0s 381us/step - loss: 0.0269 - acc: 1.0000 - val_loss: 0.0751 - val_acc: 1.0000\n",
            "Epoch 329/1000\n",
            "44/44 [==============================] - 0s 559us/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.0735 - val_acc: 1.0000\n",
            "Epoch 330/1000\n",
            "44/44 [==============================] - 0s 487us/step - loss: 0.0265 - acc: 1.0000 - val_loss: 0.0736 - val_acc: 1.0000\n",
            "Epoch 331/1000\n",
            "44/44 [==============================] - 0s 458us/step - loss: 0.0263 - acc: 1.0000 - val_loss: 0.0734 - val_acc: 1.0000\n",
            "Epoch 332/1000\n",
            "44/44 [==============================] - 0s 499us/step - loss: 0.0262 - acc: 1.0000 - val_loss: 0.0724 - val_acc: 1.0000\n",
            "Epoch 333/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0260 - acc: 1.0000 - val_loss: 0.0726 - val_acc: 1.0000\n",
            "Epoch 334/1000\n",
            "44/44 [==============================] - 0s 489us/step - loss: 0.0258 - acc: 1.0000 - val_loss: 0.0727 - val_acc: 1.0000\n",
            "Epoch 335/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.0730 - val_acc: 1.0000\n",
            "Epoch 336/1000\n",
            "44/44 [==============================] - 0s 531us/step - loss: 0.0255 - acc: 1.0000 - val_loss: 0.0721 - val_acc: 1.0000\n",
            "Epoch 337/1000\n",
            "44/44 [==============================] - 0s 482us/step - loss: 0.0254 - acc: 1.0000 - val_loss: 0.0721 - val_acc: 1.0000\n",
            "Epoch 338/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.0252 - acc: 1.0000 - val_loss: 0.0716 - val_acc: 1.0000\n",
            "Epoch 339/1000\n",
            "44/44 [==============================] - 0s 496us/step - loss: 0.0251 - acc: 1.0000 - val_loss: 0.0705 - val_acc: 1.0000\n",
            "Epoch 340/1000\n",
            "44/44 [==============================] - 0s 568us/step - loss: 0.0249 - acc: 1.0000 - val_loss: 0.0710 - val_acc: 1.0000\n",
            "Epoch 341/1000\n",
            "44/44 [==============================] - 0s 440us/step - loss: 0.0248 - acc: 1.0000 - val_loss: 0.0713 - val_acc: 1.0000\n",
            "Epoch 342/1000\n",
            "44/44 [==============================] - 0s 416us/step - loss: 0.0246 - acc: 1.0000 - val_loss: 0.0715 - val_acc: 1.0000\n",
            "Epoch 343/1000\n",
            "44/44 [==============================] - 0s 422us/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.0703 - val_acc: 1.0000\n",
            "Epoch 344/1000\n",
            "44/44 [==============================] - 0s 471us/step - loss: 0.0243 - acc: 1.0000 - val_loss: 0.0702 - val_acc: 1.0000\n",
            "Epoch 345/1000\n",
            "44/44 [==============================] - 0s 520us/step - loss: 0.0241 - acc: 1.0000 - val_loss: 0.0699 - val_acc: 1.0000\n",
            "Epoch 346/1000\n",
            "44/44 [==============================] - 0s 560us/step - loss: 0.0240 - acc: 1.0000 - val_loss: 0.0684 - val_acc: 1.0000\n",
            "Epoch 347/1000\n",
            "44/44 [==============================] - 0s 475us/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.0686 - val_acc: 1.0000\n",
            "Epoch 348/1000\n",
            "44/44 [==============================] - 0s 426us/step - loss: 0.0237 - acc: 1.0000 - val_loss: 0.0681 - val_acc: 1.0000\n",
            "Epoch 349/1000\n",
            "44/44 [==============================] - 0s 525us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.0677 - val_acc: 1.0000\n",
            "Epoch 350/1000\n",
            "44/44 [==============================] - 0s 543us/step - loss: 0.0234 - acc: 1.0000 - val_loss: 0.0666 - val_acc: 1.0000\n",
            "Epoch 351/1000\n",
            "44/44 [==============================] - 0s 443us/step - loss: 0.0232 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 1.0000\n",
            "Epoch 352/1000\n",
            "44/44 [==============================] - 0s 540us/step - loss: 0.0231 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 1.0000\n",
            "Epoch 353/1000\n",
            "44/44 [==============================] - 0s 503us/step - loss: 0.0229 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 1.0000\n",
            "Epoch 354/1000\n",
            "44/44 [==============================] - 0s 505us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 0.0638 - val_acc: 1.0000\n",
            "Epoch 355/1000\n",
            "44/44 [==============================] - 0s 526us/step - loss: 0.0227 - acc: 1.0000 - val_loss: 0.0634 - val_acc: 1.0000\n",
            "Epoch 356/1000\n",
            "44/44 [==============================] - 0s 563us/step - loss: 0.0225 - acc: 1.0000 - val_loss: 0.0622 - val_acc: 1.0000\n",
            "Epoch 357/1000\n",
            "44/44 [==============================] - 0s 557us/step - loss: 0.0224 - acc: 1.0000 - val_loss: 0.0616 - val_acc: 1.0000\n",
            "Epoch 358/1000\n",
            "44/44 [==============================] - 0s 464us/step - loss: 0.0223 - acc: 1.0000 - val_loss: 0.0622 - val_acc: 1.0000\n",
            "Epoch 359/1000\n",
            "44/44 [==============================] - 0s 428us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 0.0619 - val_acc: 1.0000\n",
            "Epoch 360/1000\n",
            "44/44 [==============================] - 0s 414us/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.0634 - val_acc: 1.0000\n",
            "Epoch 361/1000\n",
            "44/44 [==============================] - 0s 388us/step - loss: 0.0218 - acc: 1.0000 - val_loss: 0.0639 - val_acc: 1.0000\n",
            "Epoch 362/1000\n",
            "44/44 [==============================] - 0s 413us/step - loss: 0.0217 - acc: 1.0000 - val_loss: 0.0635 - val_acc: 1.0000\n",
            "Epoch 363/1000\n",
            "44/44 [==============================] - 0s 434us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 0.0628 - val_acc: 1.0000\n",
            "Epoch 364/1000\n",
            "44/44 [==============================] - 0s 465us/step - loss: 0.0215 - acc: 1.0000 - val_loss: 0.0622 - val_acc: 1.0000\n",
            "Epoch 365/1000\n",
            "44/44 [==============================] - 0s 510us/step - loss: 0.0213 - acc: 1.0000 - val_loss: 0.0619 - val_acc: 1.0000\n",
            "Epoch 366/1000\n",
            "44/44 [==============================] - 0s 479us/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.0613 - val_acc: 1.0000\n",
            "Epoch 367/1000\n",
            "44/44 [==============================] - 0s 511us/step - loss: 0.0211 - acc: 1.0000 - val_loss: 0.0609 - val_acc: 1.0000\n",
            "Epoch 368/1000\n",
            "44/44 [==============================] - 0s 430us/step - loss: 0.0209 - acc: 1.0000 - val_loss: 0.0605 - val_acc: 1.0000\n",
            "Epoch 369/1000\n",
            "44/44 [==============================] - 0s 422us/step - loss: 0.0208 - acc: 1.0000 - val_loss: 0.0605 - val_acc: 1.0000\n",
            "Epoch 370/1000\n",
            "44/44 [==============================] - 0s 410us/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.0599 - val_acc: 1.0000\n",
            "Epoch 371/1000\n",
            "44/44 [==============================] - 0s 432us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.0592 - val_acc: 1.0000\n",
            "Epoch 372/1000\n",
            "44/44 [==============================] - 0s 506us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.0588 - val_acc: 1.0000\n",
            "Epoch 373/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.0570 - val_acc: 1.0000\n",
            "Epoch 374/1000\n",
            "44/44 [==============================] - 0s 430us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.0550 - val_acc: 1.0000\n",
            "Epoch 375/1000\n",
            "44/44 [==============================] - 0s 449us/step - loss: 0.0202 - acc: 1.0000 - val_loss: 0.0541 - val_acc: 1.0000\n",
            "Epoch 376/1000\n",
            "44/44 [==============================] - 0s 442us/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.0542 - val_acc: 1.0000\n",
            "Epoch 377/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.0547 - val_acc: 1.0000\n",
            "Epoch 378/1000\n",
            "44/44 [==============================] - 0s 427us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 0.0559 - val_acc: 1.0000\n",
            "Epoch 379/1000\n",
            "44/44 [==============================] - 0s 393us/step - loss: 0.0196 - acc: 1.0000 - val_loss: 0.0561 - val_acc: 1.0000\n",
            "Epoch 380/1000\n",
            "44/44 [==============================] - 0s 472us/step - loss: 0.0195 - acc: 1.0000 - val_loss: 0.0561 - val_acc: 1.0000\n",
            "Epoch 381/1000\n",
            "44/44 [==============================] - 0s 455us/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.0560 - val_acc: 1.0000\n",
            "Epoch 382/1000\n",
            "44/44 [==============================] - 0s 476us/step - loss: 0.0193 - acc: 1.0000 - val_loss: 0.0567 - val_acc: 1.0000\n",
            "Epoch 383/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.0192 - acc: 1.0000 - val_loss: 0.0564 - val_acc: 1.0000\n",
            "Epoch 384/1000\n",
            "44/44 [==============================] - 0s 452us/step - loss: 0.0191 - acc: 1.0000 - val_loss: 0.0555 - val_acc: 1.0000\n",
            "Epoch 385/1000\n",
            "44/44 [==============================] - 0s 465us/step - loss: 0.0189 - acc: 1.0000 - val_loss: 0.0547 - val_acc: 1.0000\n",
            "Epoch 386/1000\n",
            "44/44 [==============================] - 0s 479us/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.0544 - val_acc: 1.0000\n",
            "Epoch 387/1000\n",
            "44/44 [==============================] - 0s 618us/step - loss: 0.0187 - acc: 1.0000 - val_loss: 0.0540 - val_acc: 1.0000\n",
            "Epoch 388/1000\n",
            "44/44 [==============================] - 0s 506us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.0538 - val_acc: 1.0000\n",
            "Epoch 389/1000\n",
            "44/44 [==============================] - 0s 447us/step - loss: 0.0185 - acc: 1.0000 - val_loss: 0.0532 - val_acc: 1.0000\n",
            "Epoch 390/1000\n",
            "44/44 [==============================] - 0s 512us/step - loss: 0.0184 - acc: 1.0000 - val_loss: 0.0531 - val_acc: 1.0000\n",
            "Epoch 391/1000\n",
            "44/44 [==============================] - 0s 464us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 1.0000\n",
            "Epoch 392/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 0.0532 - val_acc: 1.0000\n",
            "Epoch 393/1000\n",
            "44/44 [==============================] - 0s 492us/step - loss: 0.0181 - acc: 1.0000 - val_loss: 0.0530 - val_acc: 1.0000\n",
            "Epoch 394/1000\n",
            "44/44 [==============================] - 0s 463us/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.0526 - val_acc: 1.0000\n",
            "Epoch 395/1000\n",
            "44/44 [==============================] - 0s 499us/step - loss: 0.0179 - acc: 1.0000 - val_loss: 0.0524 - val_acc: 1.0000\n",
            "Epoch 396/1000\n",
            "44/44 [==============================] - 0s 496us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 0.0518 - val_acc: 1.0000\n",
            "Epoch 397/1000\n",
            "44/44 [==============================] - 0s 474us/step - loss: 0.0177 - acc: 1.0000 - val_loss: 0.0514 - val_acc: 1.0000\n",
            "Epoch 398/1000\n",
            "44/44 [==============================] - 0s 492us/step - loss: 0.0176 - acc: 1.0000 - val_loss: 0.0512 - val_acc: 1.0000\n",
            "Epoch 399/1000\n",
            "44/44 [==============================] - 0s 417us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.0511 - val_acc: 1.0000\n",
            "Epoch 400/1000\n",
            "44/44 [==============================] - 0s 464us/step - loss: 0.0174 - acc: 1.0000 - val_loss: 0.0506 - val_acc: 1.0000\n",
            "Epoch 401/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.0506 - val_acc: 1.0000\n",
            "Epoch 402/1000\n",
            "44/44 [==============================] - 0s 480us/step - loss: 0.0172 - acc: 1.0000 - val_loss: 0.0506 - val_acc: 1.0000\n",
            "Epoch 403/1000\n",
            "44/44 [==============================] - 0s 498us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.0499 - val_acc: 1.0000\n",
            "Epoch 404/1000\n",
            "44/44 [==============================] - 0s 423us/step - loss: 0.0171 - acc: 1.0000 - val_loss: 0.0500 - val_acc: 1.0000\n",
            "Epoch 405/1000\n",
            "44/44 [==============================] - 0s 512us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 0.0493 - val_acc: 1.0000\n",
            "Epoch 406/1000\n",
            "44/44 [==============================] - 0s 501us/step - loss: 0.0168 - acc: 1.0000 - val_loss: 0.0492 - val_acc: 1.0000\n",
            "Epoch 407/1000\n",
            "44/44 [==============================] - 0s 425us/step - loss: 0.0167 - acc: 1.0000 - val_loss: 0.0490 - val_acc: 1.0000\n",
            "Epoch 408/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.0482 - val_acc: 1.0000\n",
            "Epoch 409/1000\n",
            "44/44 [==============================] - 0s 514us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.0479 - val_acc: 1.0000\n",
            "Epoch 410/1000\n",
            "44/44 [==============================] - 0s 522us/step - loss: 0.0165 - acc: 1.0000 - val_loss: 0.0475 - val_acc: 1.0000\n",
            "Epoch 411/1000\n",
            "44/44 [==============================] - 0s 394us/step - loss: 0.0164 - acc: 1.0000 - val_loss: 0.0474 - val_acc: 1.0000\n",
            "Epoch 412/1000\n",
            "44/44 [==============================] - 0s 513us/step - loss: 0.0163 - acc: 1.0000 - val_loss: 0.0470 - val_acc: 1.0000\n",
            "Epoch 413/1000\n",
            "44/44 [==============================] - 0s 540us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.0470 - val_acc: 1.0000\n",
            "Epoch 414/1000\n",
            "44/44 [==============================] - 0s 633us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.0457 - val_acc: 1.0000\n",
            "Epoch 415/1000\n",
            "44/44 [==============================] - 0s 587us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.0446 - val_acc: 1.0000\n",
            "Epoch 416/1000\n",
            "44/44 [==============================] - 0s 594us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 1.0000\n",
            "Epoch 417/1000\n",
            "44/44 [==============================] - 0s 599us/step - loss: 0.0159 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 1.0000\n",
            "Epoch 418/1000\n",
            "44/44 [==============================] - 0s 431us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 0.0443 - val_acc: 1.0000\n",
            "Epoch 419/1000\n",
            "44/44 [==============================] - 0s 549us/step - loss: 0.0157 - acc: 1.0000 - val_loss: 0.0446 - val_acc: 1.0000\n",
            "Epoch 420/1000\n",
            "44/44 [==============================] - 0s 619us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.0452 - val_acc: 1.0000\n",
            "Epoch 421/1000\n",
            "44/44 [==============================] - 0s 483us/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.0455 - val_acc: 1.0000\n",
            "Epoch 422/1000\n",
            "44/44 [==============================] - 0s 486us/step - loss: 0.0154 - acc: 1.0000 - val_loss: 0.0451 - val_acc: 1.0000\n",
            "Epoch 423/1000\n",
            "44/44 [==============================] - 0s 549us/step - loss: 0.0153 - acc: 1.0000 - val_loss: 0.0453 - val_acc: 1.0000\n",
            "Epoch 424/1000\n",
            "44/44 [==============================] - 0s 486us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0452 - val_acc: 1.0000\n",
            "Epoch 425/1000\n",
            "44/44 [==============================] - 0s 565us/step - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0445 - val_acc: 1.0000\n",
            "Epoch 426/1000\n",
            "44/44 [==============================] - 0s 512us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.0446 - val_acc: 1.0000\n",
            "Epoch 427/1000\n",
            "44/44 [==============================] - 0s 592us/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.0439 - val_acc: 1.0000\n",
            "Epoch 428/1000\n",
            "44/44 [==============================] - 0s 443us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0436 - val_acc: 1.0000\n",
            "Epoch 429/1000\n",
            "44/44 [==============================] - 0s 510us/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.0429 - val_acc: 1.0000\n",
            "Epoch 430/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.0433 - val_acc: 1.0000\n",
            "Epoch 431/1000\n",
            "44/44 [==============================] - 0s 502us/step - loss: 0.0147 - acc: 1.0000 - val_loss: 0.0433 - val_acc: 1.0000\n",
            "Epoch 432/1000\n",
            "44/44 [==============================] - 0s 458us/step - loss: 0.0146 - acc: 1.0000 - val_loss: 0.0431 - val_acc: 1.0000\n",
            "Epoch 433/1000\n",
            "44/44 [==============================] - 0s 444us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.0424 - val_acc: 1.0000\n",
            "Epoch 434/1000\n",
            "44/44 [==============================] - 0s 500us/step - loss: 0.0145 - acc: 1.0000 - val_loss: 0.0416 - val_acc: 1.0000\n",
            "Epoch 435/1000\n",
            "44/44 [==============================] - 0s 504us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0412 - val_acc: 1.0000\n",
            "Epoch 436/1000\n",
            "44/44 [==============================] - 0s 468us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 0.0410 - val_acc: 1.0000\n",
            "Epoch 437/1000\n",
            "44/44 [==============================] - 0s 472us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0410 - val_acc: 1.0000\n",
            "Epoch 438/1000\n",
            "44/44 [==============================] - 0s 511us/step - loss: 0.0142 - acc: 1.0000 - val_loss: 0.0414 - val_acc: 1.0000\n",
            "Epoch 439/1000\n",
            "44/44 [==============================] - 0s 598us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.0413 - val_acc: 1.0000\n",
            "Epoch 440/1000\n",
            "44/44 [==============================] - 0s 440us/step - loss: 0.0140 - acc: 1.0000 - val_loss: 0.0410 - val_acc: 1.0000\n",
            "Epoch 441/1000\n",
            "44/44 [==============================] - 0s 444us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0408 - val_acc: 1.0000\n",
            "Epoch 442/1000\n",
            "44/44 [==============================] - 0s 492us/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0411 - val_acc: 1.0000\n",
            "Epoch 443/1000\n",
            "44/44 [==============================] - 0s 478us/step - loss: 0.0138 - acc: 1.0000 - val_loss: 0.0417 - val_acc: 1.0000\n",
            "Epoch 444/1000\n",
            "44/44 [==============================] - 0s 506us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.0418 - val_acc: 1.0000\n",
            "Epoch 445/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0137 - acc: 1.0000 - val_loss: 0.0416 - val_acc: 1.0000\n",
            "Epoch 446/1000\n",
            "44/44 [==============================] - 0s 515us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 0.0417 - val_acc: 1.0000\n",
            "Epoch 447/1000\n",
            "44/44 [==============================] - 0s 449us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.0410 - val_acc: 1.0000\n",
            "Epoch 448/1000\n",
            "44/44 [==============================] - 0s 469us/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 1.0000\n",
            "Epoch 449/1000\n",
            "44/44 [==============================] - 0s 510us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 0.0400 - val_acc: 1.0000\n",
            "Epoch 450/1000\n",
            "44/44 [==============================] - 0s 485us/step - loss: 0.0133 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 1.0000\n",
            "Epoch 451/1000\n",
            "44/44 [==============================] - 0s 436us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0403 - val_acc: 1.0000\n",
            "Epoch 452/1000\n",
            "44/44 [==============================] - 0s 464us/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0400 - val_acc: 1.0000\n",
            "Epoch 453/1000\n",
            "44/44 [==============================] - 0s 476us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.0397 - val_acc: 1.0000\n",
            "Epoch 454/1000\n",
            "44/44 [==============================] - 0s 486us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.0394 - val_acc: 1.0000\n",
            "Epoch 455/1000\n",
            "44/44 [==============================] - 0s 391us/step - loss: 0.0130 - acc: 1.0000 - val_loss: 0.0383 - val_acc: 1.0000\n",
            "Epoch 456/1000\n",
            "44/44 [==============================] - 0s 467us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 0.0379 - val_acc: 1.0000\n",
            "Epoch 457/1000\n",
            "44/44 [==============================] - 0s 519us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.0379 - val_acc: 1.0000\n",
            "Epoch 458/1000\n",
            "44/44 [==============================] - 0s 566us/step - loss: 0.0128 - acc: 1.0000 - val_loss: 0.0376 - val_acc: 1.0000\n",
            "Epoch 459/1000\n",
            "44/44 [==============================] - 0s 484us/step - loss: 0.0127 - acc: 1.0000 - val_loss: 0.0376 - val_acc: 1.0000\n",
            "Epoch 460/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 1.0000\n",
            "Epoch 461/1000\n",
            "44/44 [==============================] - 0s 474us/step - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0373 - val_acc: 1.0000\n",
            "Epoch 462/1000\n",
            "44/44 [==============================] - 0s 463us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 0.0372 - val_acc: 1.0000\n",
            "Epoch 463/1000\n",
            "44/44 [==============================] - 0s 470us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0370 - val_acc: 1.0000\n",
            "Epoch 464/1000\n",
            "44/44 [==============================] - 0s 530us/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.0366 - val_acc: 1.0000\n",
            "Epoch 465/1000\n",
            "44/44 [==============================] - 0s 533us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0365 - val_acc: 1.0000\n",
            "Epoch 466/1000\n",
            "44/44 [==============================] - 0s 535us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0366 - val_acc: 1.0000\n",
            "Epoch 467/1000\n",
            "44/44 [==============================] - 0s 489us/step - loss: 0.0122 - acc: 1.0000 - val_loss: 0.0365 - val_acc: 1.0000\n",
            "Epoch 468/1000\n",
            "44/44 [==============================] - 0s 478us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0364 - val_acc: 1.0000\n",
            "Epoch 469/1000\n",
            "44/44 [==============================] - 0s 472us/step - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0362 - val_acc: 1.0000\n",
            "Epoch 470/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0358 - val_acc: 1.0000\n",
            "Epoch 471/1000\n",
            "44/44 [==============================] - 0s 471us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 0.0353 - val_acc: 1.0000\n",
            "Epoch 472/1000\n",
            "44/44 [==============================] - 0s 458us/step - loss: 0.0119 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 1.0000\n",
            "Epoch 473/1000\n",
            "44/44 [==============================] - 0s 583us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 1.0000\n",
            "Epoch 474/1000\n",
            "44/44 [==============================] - 0s 451us/step - loss: 0.0118 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 1.0000\n",
            "Epoch 475/1000\n",
            "44/44 [==============================] - 0s 417us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0344 - val_acc: 1.0000\n",
            "Epoch 476/1000\n",
            "44/44 [==============================] - 0s 603us/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0346 - val_acc: 1.0000\n",
            "Epoch 477/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0343 - val_acc: 1.0000\n",
            "Epoch 478/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0342 - val_acc: 1.0000\n",
            "Epoch 479/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.0339 - val_acc: 1.0000\n",
            "Epoch 480/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0338 - val_acc: 1.0000\n",
            "Epoch 481/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0340 - val_acc: 1.0000\n",
            "Epoch 482/1000\n",
            "44/44 [==============================] - 0s 463us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0336 - val_acc: 1.0000\n",
            "Epoch 483/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0334 - val_acc: 1.0000\n",
            "Epoch 484/1000\n",
            "44/44 [==============================] - 0s 498us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0335 - val_acc: 1.0000\n",
            "Epoch 485/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.0112 - acc: 1.0000 - val_loss: 0.0336 - val_acc: 1.0000\n",
            "Epoch 486/1000\n",
            "44/44 [==============================] - 0s 431us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.0339 - val_acc: 1.0000\n",
            "Epoch 487/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0111 - acc: 1.0000 - val_loss: 0.0337 - val_acc: 1.0000\n",
            "Epoch 488/1000\n",
            "44/44 [==============================] - 0s 539us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0333 - val_acc: 1.0000\n",
            "Epoch 489/1000\n",
            "44/44 [==============================] - 0s 638us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0327 - val_acc: 1.0000\n",
            "Epoch 490/1000\n",
            "44/44 [==============================] - 0s 527us/step - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0327 - val_acc: 1.0000\n",
            "Epoch 491/1000\n",
            "44/44 [==============================] - 0s 515us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0325 - val_acc: 1.0000\n",
            "Epoch 492/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0325 - val_acc: 1.0000\n",
            "Epoch 493/1000\n",
            "44/44 [==============================] - 0s 430us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0325 - val_acc: 1.0000\n",
            "Epoch 494/1000\n",
            "44/44 [==============================] - 0s 436us/step - loss: 0.0107 - acc: 1.0000 - val_loss: 0.0324 - val_acc: 1.0000\n",
            "Epoch 495/1000\n",
            "44/44 [==============================] - 0s 414us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0320 - val_acc: 1.0000\n",
            "Epoch 496/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0314 - val_acc: 1.0000\n",
            "Epoch 497/1000\n",
            "44/44 [==============================] - 0s 469us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0316 - val_acc: 1.0000\n",
            "Epoch 498/1000\n",
            "44/44 [==============================] - 0s 452us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0314 - val_acc: 1.0000\n",
            "Epoch 499/1000\n",
            "44/44 [==============================] - 0s 550us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0315 - val_acc: 1.0000\n",
            "Epoch 500/1000\n",
            "44/44 [==============================] - 0s 565us/step - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0313 - val_acc: 1.0000\n",
            "Epoch 501/1000\n",
            "44/44 [==============================] - 0s 499us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0306 - val_acc: 1.0000\n",
            "Epoch 502/1000\n",
            "44/44 [==============================] - 0s 549us/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 1.0000\n",
            "Epoch 503/1000\n",
            "44/44 [==============================] - 0s 482us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0303 - val_acc: 1.0000\n",
            "Epoch 504/1000\n",
            "44/44 [==============================] - 0s 471us/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 1.0000\n",
            "Epoch 505/1000\n",
            "44/44 [==============================] - 0s 499us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0309 - val_acc: 1.0000\n",
            "Epoch 506/1000\n",
            "44/44 [==============================] - 0s 536us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.0307 - val_acc: 1.0000\n",
            "Epoch 507/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0305 - val_acc: 1.0000\n",
            "Epoch 508/1000\n",
            "44/44 [==============================] - 0s 463us/step - loss: 0.0100 - acc: 1.0000 - val_loss: 0.0302 - val_acc: 1.0000\n",
            "Epoch 509/1000\n",
            "44/44 [==============================] - 0s 571us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0298 - val_acc: 1.0000\n",
            "Epoch 510/1000\n",
            "44/44 [==============================] - 0s 459us/step - loss: 0.0099 - acc: 1.0000 - val_loss: 0.0300 - val_acc: 1.0000\n",
            "Epoch 511/1000\n",
            "44/44 [==============================] - 0s 486us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0299 - val_acc: 1.0000\n",
            "Epoch 512/1000\n",
            "44/44 [==============================] - 0s 458us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 1.0000\n",
            "Epoch 513/1000\n",
            "44/44 [==============================] - 0s 482us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 0.0292 - val_acc: 1.0000\n",
            "Epoch 514/1000\n",
            "44/44 [==============================] - 0s 463us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0292 - val_acc: 1.0000\n",
            "Epoch 515/1000\n",
            "44/44 [==============================] - 0s 447us/step - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0288 - val_acc: 1.0000\n",
            "Epoch 516/1000\n",
            "44/44 [==============================] - 0s 618us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0288 - val_acc: 1.0000\n",
            "Epoch 517/1000\n",
            "44/44 [==============================] - 0s 679us/step - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0290 - val_acc: 1.0000\n",
            "Epoch 518/1000\n",
            "44/44 [==============================] - 0s 466us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0292 - val_acc: 1.0000\n",
            "Epoch 519/1000\n",
            "44/44 [==============================] - 0s 492us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0289 - val_acc: 1.0000\n",
            "Epoch 520/1000\n",
            "44/44 [==============================] - 0s 528us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0288 - val_acc: 1.0000\n",
            "Epoch 521/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0287 - val_acc: 1.0000\n",
            "Epoch 522/1000\n",
            "44/44 [==============================] - 0s 485us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0286 - val_acc: 1.0000\n",
            "Epoch 523/1000\n",
            "44/44 [==============================] - 0s 466us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0284 - val_acc: 1.0000\n",
            "Epoch 524/1000\n",
            "44/44 [==============================] - 0s 513us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 0.0280 - val_acc: 1.0000\n",
            "Epoch 525/1000\n",
            "44/44 [==============================] - 0s 475us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0279 - val_acc: 1.0000\n",
            "Epoch 526/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 1.0000\n",
            "Epoch 527/1000\n",
            "44/44 [==============================] - 0s 467us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0276 - val_acc: 1.0000\n",
            "Epoch 528/1000\n",
            "44/44 [==============================] - 0s 469us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 1.0000\n",
            "Epoch 529/1000\n",
            "44/44 [==============================] - 0s 523us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0279 - val_acc: 1.0000\n",
            "Epoch 530/1000\n",
            "44/44 [==============================] - 0s 484us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0279 - val_acc: 1.0000\n",
            "Epoch 531/1000\n",
            "44/44 [==============================] - 0s 459us/step - loss: 0.0090 - acc: 1.0000 - val_loss: 0.0278 - val_acc: 1.0000\n",
            "Epoch 532/1000\n",
            "44/44 [==============================] - 0s 465us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 1.0000\n",
            "Epoch 533/1000\n",
            "44/44 [==============================] - 0s 463us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0277 - val_acc: 1.0000\n",
            "Epoch 534/1000\n",
            "44/44 [==============================] - 0s 496us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.0278 - val_acc: 1.0000\n",
            "Epoch 535/1000\n",
            "44/44 [==============================] - 0s 493us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0274 - val_acc: 1.0000\n",
            "Epoch 536/1000\n",
            "44/44 [==============================] - 0s 472us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 0.0270 - val_acc: 1.0000\n",
            "Epoch 537/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0268 - val_acc: 1.0000\n",
            "Epoch 538/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0087 - acc: 1.0000 - val_loss: 0.0268 - val_acc: 1.0000\n",
            "Epoch 539/1000\n",
            "44/44 [==============================] - 0s 498us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0267 - val_acc: 1.0000\n",
            "Epoch 540/1000\n",
            "44/44 [==============================] - 0s 479us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0261 - val_acc: 1.0000\n",
            "Epoch 541/1000\n",
            "44/44 [==============================] - 0s 491us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0260 - val_acc: 1.0000\n",
            "Epoch 542/1000\n",
            "44/44 [==============================] - 0s 536us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0257 - val_acc: 1.0000\n",
            "Epoch 543/1000\n",
            "44/44 [==============================] - 0s 534us/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0254 - val_acc: 1.0000\n",
            "Epoch 544/1000\n",
            "44/44 [==============================] - 0s 499us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 1.0000\n",
            "Epoch 545/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 1.0000\n",
            "Epoch 546/1000\n",
            "44/44 [==============================] - 0s 474us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0247 - val_acc: 1.0000\n",
            "Epoch 547/1000\n",
            "44/44 [==============================] - 0s 407us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0247 - val_acc: 1.0000\n",
            "Epoch 548/1000\n",
            "44/44 [==============================] - 0s 442us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0248 - val_acc: 1.0000\n",
            "Epoch 549/1000\n",
            "44/44 [==============================] - 0s 497us/step - loss: 0.0083 - acc: 1.0000 - val_loss: 0.0248 - val_acc: 1.0000\n",
            "Epoch 550/1000\n",
            "44/44 [==============================] - 0s 500us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 1.0000\n",
            "Epoch 551/1000\n",
            "44/44 [==============================] - 0s 493us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0245 - val_acc: 1.0000\n",
            "Epoch 552/1000\n",
            "44/44 [==============================] - 0s 478us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0244 - val_acc: 1.0000\n",
            "Epoch 553/1000\n",
            "44/44 [==============================] - 0s 432us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0245 - val_acc: 1.0000\n",
            "Epoch 554/1000\n",
            "44/44 [==============================] - 0s 526us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 1.0000\n",
            "Epoch 555/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0244 - val_acc: 1.0000\n",
            "Epoch 556/1000\n",
            "44/44 [==============================] - 0s 474us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0246 - val_acc: 1.0000\n",
            "Epoch 557/1000\n",
            "44/44 [==============================] - 0s 487us/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0245 - val_acc: 1.0000\n",
            "Epoch 558/1000\n",
            "44/44 [==============================] - 0s 527us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 1.0000\n",
            "Epoch 559/1000\n",
            "44/44 [==============================] - 0s 655us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0239 - val_acc: 1.0000\n",
            "Epoch 560/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.0239 - val_acc: 1.0000\n",
            "Epoch 561/1000\n",
            "44/44 [==============================] - 0s 488us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 1.0000\n",
            "Epoch 562/1000\n",
            "44/44 [==============================] - 0s 474us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 1.0000\n",
            "Epoch 563/1000\n",
            "44/44 [==============================] - 0s 474us/step - loss: 0.0078 - acc: 1.0000 - val_loss: 0.0234 - val_acc: 1.0000\n",
            "Epoch 564/1000\n",
            "44/44 [==============================] - 0s 467us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 1.0000\n",
            "Epoch 565/1000\n",
            "44/44 [==============================] - 0s 503us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 1.0000\n",
            "Epoch 566/1000\n",
            "44/44 [==============================] - 0s 488us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 1.0000\n",
            "Epoch 567/1000\n",
            "44/44 [==============================] - 0s 493us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 1.0000\n",
            "Epoch 568/1000\n",
            "44/44 [==============================] - 0s 538us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
            "Epoch 569/1000\n",
            "44/44 [==============================] - 0s 458us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
            "Epoch 570/1000\n",
            "44/44 [==============================] - 0s 462us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 1.0000\n",
            "Epoch 571/1000\n",
            "44/44 [==============================] - 0s 628us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 1.0000\n",
            "Epoch 572/1000\n",
            "44/44 [==============================] - 0s 474us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 0.0236 - val_acc: 1.0000\n",
            "Epoch 573/1000\n",
            "44/44 [==============================] - 0s 451us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 1.0000\n",
            "Epoch 574/1000\n",
            "44/44 [==============================] - 0s 440us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0233 - val_acc: 1.0000\n",
            "Epoch 575/1000\n",
            "44/44 [==============================] - 0s 426us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 1.0000\n",
            "Epoch 576/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 1.0000\n",
            "Epoch 577/1000\n",
            "44/44 [==============================] - 0s 469us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 1.0000\n",
            "Epoch 578/1000\n",
            "44/44 [==============================] - 0s 538us/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0228 - val_acc: 1.0000\n",
            "Epoch 579/1000\n",
            "44/44 [==============================] - 0s 443us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 1.0000\n",
            "Epoch 580/1000\n",
            "44/44 [==============================] - 0s 469us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 1.0000\n",
            "Epoch 581/1000\n",
            "44/44 [==============================] - 0s 505us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 1.0000\n",
            "Epoch 582/1000\n",
            "44/44 [==============================] - 0s 586us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0221 - val_acc: 1.0000\n",
            "Epoch 583/1000\n",
            "44/44 [==============================] - 0s 509us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0222 - val_acc: 1.0000\n",
            "Epoch 584/1000\n",
            "44/44 [==============================] - 0s 543us/step - loss: 0.0071 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 1.0000\n",
            "Epoch 585/1000\n",
            "44/44 [==============================] - 0s 449us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 1.0000\n",
            "Epoch 586/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0219 - val_acc: 1.0000\n",
            "Epoch 587/1000\n",
            "44/44 [==============================] - 0s 455us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0217 - val_acc: 1.0000\n",
            "Epoch 588/1000\n",
            "44/44 [==============================] - 0s 449us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 1.0000\n",
            "Epoch 589/1000\n",
            "44/44 [==============================] - 0s 460us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0213 - val_acc: 1.0000\n",
            "Epoch 590/1000\n",
            "44/44 [==============================] - 0s 539us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 1.0000\n",
            "Epoch 591/1000\n",
            "44/44 [==============================] - 0s 487us/step - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 1.0000\n",
            "Epoch 592/1000\n",
            "44/44 [==============================] - 0s 487us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 1.0000\n",
            "Epoch 593/1000\n",
            "44/44 [==============================] - 0s 471us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 1.0000\n",
            "Epoch 594/1000\n",
            "44/44 [==============================] - 0s 531us/step - loss: 0.0068 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 1.0000\n",
            "Epoch 595/1000\n",
            "44/44 [==============================] - 0s 449us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0209 - val_acc: 1.0000\n",
            "Epoch 596/1000\n",
            "44/44 [==============================] - 0s 553us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 1.0000\n",
            "Epoch 597/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
            "Epoch 598/1000\n",
            "44/44 [==============================] - 0s 444us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0204 - val_acc: 1.0000\n",
            "Epoch 599/1000\n",
            "44/44 [==============================] - 0s 431us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 1.0000\n",
            "Epoch 600/1000\n",
            "44/44 [==============================] - 0s 488us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0200 - val_acc: 1.0000\n",
            "Epoch 601/1000\n",
            "44/44 [==============================] - 0s 432us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0198 - val_acc: 1.0000\n",
            "Epoch 602/1000\n",
            "44/44 [==============================] - 0s 480us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 1.0000\n",
            "Epoch 603/1000\n",
            "44/44 [==============================] - 0s 557us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 1.0000\n",
            "Epoch 604/1000\n",
            "44/44 [==============================] - 0s 432us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0199 - val_acc: 1.0000\n",
            "Epoch 605/1000\n",
            "44/44 [==============================] - 0s 489us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 1.0000\n",
            "Epoch 606/1000\n",
            "44/44 [==============================] - 0s 666us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 1.0000\n",
            "Epoch 607/1000\n",
            "44/44 [==============================] - 0s 482us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 1.0000\n",
            "Epoch 608/1000\n",
            "44/44 [==============================] - 0s 462us/step - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0196 - val_acc: 1.0000\n",
            "Epoch 609/1000\n",
            "44/44 [==============================] - 0s 436us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 1.0000\n",
            "Epoch 610/1000\n",
            "44/44 [==============================] - 0s 456us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0194 - val_acc: 1.0000\n",
            "Epoch 611/1000\n",
            "44/44 [==============================] - 0s 498us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
            "Epoch 612/1000\n",
            "44/44 [==============================] - 0s 518us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 1.0000\n",
            "Epoch 613/1000\n",
            "44/44 [==============================] - 0s 452us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
            "Epoch 614/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0192 - val_acc: 1.0000\n",
            "Epoch 615/1000\n",
            "44/44 [==============================] - 0s 525us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 1.0000\n",
            "Epoch 616/1000\n",
            "44/44 [==============================] - 0s 474us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 1.0000\n",
            "Epoch 617/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0187 - val_acc: 1.0000\n",
            "Epoch 618/1000\n",
            "44/44 [==============================] - 0s 547us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0186 - val_acc: 1.0000\n",
            "Epoch 619/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
            "Epoch 620/1000\n",
            "44/44 [==============================] - 0s 491us/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 1.0000\n",
            "Epoch 621/1000\n",
            "44/44 [==============================] - 0s 478us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
            "Epoch 622/1000\n",
            "44/44 [==============================] - 0s 427us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
            "Epoch 623/1000\n",
            "44/44 [==============================] - 0s 483us/step - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 1.0000\n",
            "Epoch 624/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
            "Epoch 625/1000\n",
            "44/44 [==============================] - 0s 571us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 1.0000\n",
            "Epoch 626/1000\n",
            "44/44 [==============================] - 0s 514us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
            "Epoch 627/1000\n",
            "44/44 [==============================] - 0s 479us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 1.0000\n",
            "Epoch 628/1000\n",
            "44/44 [==============================] - 0s 540us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0183 - val_acc: 1.0000\n",
            "Epoch 629/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
            "Epoch 630/1000\n",
            "44/44 [==============================] - 0s 542us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
            "Epoch 631/1000\n",
            "44/44 [==============================] - 0s 431us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 1.0000\n",
            "Epoch 632/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 1.0000\n",
            "Epoch 633/1000\n",
            "44/44 [==============================] - 0s 398us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0180 - val_acc: 1.0000\n",
            "Epoch 634/1000\n",
            "44/44 [==============================] - 0s 449us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 1.0000\n",
            "Epoch 635/1000\n",
            "44/44 [==============================] - 0s 497us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 1.0000\n",
            "Epoch 636/1000\n",
            "44/44 [==============================] - 0s 538us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 1.0000\n",
            "Epoch 637/1000\n",
            "44/44 [==============================] - 0s 415us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0174 - val_acc: 1.0000\n",
            "Epoch 638/1000\n",
            "44/44 [==============================] - 0s 527us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 1.0000\n",
            "Epoch 639/1000\n",
            "44/44 [==============================] - 0s 469us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
            "Epoch 640/1000\n",
            "44/44 [==============================] - 0s 509us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0172 - val_acc: 1.0000\n",
            "Epoch 641/1000\n",
            "44/44 [==============================] - 0s 465us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 1.0000\n",
            "Epoch 642/1000\n",
            "44/44 [==============================] - 0s 421us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0169 - val_acc: 1.0000\n",
            "Epoch 643/1000\n",
            "44/44 [==============================] - 0s 492us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 1.0000\n",
            "Epoch 644/1000\n",
            "44/44 [==============================] - 0s 506us/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.0165 - val_acc: 1.0000\n",
            "Epoch 645/1000\n",
            "44/44 [==============================] - 0s 489us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0163 - val_acc: 1.0000\n",
            "Epoch 646/1000\n",
            "44/44 [==============================] - 0s 475us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 1.0000\n",
            "Epoch 647/1000\n",
            "44/44 [==============================] - 0s 499us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
            "Epoch 648/1000\n",
            "44/44 [==============================] - 0s 447us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 1.0000\n",
            "Epoch 649/1000\n",
            "44/44 [==============================] - 0s 502us/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
            "Epoch 650/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
            "Epoch 651/1000\n",
            "44/44 [==============================] - 0s 412us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
            "Epoch 652/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 1.0000\n",
            "Epoch 653/1000\n",
            "44/44 [==============================] - 0s 500us/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0161 - val_acc: 1.0000\n",
            "Epoch 654/1000\n",
            "44/44 [==============================] - 0s 488us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
            "Epoch 655/1000\n",
            "44/44 [==============================] - 0s 497us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
            "Epoch 656/1000\n",
            "44/44 [==============================] - 0s 518us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 1.0000\n",
            "Epoch 657/1000\n",
            "44/44 [==============================] - 0s 542us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0158 - val_acc: 1.0000\n",
            "Epoch 658/1000\n",
            "44/44 [==============================] - 0s 572us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
            "Epoch 659/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 1.0000\n",
            "Epoch 660/1000\n",
            "44/44 [==============================] - 0s 447us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0159 - val_acc: 1.0000\n",
            "Epoch 661/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 1.0000\n",
            "Epoch 662/1000\n",
            "44/44 [==============================] - 0s 486us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 1.0000\n",
            "Epoch 663/1000\n",
            "44/44 [==============================] - 0s 472us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0155 - val_acc: 1.0000\n",
            "Epoch 664/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 1.0000\n",
            "Epoch 665/1000\n",
            "44/44 [==============================] - 0s 461us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0149 - val_acc: 1.0000\n",
            "Epoch 666/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0149 - val_acc: 1.0000\n",
            "Epoch 667/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0150 - val_acc: 1.0000\n",
            "Epoch 668/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0150 - val_acc: 1.0000\n",
            "Epoch 669/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
            "Epoch 670/1000\n",
            "44/44 [==============================] - 0s 429us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
            "Epoch 671/1000\n",
            "44/44 [==============================] - 0s 451us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
            "Epoch 672/1000\n",
            "44/44 [==============================] - 0s 449us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
            "Epoch 673/1000\n",
            "44/44 [==============================] - 0s 414us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0150 - val_acc: 1.0000\n",
            "Epoch 674/1000\n",
            "44/44 [==============================] - 0s 409us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
            "Epoch 675/1000\n",
            "44/44 [==============================] - 0s 424us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
            "Epoch 676/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 1.0000\n",
            "Epoch 677/1000\n",
            "44/44 [==============================] - 0s 453us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 1.0000\n",
            "Epoch 678/1000\n",
            "44/44 [==============================] - 0s 426us/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0152 - val_acc: 1.0000\n",
            "Epoch 679/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 1.0000\n",
            "Epoch 680/1000\n",
            "44/44 [==============================] - 0s 522us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
            "Epoch 681/1000\n",
            "44/44 [==============================] - 0s 426us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0149 - val_acc: 1.0000\n",
            "Epoch 682/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0147 - val_acc: 1.0000\n",
            "Epoch 683/1000\n",
            "44/44 [==============================] - 0s 412us/step - loss: 0.0047 - acc: 1.0000 - val_loss: 0.0146 - val_acc: 1.0000\n",
            "Epoch 684/1000\n",
            "44/44 [==============================] - 0s 402us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 1.0000\n",
            "Epoch 685/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
            "Epoch 686/1000\n",
            "44/44 [==============================] - 0s 412us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0143 - val_acc: 1.0000\n",
            "Epoch 687/1000\n",
            "44/44 [==============================] - 0s 429us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0142 - val_acc: 1.0000\n",
            "Epoch 688/1000\n",
            "44/44 [==============================] - 0s 430us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 1.0000\n",
            "Epoch 689/1000\n",
            "44/44 [==============================] - 0s 426us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 1.0000\n",
            "Epoch 690/1000\n",
            "44/44 [==============================] - 0s 475us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 1.0000\n",
            "Epoch 691/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 1.0000\n",
            "Epoch 692/1000\n",
            "44/44 [==============================] - 0s 418us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
            "Epoch 693/1000\n",
            "44/44 [==============================] - 0s 424us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
            "Epoch 694/1000\n",
            "44/44 [==============================] - 0s 454us/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
            "Epoch 695/1000\n",
            "44/44 [==============================] - 0s 456us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
            "Epoch 696/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
            "Epoch 697/1000\n",
            "44/44 [==============================] - 0s 426us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 1.0000\n",
            "Epoch 698/1000\n",
            "44/44 [==============================] - 0s 421us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 1.0000\n",
            "Epoch 699/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
            "Epoch 700/1000\n",
            "44/44 [==============================] - 0s 455us/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
            "Epoch 701/1000\n",
            "44/44 [==============================] - 0s 434us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 1.0000\n",
            "Epoch 702/1000\n",
            "44/44 [==============================] - 0s 426us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
            "Epoch 703/1000\n",
            "44/44 [==============================] - 0s 428us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
            "Epoch 704/1000\n",
            "44/44 [==============================] - 0s 544us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
            "Epoch 705/1000\n",
            "44/44 [==============================] - 0s 593us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0136 - val_acc: 1.0000\n",
            "Epoch 706/1000\n",
            "44/44 [==============================] - 0s 542us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 1.0000\n",
            "Epoch 707/1000\n",
            "44/44 [==============================] - 0s 419us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0134 - val_acc: 1.0000\n",
            "Epoch 708/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0133 - val_acc: 1.0000\n",
            "Epoch 709/1000\n",
            "44/44 [==============================] - 0s 431us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 1.0000\n",
            "Epoch 710/1000\n",
            "44/44 [==============================] - 0s 465us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 1.0000\n",
            "Epoch 711/1000\n",
            "44/44 [==============================] - 0s 470us/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0129 - val_acc: 1.0000\n",
            "Epoch 712/1000\n",
            "44/44 [==============================] - 0s 509us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 1.0000\n",
            "Epoch 713/1000\n",
            "44/44 [==============================] - 0s 475us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
            "Epoch 714/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
            "Epoch 715/1000\n",
            "44/44 [==============================] - 0s 478us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
            "Epoch 716/1000\n",
            "44/44 [==============================] - 0s 537us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
            "Epoch 717/1000\n",
            "44/44 [==============================] - 0s 588us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
            "Epoch 718/1000\n",
            "44/44 [==============================] - 0s 518us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
            "Epoch 719/1000\n",
            "44/44 [==============================] - 0s 512us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0127 - val_acc: 1.0000\n",
            "Epoch 720/1000\n",
            "44/44 [==============================] - 0s 512us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
            "Epoch 721/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0126 - val_acc: 1.0000\n",
            "Epoch 722/1000\n",
            "44/44 [==============================] - 0s 436us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
            "Epoch 723/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0125 - val_acc: 1.0000\n",
            "Epoch 724/1000\n",
            "44/44 [==============================] - 0s 428us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0124 - val_acc: 1.0000\n",
            "Epoch 725/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
            "Epoch 726/1000\n",
            "44/44 [==============================] - 0s 455us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0123 - val_acc: 1.0000\n",
            "Epoch 727/1000\n",
            "44/44 [==============================] - 0s 459us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 1.0000\n",
            "Epoch 728/1000\n",
            "44/44 [==============================] - 0s 565us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
            "Epoch 729/1000\n",
            "44/44 [==============================] - 0s 568us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 1.0000\n",
            "Epoch 730/1000\n",
            "44/44 [==============================] - 0s 607us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 1.0000\n",
            "Epoch 731/1000\n",
            "44/44 [==============================] - 0s 537us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
            "Epoch 732/1000\n",
            "44/44 [==============================] - 0s 530us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 1.0000\n",
            "Epoch 733/1000\n",
            "44/44 [==============================] - 0s 548us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
            "Epoch 734/1000\n",
            "44/44 [==============================] - 0s 560us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 1.0000\n",
            "Epoch 735/1000\n",
            "44/44 [==============================] - 0s 542us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
            "Epoch 736/1000\n",
            "44/44 [==============================] - 0s 589us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
            "Epoch 737/1000\n",
            "44/44 [==============================] - 0s 565us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
            "Epoch 738/1000\n",
            "44/44 [==============================] - 0s 651us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
            "Epoch 739/1000\n",
            "44/44 [==============================] - 0s 542us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0113 - val_acc: 1.0000\n",
            "Epoch 740/1000\n",
            "44/44 [==============================] - 0s 523us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 1.0000\n",
            "Epoch 741/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 1.0000\n",
            "Epoch 742/1000\n",
            "44/44 [==============================] - 0s 468us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 1.0000\n",
            "Epoch 743/1000\n",
            "44/44 [==============================] - 0s 460us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 1.0000\n",
            "Epoch 744/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
            "Epoch 745/1000\n",
            "44/44 [==============================] - 0s 412us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0110 - val_acc: 1.0000\n",
            "Epoch 746/1000\n",
            "44/44 [==============================] - 0s 442us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
            "Epoch 747/1000\n",
            "44/44 [==============================] - 0s 513us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0108 - val_acc: 1.0000\n",
            "Epoch 748/1000\n",
            "44/44 [==============================] - 0s 459us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0107 - val_acc: 1.0000\n",
            "Epoch 749/1000\n",
            "44/44 [==============================] - 0s 507us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
            "Epoch 750/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
            "Epoch 751/1000\n",
            "44/44 [==============================] - 0s 478us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
            "Epoch 752/1000\n",
            "44/44 [==============================] - 0s 604us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
            "Epoch 753/1000\n",
            "44/44 [==============================] - 0s 548us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 1.0000\n",
            "Epoch 754/1000\n",
            "44/44 [==============================] - 0s 572us/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
            "Epoch 755/1000\n",
            "44/44 [==============================] - 0s 588us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
            "Epoch 756/1000\n",
            "44/44 [==============================] - 0s 489us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
            "Epoch 757/1000\n",
            "44/44 [==============================] - 0s 478us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
            "Epoch 758/1000\n",
            "44/44 [==============================] - 0s 497us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
            "Epoch 759/1000\n",
            "44/44 [==============================] - 0s 471us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
            "Epoch 760/1000\n",
            "44/44 [==============================] - 0s 508us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
            "Epoch 761/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0105 - val_acc: 1.0000\n",
            "Epoch 762/1000\n",
            "44/44 [==============================] - 0s 517us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0104 - val_acc: 1.0000\n",
            "Epoch 763/1000\n",
            "44/44 [==============================] - 0s 482us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0103 - val_acc: 1.0000\n",
            "Epoch 764/1000\n",
            "44/44 [==============================] - 0s 393us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 1.0000\n",
            "Epoch 765/1000\n",
            "44/44 [==============================] - 0s 475us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 1.0000\n",
            "Epoch 766/1000\n",
            "44/44 [==============================] - 0s 474us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
            "Epoch 767/1000\n",
            "44/44 [==============================] - 0s 482us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
            "Epoch 768/1000\n",
            "44/44 [==============================] - 0s 463us/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
            "Epoch 769/1000\n",
            "44/44 [==============================] - 0s 480us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
            "Epoch 770/1000\n",
            "44/44 [==============================] - 0s 514us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
            "Epoch 771/1000\n",
            "44/44 [==============================] - 0s 472us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
            "Epoch 772/1000\n",
            "44/44 [==============================] - 0s 507us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 1.0000\n",
            "Epoch 773/1000\n",
            "44/44 [==============================] - 0s 493us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 1.0000\n",
            "Epoch 774/1000\n",
            "44/44 [==============================] - 0s 471us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
            "Epoch 775/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
            "Epoch 776/1000\n",
            "44/44 [==============================] - 0s 469us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0098 - val_acc: 1.0000\n",
            "Epoch 777/1000\n",
            "44/44 [==============================] - 0s 409us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
            "Epoch 778/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
            "Epoch 779/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
            "Epoch 780/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
            "Epoch 781/1000\n",
            "44/44 [==============================] - 0s 411us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0097 - val_acc: 1.0000\n",
            "Epoch 782/1000\n",
            "44/44 [==============================] - 0s 424us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
            "Epoch 783/1000\n",
            "44/44 [==============================] - 0s 413us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
            "Epoch 784/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
            "Epoch 785/1000\n",
            "44/44 [==============================] - 0s 468us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 1.0000\n",
            "Epoch 786/1000\n",
            "44/44 [==============================] - 0s 430us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000\n",
            "Epoch 787/1000\n",
            "44/44 [==============================] - 0s 436us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 1.0000\n",
            "Epoch 788/1000\n",
            "44/44 [==============================] - 0s 456us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
            "Epoch 789/1000\n",
            "44/44 [==============================] - 0s 437us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
            "Epoch 790/1000\n",
            "44/44 [==============================] - 0s 453us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
            "Epoch 791/1000\n",
            "44/44 [==============================] - 0s 423us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
            "Epoch 792/1000\n",
            "44/44 [==============================] - 0s 442us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 1.0000\n",
            "Epoch 793/1000\n",
            "44/44 [==============================] - 0s 551us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
            "Epoch 794/1000\n",
            "44/44 [==============================] - 0s 424us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0091 - val_acc: 1.0000\n",
            "Epoch 795/1000\n",
            "44/44 [==============================] - 0s 433us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 1.0000\n",
            "Epoch 796/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 1.0000\n",
            "Epoch 797/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 1.0000\n",
            "Epoch 798/1000\n",
            "44/44 [==============================] - 0s 509us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
            "Epoch 799/1000\n",
            "44/44 [==============================] - 0s 492us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
            "Epoch 800/1000\n",
            "44/44 [==============================] - 0s 466us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
            "Epoch 801/1000\n",
            "44/44 [==============================] - 0s 464us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
            "Epoch 802/1000\n",
            "44/44 [==============================] - 0s 453us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
            "Epoch 803/1000\n",
            "44/44 [==============================] - 0s 417us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
            "Epoch 804/1000\n",
            "44/44 [==============================] - 0s 425us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 1.0000\n",
            "Epoch 805/1000\n",
            "44/44 [==============================] - 0s 413us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
            "Epoch 806/1000\n",
            "44/44 [==============================] - 0s 411us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 1.0000\n",
            "Epoch 807/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
            "Epoch 808/1000\n",
            "44/44 [==============================] - 0s 515us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Epoch 809/1000\n",
            "44/44 [==============================] - 0s 430us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 1.0000\n",
            "Epoch 810/1000\n",
            "44/44 [==============================] - 0s 431us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Epoch 811/1000\n",
            "44/44 [==============================] - 0s 492us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 1.0000\n",
            "Epoch 812/1000\n",
            "44/44 [==============================] - 0s 451us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
            "Epoch 813/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
            "Epoch 814/1000\n",
            "44/44 [==============================] - 0s 430us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
            "Epoch 815/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 816/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 817/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 818/1000\n",
            "44/44 [==============================] - 0s 488us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 819/1000\n",
            "44/44 [==============================] - 0s 431us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 820/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 821/1000\n",
            "44/44 [==============================] - 0s 430us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
            "Epoch 822/1000\n",
            "44/44 [==============================] - 0s 411us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
            "Epoch 823/1000\n",
            "44/44 [==============================] - 0s 436us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 824/1000\n",
            "44/44 [==============================] - 0s 442us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 1.0000\n",
            "Epoch 825/1000\n",
            "44/44 [==============================] - 0s 513us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 826/1000\n",
            "44/44 [==============================] - 0s 468us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 827/1000\n",
            "44/44 [==============================] - 0s 437us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
            "Epoch 828/1000\n",
            "44/44 [==============================] - 0s 426us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 829/1000\n",
            "44/44 [==============================] - 0s 427us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 830/1000\n",
            "44/44 [==============================] - 0s 421us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 831/1000\n",
            "44/44 [==============================] - 0s 443us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 832/1000\n",
            "44/44 [==============================] - 0s 434us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 1.0000\n",
            "Epoch 833/1000\n",
            "44/44 [==============================] - 0s 414us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 834/1000\n",
            "44/44 [==============================] - 0s 421us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 835/1000\n",
            "44/44 [==============================] - 0s 436us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 836/1000\n",
            "44/44 [==============================] - 0s 452us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 837/1000\n",
            "44/44 [==============================] - 0s 419us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 838/1000\n",
            "44/44 [==============================] - 0s 414us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 839/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 1.0000\n",
            "Epoch 840/1000\n",
            "44/44 [==============================] - 0s 425us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 841/1000\n",
            "44/44 [==============================] - 0s 409us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 842/1000\n",
            "44/44 [==============================] - 0s 434us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 843/1000\n",
            "44/44 [==============================] - 0s 410us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0075 - val_acc: 1.0000\n",
            "Epoch 844/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
            "Epoch 845/1000\n",
            "44/44 [==============================] - 0s 427us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 1.0000\n",
            "Epoch 846/1000\n",
            "44/44 [==============================] - 0s 431us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 1.0000\n",
            "Epoch 847/1000\n",
            "44/44 [==============================] - 0s 471us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 1.0000\n",
            "Epoch 848/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
            "Epoch 849/1000\n",
            "44/44 [==============================] - 0s 456us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
            "Epoch 850/1000\n",
            "44/44 [==============================] - 0s 447us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0071 - val_acc: 1.0000\n",
            "Epoch 851/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
            "Epoch 852/1000\n",
            "44/44 [==============================] - 0s 453us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
            "Epoch 853/1000\n",
            "44/44 [==============================] - 0s 410us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
            "Epoch 854/1000\n",
            "44/44 [==============================] - 0s 410us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 1.0000\n",
            "Epoch 855/1000\n",
            "44/44 [==============================] - 0s 416us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
            "Epoch 856/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 1.0000\n",
            "Epoch 857/1000\n",
            "44/44 [==============================] - 0s 458us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 858/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 859/1000\n",
            "44/44 [==============================] - 0s 465us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
            "Epoch 860/1000\n",
            "44/44 [==============================] - 0s 467us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
            "Epoch 861/1000\n",
            "44/44 [==============================] - 0s 423us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 862/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 863/1000\n",
            "44/44 [==============================] - 0s 430us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 864/1000\n",
            "44/44 [==============================] - 0s 405us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 1.0000\n",
            "Epoch 865/1000\n",
            "44/44 [==============================] - 0s 413us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 1.0000\n",
            "Epoch 866/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 1.0000\n",
            "Epoch 867/1000\n",
            "44/44 [==============================] - 0s 516us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
            "Epoch 868/1000\n",
            "44/44 [==============================] - 0s 413us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
            "Epoch 869/1000\n",
            "44/44 [==============================] - 0s 516us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
            "Epoch 870/1000\n",
            "44/44 [==============================] - 0s 467us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
            "Epoch 871/1000\n",
            "44/44 [==============================] - 0s 439us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
            "Epoch 872/1000\n",
            "44/44 [==============================] - 0s 426us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
            "Epoch 873/1000\n",
            "44/44 [==============================] - 0s 425us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
            "Epoch 874/1000\n",
            "44/44 [==============================] - 0s 403us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
            "Epoch 875/1000\n",
            "44/44 [==============================] - 0s 556us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
            "Epoch 876/1000\n",
            "44/44 [==============================] - 0s 513us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
            "Epoch 877/1000\n",
            "44/44 [==============================] - 0s 458us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
            "Epoch 878/1000\n",
            "44/44 [==============================] - 0s 478us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000\n",
            "Epoch 879/1000\n",
            "44/44 [==============================] - 0s 493us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
            "Epoch 880/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 1.0000\n",
            "Epoch 881/1000\n",
            "44/44 [==============================] - 0s 512us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
            "Epoch 882/1000\n",
            "44/44 [==============================] - 0s 495us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 1.0000\n",
            "Epoch 883/1000\n",
            "44/44 [==============================] - 0s 406us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 1.0000\n",
            "Epoch 884/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
            "Epoch 885/1000\n",
            "44/44 [==============================] - 0s 592us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
            "Epoch 886/1000\n",
            "44/44 [==============================] - 0s 503us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
            "Epoch 887/1000\n",
            "44/44 [==============================] - 0s 535us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
            "Epoch 888/1000\n",
            "44/44 [==============================] - 0s 495us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
            "Epoch 889/1000\n",
            "44/44 [==============================] - 0s 489us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
            "Epoch 890/1000\n",
            "44/44 [==============================] - 0s 496us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
            "Epoch 891/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 1.0000\n",
            "Epoch 892/1000\n",
            "44/44 [==============================] - 0s 457us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 1.0000\n",
            "Epoch 893/1000\n",
            "44/44 [==============================] - 0s 460us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
            "Epoch 894/1000\n",
            "44/44 [==============================] - 0s 489us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0058 - val_acc: 1.0000\n",
            "Epoch 895/1000\n",
            "44/44 [==============================] - 0s 528us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
            "Epoch 896/1000\n",
            "44/44 [==============================] - 0s 438us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
            "Epoch 897/1000\n",
            "44/44 [==============================] - 0s 426us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
            "Epoch 898/1000\n",
            "44/44 [==============================] - 0s 584us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
            "Epoch 899/1000\n",
            "44/44 [==============================] - 0s 479us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
            "Epoch 900/1000\n",
            "44/44 [==============================] - 0s 476us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
            "Epoch 901/1000\n",
            "44/44 [==============================] - 0s 434us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000\n",
            "Epoch 902/1000\n",
            "44/44 [==============================] - 0s 512us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
            "Epoch 903/1000\n",
            "44/44 [==============================] - 0s 437us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
            "Epoch 904/1000\n",
            "44/44 [==============================] - 0s 490us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
            "Epoch 905/1000\n",
            "44/44 [==============================] - 0s 452us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
            "Epoch 906/1000\n",
            "44/44 [==============================] - 0s 461us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
            "Epoch 907/1000\n",
            "44/44 [==============================] - 0s 453us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 1.0000\n",
            "Epoch 908/1000\n",
            "44/44 [==============================] - 0s 600us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
            "Epoch 909/1000\n",
            "44/44 [==============================] - 0s 494us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
            "Epoch 910/1000\n",
            "44/44 [==============================] - 0s 428us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
            "Epoch 911/1000\n",
            "44/44 [==============================] - 0s 460us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000\n",
            "Epoch 912/1000\n",
            "44/44 [==============================] - 0s 460us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
            "Epoch 913/1000\n",
            "44/44 [==============================] - 0s 455us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
            "Epoch 914/1000\n",
            "44/44 [==============================] - 0s 518us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n",
            "Epoch 915/1000\n",
            "44/44 [==============================] - 0s 495us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 1.0000\n",
            "Epoch 916/1000\n",
            "44/44 [==============================] - 0s 471us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
            "Epoch 917/1000\n",
            "44/44 [==============================] - 0s 648us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
            "Epoch 918/1000\n",
            "44/44 [==============================] - 0s 493us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
            "Epoch 919/1000\n",
            "44/44 [==============================] - 0s 404us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
            "Epoch 920/1000\n",
            "44/44 [==============================] - 0s 474us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
            "Epoch 921/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 1.0000\n",
            "Epoch 922/1000\n",
            "44/44 [==============================] - 0s 552us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
            "Epoch 923/1000\n",
            "44/44 [==============================] - 0s 498us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
            "Epoch 924/1000\n",
            "44/44 [==============================] - 0s 408us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
            "Epoch 925/1000\n",
            "44/44 [==============================] - 0s 431us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
            "Epoch 926/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
            "Epoch 927/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
            "Epoch 928/1000\n",
            "44/44 [==============================] - 0s 412us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
            "Epoch 929/1000\n",
            "44/44 [==============================] - 0s 432us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
            "Epoch 930/1000\n",
            "44/44 [==============================] - 0s 471us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
            "Epoch 931/1000\n",
            "44/44 [==============================] - 0s 445us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
            "Epoch 932/1000\n",
            "44/44 [==============================] - 0s 465us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
            "Epoch 933/1000\n",
            "44/44 [==============================] - 0s 461us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 1.0000\n",
            "Epoch 934/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
            "Epoch 935/1000\n",
            "44/44 [==============================] - 0s 442us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
            "Epoch 936/1000\n",
            "44/44 [==============================] - 0s 449us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
            "Epoch 937/1000\n",
            "44/44 [==============================] - 0s 452us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
            "Epoch 938/1000\n",
            "44/44 [==============================] - 0s 527us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
            "Epoch 939/1000\n",
            "44/44 [==============================] - 0s 585us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
            "Epoch 940/1000\n",
            "44/44 [==============================] - 0s 627us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
            "Epoch 941/1000\n",
            "44/44 [==============================] - 0s 498us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
            "Epoch 942/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 1.0000\n",
            "Epoch 943/1000\n",
            "44/44 [==============================] - 0s 423us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
            "Epoch 944/1000\n",
            "44/44 [==============================] - 0s 420us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
            "Epoch 945/1000\n",
            "44/44 [==============================] - 0s 547us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
            "Epoch 946/1000\n",
            "44/44 [==============================] - 0s 433us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
            "Epoch 947/1000\n",
            "44/44 [==============================] - 0s 451us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 1.0000\n",
            "Epoch 948/1000\n",
            "44/44 [==============================] - 0s 500us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
            "Epoch 949/1000\n",
            "44/44 [==============================] - 0s 531us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
            "Epoch 950/1000\n",
            "44/44 [==============================] - 0s 470us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000\n",
            "Epoch 951/1000\n",
            "44/44 [==============================] - 0s 453us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
            "Epoch 952/1000\n",
            "44/44 [==============================] - 0s 456us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
            "Epoch 953/1000\n",
            "44/44 [==============================] - 0s 450us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 1.0000\n",
            "Epoch 954/1000\n",
            "44/44 [==============================] - 0s 534us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
            "Epoch 955/1000\n",
            "44/44 [==============================] - 0s 545us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000\n",
            "Epoch 956/1000\n",
            "44/44 [==============================] - 0s 441us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
            "Epoch 957/1000\n",
            "44/44 [==============================] - 0s 505us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
            "Epoch 958/1000\n",
            "44/44 [==============================] - 0s 596us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
            "Epoch 959/1000\n",
            "44/44 [==============================] - 0s 536us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
            "Epoch 960/1000\n",
            "44/44 [==============================] - 0s 516us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
            "Epoch 961/1000\n",
            "44/44 [==============================] - 0s 546us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
            "Epoch 962/1000\n",
            "44/44 [==============================] - 0s 558us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
            "Epoch 963/1000\n",
            "44/44 [==============================] - 0s 563us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000\n",
            "Epoch 964/1000\n",
            "44/44 [==============================] - 0s 529us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
            "Epoch 965/1000\n",
            "44/44 [==============================] - 0s 521us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
            "Epoch 966/1000\n",
            "44/44 [==============================] - 0s 430us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000\n",
            "Epoch 967/1000\n",
            "44/44 [==============================] - 0s 472us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
            "Epoch 968/1000\n",
            "44/44 [==============================] - 0s 395us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
            "Epoch 969/1000\n",
            "44/44 [==============================] - 0s 511us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
            "Epoch 970/1000\n",
            "44/44 [==============================] - 0s 434us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
            "Epoch 971/1000\n",
            "44/44 [==============================] - 0s 488us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
            "Epoch 972/1000\n",
            "44/44 [==============================] - 0s 497us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
            "Epoch 973/1000\n",
            "44/44 [==============================] - 0s 540us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
            "Epoch 974/1000\n",
            "44/44 [==============================] - 0s 480us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
            "Epoch 975/1000\n",
            "44/44 [==============================] - 0s 585us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
            "Epoch 976/1000\n",
            "44/44 [==============================] - 0s 468us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
            "Epoch 977/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
            "Epoch 978/1000\n",
            "44/44 [==============================] - 0s 440us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 1.0000\n",
            "Epoch 979/1000\n",
            "44/44 [==============================] - 0s 660us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
            "Epoch 980/1000\n",
            "44/44 [==============================] - 0s 473us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
            "Epoch 981/1000\n",
            "44/44 [==============================] - 0s 671us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
            "Epoch 982/1000\n",
            "44/44 [==============================] - 0s 545us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
            "Epoch 983/1000\n",
            "44/44 [==============================] - 0s 516us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 1.0000\n",
            "Epoch 984/1000\n",
            "44/44 [==============================] - 0s 484us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
            "Epoch 985/1000\n",
            "44/44 [==============================] - 0s 477us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
            "Epoch 986/1000\n",
            "44/44 [==============================] - 0s 495us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
            "Epoch 987/1000\n",
            "44/44 [==============================] - 0s 446us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
            "Epoch 988/1000\n",
            "44/44 [==============================] - 0s 422us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
            "Epoch 989/1000\n",
            "44/44 [==============================] - 0s 422us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
            "Epoch 990/1000\n",
            "44/44 [==============================] - 0s 429us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000\n",
            "Epoch 991/1000\n",
            "44/44 [==============================] - 0s 468us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
            "Epoch 992/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
            "Epoch 993/1000\n",
            "44/44 [==============================] - 0s 429us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
            "Epoch 994/1000\n",
            "44/44 [==============================] - 0s 419us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 1.0000\n",
            "Epoch 995/1000\n",
            "44/44 [==============================] - 0s 412us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
            "Epoch 996/1000\n",
            "44/44 [==============================] - 0s 519us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
            "Epoch 997/1000\n",
            "44/44 [==============================] - 0s 448us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
            "Epoch 998/1000\n",
            "44/44 [==============================] - 0s 444us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
            "Epoch 999/1000\n",
            "44/44 [==============================] - 0s 435us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
            "Epoch 1000/1000\n",
            "44/44 [==============================] - 0s 425us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxvuJalq1LHl",
        "colab_type": "code",
        "outputId": "ab55eaa9-996f-4218-9f58-553fdebb471b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#Model Summary\n",
        "print(model.summary())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 5)                 720       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 726\n",
            "Trainable params: 726\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu3xqT65BP95",
        "colab_type": "code",
        "outputId": "d09861a8-0a74-4d42-9368-dabc29ca2e9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "#Diagnostic plot I: Model Performance (training loss vs test loss)\n",
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'])\n",
        "pyplot.plot(history.history['val_loss'])\n",
        "pyplot.title('Loss in training vs validation datasets')\n",
        "pyplot.ylabel('Loss')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
        "pyplot.show()\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "racnXi9hDEkC",
        "colab_type": "code",
        "outputId": "e5215391-17c9-4e5c-89de-e1550fc845bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "#Diagnostic Plot II: Model Performance (training accuracy vs test accuracy)\n",
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['acc'])\n",
        "pyplot.plot(history.history['val_acc'])\n",
        "pyplot.title('Accuracy in Training vs Validation datasets')\n",
        "pyplot.ylabel('Accuracy')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.legend(['Training Accuracy', 'Test Accuracy'], loc='upper right')\n",
        "pyplot.show()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}